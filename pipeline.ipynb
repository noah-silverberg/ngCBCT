{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4229da",
   "metadata": {},
   "source": [
    "# Setup Logging & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a15cef",
   "metadata": {},
   "source": [
    "### Setting up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"pipeline\")\n",
    "\n",
    "# Show info messages if DEBUG mode is enabled\n",
    "if DEBUG:\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.debug(\"DEBUG mode is enabled. Detailed logs will be shown.\")\n",
    "else:\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.info(\"DEBUG mode is disabled. Only essential logs will be shown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0476a6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd091fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import torch\n",
    "\n",
    "# We set up CUDA first to ensure it is configured correctly\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "if torch.cuda.is_available():\n",
    "    CUDA_DEVICE = torch.device(\"cuda:0\")\n",
    "    logger.info(f\"CUDA is available. Using device: {CUDA_DEVICE}\")\n",
    "else:\n",
    "    logger.error(\"CUDA is not available. Please check your PyTorch installation. Using CPU instead...this will be slow.\")\n",
    "    CUDA_DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.proj import load_projection_mat, reformat_sinogram, interpolate_projections, pad_and_reshape, divide_sinogram, undersample_projections, get_even_index\n",
    "from pipeline.aggregate_prj import aggregate_saved_projections\n",
    "from pipeline.aggregate_ct import aggregate_saved_recons\n",
    "from pipeline.apply_model import apply_model_to_projections, load_model, apply_model_to_recons\n",
    "from pipeline.utils import read_scans_agg_file, CTorchReconstruct\n",
    "from pipeline.paths import Directories, Files\n",
    "import scipy.io\n",
    "import matlab.engine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "import importlib\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d9f9e",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scans to convert to PyTorch tensors\n",
    "# Put None if you don't have any scans to convert\n",
    "# See the README for how to write this file correctly\n",
    "# NOTE: This will throw an error if the scan has already been converted\n",
    "#       If you would like to re-convert a scan,\n",
    "#       you can delete the file manually\n",
    "SCANS_CONVERT = 'txt_files/scans_convert_to_pt_liver.txt'\n",
    "# SCANS_CONVERT = None\n",
    "\n",
    "# Phase of the project (all data, models, etc. will be saved under this phase)\n",
    "PHASE = \"8\"\n",
    "\n",
    "# If this data version already exists in this phase, it will be loaded\n",
    "# Otherwise it will be created using whatever the most updated data creation script is\n",
    "DATA_VERSION = '03_liver'\n",
    "PANCREAS = False # Whether the data is pancreas\n",
    "LIVER = True # Whether the data is liver\n",
    "\n",
    "\n",
    "# Scans to use for training, val, and testing\n",
    "# You should set this even if you are not doing aggregation\n",
    "# See the README for how to write this file correctly\n",
    "# NOTE: This will NOT throw an error if there are already aggregated scans\n",
    "#       it will just give a warning and skip the aggregation step\n",
    "SCANS_AGG = 'txt_files/scans_to_agg_liver.txt'\n",
    "# SCANS_AGG = None\n",
    "\n",
    "# Whether to use even indices, too, for the projections\n",
    "USE_EVEN_INDICES = False\n",
    "\n",
    "# Reconstruction method ('CTorch' or 'matlab')\n",
    "RECON_METHOD = 'matlab'\n",
    "\n",
    "# Whether to augment the data for the image domain\n",
    "# This will only be used if you are doing image domain aggregation\n",
    "AUGMENT_ID = True\n",
    "\n",
    "# List of yaml files that contain configurations for the pipeline\n",
    "# Each file should contain the paramters for a specific model/ensemble\n",
    "CONFIG_FILES = [\n",
    "    \"config.yaml\",\n",
    "]\n",
    "\n",
    "# Base directory\n",
    "WORK_ROOT = \"D:/NoahSilverberg/ngCBCT\"\n",
    "\n",
    "# NSG_CBCT Path where the raw matlab data is stored\n",
    "# NSG_CBCT_PATH = \"D:/MitchellYu/NSG_CBCT\"\n",
    "\n",
    "# Directory with all files specific to this phase/data version\n",
    "PHASE_DATAVER_DIR = os.path.join(\n",
    "    WORK_ROOT, f\"phase{PHASE}\", f\"DS{DATA_VERSION}\"\n",
    ")\n",
    "\n",
    "DIRECTORIES = Directories(\n",
    "    mat_projections_dir=os.path.join(\"H:/Public/Noah/liver_prj_mat\"),\n",
    "    pt_projections_dir=os.path.join(\"H:/Public/Noah\", \"prj_pt_liver\"),\n",
    "    # projections_aggregate_dir=os.path.join(PHASE_DATAVER_DIR, \"aggregates\", \"projections\"),\n",
    "    projections_model_dir=os.path.join(f'H:\\Public/Noah/phase{PHASE}/DS01_panc', \"models\", \"projections\"),\n",
    "    projections_results_dir=os.path.join(f'H:\\Public/Noah/phase{PHASE}/DS{DATA_VERSION}', \"results\", \"projections\"),\n",
    "    projections_gated_dir=os.path.join(\"H:\\Public/Noah\", \"gated_liver\", \"prj_mat\"),\n",
    "    reconstructions_dir=os.path.join(f'H:\\Public/Noah/phase{PHASE}/DS{DATA_VERSION}', \"reconstructions\"),\n",
    "    reconstructions_gated_dir=os.path.join(\"H:\\Public/Noah\", \"gated_liver\", \"fdk_recon\" if RECON_METHOD == 'matlab' else \"ctorch_recon\"),\n",
    "    # pl_reconstructions_dir=os.path.join(\"H:\\Public/Noah\", \"gated\", \"pl_recon\", 'HF'),\n",
    "    # images_aggregate_dir=os.path.join(PHASE_DATAVER_DIR, \"aggregates\", \"images\"),\n",
    "    images_model_dir=os.path.join(f'H:\\Public/Noah/phase{PHASE}/DS01_panc', \"models\", \"images\"),\n",
    "    images_results_dir=os.path.join(f'H:\\Public/Noah/phase{PHASE}/DS{DATA_VERSION}', \"results\", \"images\"),\n",
    "    # error_results_dir= os.path.join(f'H:\\Public/Noah/phase{PHASE}/DS{DATA_VERSION}', \"results\", \"error_results\"),\n",
    ")\n",
    "\n",
    "FILES = Files(DIRECTORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b49a2c",
   "metadata": {},
   "source": [
    "# Data Preparation: projection interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCANS_CONVERT is not None:\n",
    "    # Read the scans to convert file\n",
    "    with open(SCANS_CONVERT, \"r\") as f:\n",
    "        SCANS_CONVERT = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            patient, scan, scan_type = line.split()\n",
    "            SCANS_CONVERT.append((patient, scan, scan_type))\n",
    "\n",
    "    logger.debug(f\"Loaded scan list for conversion: {SCANS_CONVERT}\")\n",
    "\n",
    "    logger.info(\"Starting to process projection data...\")\n",
    "\n",
    "    for patient, scan, scan_type in SCANS_CONVERT:\n",
    "        for odd in [True, False] if USE_EVEN_INDICES else [True]:\n",
    "            g_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=True)\n",
    "            ng_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=False, odd=odd)\n",
    "\n",
    "            # Make sure the files do not already exist\n",
    "            if os.path.exists(ng_path):\n",
    "                logger.warning(f\"Projection files already exist for patient {patient}, scan {scan}, type {scan_type}. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Load the projection data from the matlab files\n",
    "            mat_path = FILES.get_projection_mat_filepath(patient, scan, scan_type, PANCREAS, LIVER)\n",
    "            odd_index, angles, prj = load_projection_mat(mat_path)\n",
    "\n",
    "            # Log shapes of loaded data\n",
    "            logger.debug(f'Processing patient {patient}, scan {scan}, type {scan_type}')\n",
    "            logger.debug(f'Loaded odd_index shape: {odd_index.shape}')\n",
    "            logger.debug(f'Loaded angles shape: {angles.shape}')\n",
    "            logger.debug(f'Loaded projection shape: {prj.shape}')\n",
    "\n",
    "            # Flip and permute to get it in the right format\n",
    "            prj_gcbct, angles1, _ = reformat_sinogram(prj, angles)\n",
    "\n",
    "            # Log shapes after reformatting\n",
    "            logger.debug(f'Reformatted projection shape: {prj_gcbct.shape}')\n",
    "\n",
    "            # Simulate ngCBCT projections\n",
    "            prj_ngcbct_li = interpolate_projections(prj_gcbct, odd_index, odd=odd)\n",
    "\n",
    "            # Log shapes after interpolation\n",
    "            logger.debug(f'Interpolated ngCBCT projection shape: {prj_ngcbct_li.shape}')\n",
    "\n",
    "            # Split the projections into two halves so they are good dimensions for the CNN\n",
    "            patches = 3 if scan_type == 'FF' and prj_gcbct.shape[0] > 520 else 2\n",
    "            logger.debug(f'Splitting projections into {patches}')\n",
    "            combined_gcbct = divide_sinogram(pad_and_reshape(prj_gcbct), v_dim=512 if scan_type == \"HF\" else 256, patches=patches)\n",
    "            combined_ngcbct = divide_sinogram(pad_and_reshape(prj_ngcbct_li), v_dim=512 if scan_type == \"HF\" else 256, patches=patches)\n",
    "\n",
    "            # Log shapes after dividing sinograms\n",
    "            logger.debug(f'Combined gCBCT shape: {combined_gcbct.shape}')\n",
    "            logger.debug(f'Combined ngCBCT shape: {combined_ngcbct.shape}')\n",
    "\n",
    "            logger.debug(f'Saving projections...')\n",
    "            \n",
    "            # Save the projections\n",
    "            torch.save(combined_gcbct, g_path)\n",
    "            torch.save(combined_ngcbct, ng_path)\n",
    "\n",
    "            logger.debug(f'Done with patient {patient}, scan {scan}, type {scan_type}\\n')\n",
    "\n",
    "    logger.info(\"All projections saved successfully.\")\n",
    "\n",
    "    # Free up memory\n",
    "    try:\n",
    "        del odd_index, angles, prj, prj_gcbct, angles1, prj_ngcbct_li, combined_gcbct, combined_ngcbct\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    logger.info(\"No scans to convert. Skipping projection data processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23247d",
   "metadata": {},
   "source": [
    "### DEBUG: Sample projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b21297",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG and SCANS_CONVERT is not None:\n",
    "    # Pick the first HF scan and first FF scan\n",
    "    hf_scan = None\n",
    "    ff_scan = None\n",
    "    for patient, scan, scan_type in SCANS_CONVERT:\n",
    "        if scan_type == \"HF\":\n",
    "            hf_scan = (patient, scan, scan_type)\n",
    "            break\n",
    "    for patient, scan, scan_type in SCANS_CONVERT:\n",
    "        if scan_type == \"FF\":\n",
    "            ff_scan = (patient, scan, scan_type)\n",
    "            break\n",
    "\n",
    "    # Display the first HF scan\n",
    "    # Show the gated and nonstop-gated on subplots\n",
    "    if hf_scan:\n",
    "        if USE_EVEN_INDICES:\n",
    "            hf_patient, hf_scan_num, hf_scan_type = hf_scan\n",
    "            g_path = FILES.get_projection_pt_filepath(hf_patient, hf_scan_num, hf_scan_type, gated=True)\n",
    "            ng_path_odd = FILES.get_projection_pt_filepath(hf_patient, hf_scan_num, hf_scan_type, gated=False, odd=True)\n",
    "            ng_path_even = FILES.get_projection_pt_filepath(hf_patient, hf_scan_num, hf_scan_type, gated=False, odd=False)\n",
    "            hf_gated_prj = torch.load(g_path)\n",
    "            hf_ng_prj_odd = torch.load(ng_path_odd)\n",
    "            hf_ng_prj_even = torch.load(ng_path_even)\n",
    "            plt.figure(figsize=(18, 6))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(hf_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(hf_ng_prj_odd[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Odd Nonstop-Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(hf_ng_prj_even[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Even Nonstop-Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Also plot a difference map between odd/gated and even/gated, but set all non-zero differences to 1\n",
    "            diff_map_odd = np.abs(hf_ng_prj_odd[0, 0, :, :].cpu().numpy() - hf_gated_prj[0, 0, :, :].cpu().numpy())\n",
    "            diff_map_even = np.abs(hf_ng_prj_even[0, 0, :, :].cpu().numpy() - hf_gated_prj[0, 0, :, :].cpu().numpy())\n",
    "            diff_map_odd[diff_map_odd > 0] = 1  # Set all non-zero differences to 1\n",
    "            diff_map_even[diff_map_even > 0] = 1  # Set all non-zero differences to 1\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(diff_map_odd, cmap='gray')\n",
    "            plt.title(f'Difference Map (Odd) - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(diff_map_even, cmap='gray')\n",
    "            plt.title(f'Difference Map (Even) - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            # Free up memory\n",
    "            del hf_gated_prj, hf_ng_prj_odd, hf_ng_prj_even\n",
    "        else:\n",
    "            hf_patient, hf_scan_num, hf_scan_type = hf_scan\n",
    "            g_path = FILES.get_projection_pt_filepath(hf_patient, hf_scan_num, hf_scan_type, gated=True)\n",
    "            ng_path = FILES.get_projection_pt_filepath(hf_patient, hf_scan_num, hf_scan_type, gated=False, odd=False)\n",
    "            hf_gated_prj = torch.load(g_path)\n",
    "            hf_ng_prj = torch.load(ng_path)\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(hf_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(hf_ng_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Nonstop-Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Free up memory\n",
    "            del hf_gated_prj, hf_ng_prj\n",
    "\n",
    "    # Repeat for FF scan\n",
    "    if ff_scan:\n",
    "        if USE_EVEN_INDICES:\n",
    "            ff_patient, ff_scan_num, ff_scan_type = ff_scan\n",
    "            g_path = FILES.get_projection_pt_filepath(ff_patient, ff_scan_num, ff_scan_type, gated=True)\n",
    "            ng_path_odd = FILES.get_projection_pt_filepath(ff_patient, ff_scan_num, ff_scan_type, gated=False, odd=True)\n",
    "            ng_path_even = FILES.get_projection_pt_filepath(ff_patient, ff_scan_num, ff_scan_type, gated=False, odd=False)\n",
    "            ff_gated_prj = torch.load(g_path)\n",
    "            ff_ng_prj_odd = torch.load(ng_path_odd)\n",
    "            ff_ng_prj_even = torch.load(ng_path_even)\n",
    "            plt.figure(figsize=(18, 6))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(ff_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(ff_ng_prj_odd[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Odd Nonstop-Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(ff_ng_prj_even[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Even Nonstop-Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Also plot a difference map between odd/gated and even/gated\n",
    "            diff_map_odd = np.abs(ff_ng_prj_odd[0, 0, :, :].cpu().numpy() - ff_gated_prj[0, 0, :, :].cpu().numpy())\n",
    "            diff_map_even = np.abs(ff_ng_prj_even[0, 0, :, :].cpu().numpy() - ff_gated_prj[0, 0, :, :].cpu().numpy())\n",
    "            diff_map_odd[diff_map_odd > 0] = 1  # Set all non-zero differences to 1\n",
    "            diff_map_even[diff_map_even > 0] = 1  # Set all non-zero differences to 1\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(diff_map_odd, cmap='gray')\n",
    "            plt.title(f'Difference Map (Odd) - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(diff_map_even, cmap='gray')\n",
    "            plt.title(f'Difference Map (Even) - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Free up memory\n",
    "            del ff_gated_prj, ff_ng_prj_odd, ff_ng_prj_even\n",
    "        else:\n",
    "            ff_patient, ff_scan_num, ff_scan_type = ff_scan\n",
    "            g_path = FILES.get_projection_pt_filepath(ff_patient, ff_scan_num, ff_scan_type, gated=True)\n",
    "            ng_path = FILES.get_projection_pt_filepath(ff_patient, ff_scan_num, ff_scan_type, gated=False, odd=False)\n",
    "            ff_gated_prj = torch.load(g_path)\n",
    "            ff_ng_prj = torch.load(ng_path)\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(ff_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(ff_ng_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "            plt.title(f'Nonstop-Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Free up memory\n",
    "        del ff_gated_prj, ff_ng_prj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e695f",
   "metadata": {},
   "source": [
    "# Aggregate projections for train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCANS_AGG is not None:\n",
    "    scans_agg, scan_type = read_scans_agg_file(SCANS_AGG)\n",
    "    logger.debug(f\"Loaded scan list for aggregation: {scans_agg}\")\n",
    "\n",
    "    # Only aggregate projections if they don't already exist\n",
    "    agg_dir = DIRECTORIES.projections_aggregate_dir\n",
    "    if agg_dir is None:\n",
    "        logger.warning(\"No aggregation directory specified. Skipping projection data aggregation.\")\n",
    "    elif len(os.listdir(agg_dir)) > 0:\n",
    "        logger.warning(f\"Aggregated projection data already exists in {agg_dir}. Skipping...\")\n",
    "    else:\n",
    "        logger.info(\"Starting to aggregate projection data...\")\n",
    "        \n",
    "        # Aggregate and save projection data sets\n",
    "        for split in ['TRAIN', 'VALIDATION']:\n",
    "            if len(scans_agg[split]) > 0:\n",
    "                ng_paths = [FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=False, odd=True) for patient, scan, scan_type in scans_agg[split]]\n",
    "                if USE_EVEN_INDICES:\n",
    "                    ng_paths += [FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=False, odd=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                ng_agg_path = FILES.get_projections_aggregate_filepath(split, gated=False)\n",
    "                aggregate_saved_projections(ng_paths, ng_agg_path)\n",
    "                logger.debug(\"Done with nonstop-gated...\")\n",
    "                g_paths = [FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=True) for patient, scan, scan_type in scans_agg[split]]\n",
    "                if USE_EVEN_INDICES:\n",
    "                    g_paths *= 2\n",
    "                g_agg_path = FILES.get_projections_aggregate_filepath(split, gated=True)\n",
    "                aggregate_saved_projections(g_paths, g_agg_path)\n",
    "                logger.debug(\"Done with gated...\")\n",
    "\n",
    "                logger.debug(f\"Aggregated projections saved for {scan_type} {split}.\\n\")\n",
    "            else:\n",
    "                logger.debug(f\"No scans to aggregate for {scan_type} {split}. Skipping aggregation.\")\n",
    "\n",
    "        logger.info(\"Projection data aggregation completed successfully.\")\n",
    "        logger.info(\"Aggregated projection data saved in: %s\", agg_dir)\n",
    "else:\n",
    "    logger.info(\"No scans to aggregate. Skipping projection data aggregation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae3e79",
   "metadata": {},
   "source": [
    "# Training PD CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daead9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_file in CONFIG_FILES:\n",
    "    # Load the yaml configuration file\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "    # Skip this config if the user has set PD_training to False\n",
    "    if not config['PD_settings']['training']:\n",
    "        logger.info(f\"Skipping PD training for {config_file} as PD training is set to False.\")\n",
    "        continue\n",
    "\n",
    "    # Get the training application\n",
    "    module_name, class_name = config['PD_settings']['training_app'].rsplit('.', 1)\n",
    "    module = importlib.import_module(\"pipeline.\" + module_name)\n",
    "    cls = getattr(module, class_name)\n",
    "\n",
    "    logger.debug(f\"Loaded class {class_name} from module {module_name}\")\n",
    "\n",
    "    # Get the model version (for naming purposes)\n",
    "    model_version = config['PD_settings']['model_version']\n",
    "\n",
    "    # Get the ensemble size, and loop through it\n",
    "    ensemble_size = config['PD_settings']['ensemble_size']\n",
    "    for i in range(ensemble_size):\n",
    "        # If we are training an ensemble, we add an identifier to the model version\n",
    "        if ensemble_size > 1:\n",
    "            # Deepcopy config so we don't affect the original\n",
    "            cfg = copy.deepcopy(config)\n",
    "            cfg['PD_settings']['model_version'] = f\"{model_version}_{i+1:02}\" # e.g., \"v1_01\"\n",
    "        else:\n",
    "            cfg = config\n",
    "\n",
    "        # Add the data version to the configuration\n",
    "        cfg['PD_settings']['data_version'] = DATA_VERSION\n",
    "\n",
    "        checkpoint = FILES.get_model_filepath(model_version=cfg['PD_settings']['model_version'], domain='PROJ', checkpoint=cfg['PD_settings']['start_checkpoint'], ensure_exists=False)\n",
    "        if cfg['PD_settings']['start_checkpoint'] is not None and os.path.exists(checkpoint):\n",
    "            checkpoint = torch.load(checkpoint)\n",
    "            epoch = checkpoint['epoch']\n",
    "            state_dict = checkpoint['state_dict']\n",
    "            optimizer = checkpoint['optimizer']\n",
    "\n",
    "        #     logger.info(f\"Resuming training from epoch {epoch} for model version {cfg['PD_settings']['model_version']}...\")\n",
    "\n",
    "        #     # Instantiate with the loaded configuration\n",
    "        #     instance = cls(cfg, \"PROJ\", DEBUG, FILES, epoch, optimizer, state_dict)\n",
    "        # else:\n",
    "        #     logger.info(f\"Starting training from scratch for model version {cfg['PD_settings']['model_version']}...\")\n",
    "        #     instance = cls(cfg, \"PROJ\", DEBUG, FILES)\n",
    "\n",
    "        # Instantiate with the loaded configuration\n",
    "        instance = cls(cfg, \"PROJ\", DEBUG, FILES)\n",
    "\n",
    "        logger.info(f\"Going to try training the {i + 1}-th model with configuration from {config_file}...\")\n",
    "\n",
    "        # Run the training\n",
    "        instance.main()\n",
    "\n",
    "        logger.info(f\"Finished training the {i + 1}-th model.\\n\")\n",
    "\n",
    "        del instance, cfg\n",
    "        gc.collect()\n",
    "\n",
    "    # Free up memory\n",
    "    del module, cls, config, module_name, class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb52db",
   "metadata": {},
   "source": [
    "# Apply PD model and FDK to all scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba6ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCANS_AGG is None:\n",
    "    logger.info(\"Skipping model application as the aggregation scan list is not provided.\")\n",
    "else:\n",
    "    if RECON_METHOD == 'matlab':\n",
    "        eng = matlab.engine.start_matlab()\n",
    "\n",
    "        matlab_script_path = 'D:/NoahSilverberg/CudaRecon'\n",
    "        cuda_tools = r'D:\\NoahSilverberg\\CudaTools'\n",
    "        matlab_functions = r'D:\\NoahSilverberg\\CommonMatlabFunctions_HZ'\n",
    "\n",
    "        eng.addpath(cuda_tools, nargout=0)\n",
    "        eng.addpath(matlab_functions, nargout=0)\n",
    "        eng.addpath(matlab_script_path, nargout=0)\n",
    "\n",
    "    # Loop through the configurations again\n",
    "    for config_file in CONFIG_FILES:\n",
    "        # Load the yaml configuration file\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "\n",
    "        logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "        # Get the ensemble size, and loop through it\n",
    "        ensemble_size = config['PD_settings']['ensemble_size']\n",
    "        for i in range(ensemble_size):\n",
    "            model_version = config['PD_settings']['model_version']\n",
    "\n",
    "            # If we are training an ensemble, we add an identifier to the model version\n",
    "            if ensemble_size > 1:\n",
    "                model_version = f\"{model_version}_{i+1:02}\"\n",
    "\n",
    "            # Load the trained PD model onto the GPU\n",
    "            model_path = FILES.get_model_filepath(model_version, \"PROJ\")\n",
    "            PD_model = load_model(config['PD_settings']['network_name'], config['PD_settings']['network_kwargs'], model_path, CUDA_DEVICE)\n",
    "\n",
    "            passthrough_count = config['PD_settings']['passthrough_count']\n",
    "\n",
    "            scans_agg, scan_type = read_scans_agg_file(SCANS_AGG)\n",
    "            if scan_type != config['PD_settings']['scan_type']:\n",
    "                raise ValueError(f\"Scan type in aggregation file ({scan_type}) does not match scan type in config ({config['PD_settings']['scan_type']}).\")\n",
    "            \n",
    "            for split in ['TRAIN', 'VALIDATION', 'TEST']:\n",
    "                for patient, scan, scan_type in tqdm(scans_agg[split], desc=f\"Applying model {model_version} to projections split {split}\"):\n",
    "                    # Get the matlab dict for the nonstop-gated projections\n",
    "                    mat_path = FILES.get_projection_mat_filepath(patient, scan, scan_type, PANCREAS, LIVER)\n",
    "\n",
    "                    # Get the acquired nonstop-gated projections, indices, and angles from the .mat file\n",
    "                    odd_index, angles, prj = load_projection_mat(mat_path)\n",
    "\n",
    "                    # Flip and permute to get it in the right format\n",
    "                    prj_gcbct_, angles1, flipped = reformat_sinogram(prj, angles)\n",
    "\n",
    "                    for odd in [True, False] if USE_EVEN_INDICES else [True]:\n",
    "\n",
    "                        # Simulate ngCBCT projections\n",
    "                        prj_ngcbct_li_ = interpolate_projections(prj_gcbct_.detach(), odd_index, odd=odd)\n",
    "\n",
    "                        # Reformat the projections to be in the right shape for the CNN\n",
    "                        prj_gcbct = pad_and_reshape(prj_gcbct_).detach()\n",
    "                        prj_ngcbct_li = pad_and_reshape(prj_ngcbct_li_).detach()\n",
    "\n",
    "                        for passthrough_num in range(passthrough_count):\n",
    "                        \n",
    "                            # Save paths for the the ground truth, CNN-processed, and nonstop-gated projections\n",
    "                            cnn_path = FILES.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=False, odd=odd, passthrough_num=passthrough_num if passthrough_count > 1 else None)\n",
    "                            g_recon_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type, gated=True, odd=odd)\n",
    "                            cnn_recon_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type, gated=False, odd=odd, passthrough_num=passthrough_num if passthrough_count > 1 else None)\n",
    "                            nsg_recon_path = FILES.get_recon_filepath('nsg', patient, scan, scan_type, gated=False, odd=odd)\n",
    "                            raw_recon_path = FILES.get_recon_filepath('raw', patient, scan, scan_type, gated=False, odd=odd)\n",
    "\n",
    "                            # For training we only save the reconstructions\n",
    "                            if split == 'TRAIN'and os.path.exists(cnn_recon_path):\n",
    "                                logger.info(f\"CNN projections and reconstructions already exist for {scan_type} p{patient}_{scan} for model {model_version}. Skipping...\")\n",
    "                                continue\n",
    "\n",
    "                            # For validation and testing we save both projections and reconstructions\n",
    "                            if split != 'TRAIN' and os.path.exists(cnn_recon_path): # and os.path.exists(cnn_path):\n",
    "                                logger.info(f\"CNN projections and reconstructions already exist for {scan_type} p{patient}_{scan} for model {model_version}. Skipping...\")\n",
    "                                continue\n",
    "\n",
    "                            if os.path.exists(cnn_path):\n",
    "                                cnn_mat = scipy.io.loadmat(cnn_path)\n",
    "                                if split == 'TRAIN':\n",
    "                                    os.remove(cnn_path)  # Remove the .mat file to save space\n",
    "\n",
    "                                logger.debug(f\"Loaded existing CNN projections for {scan_type} p{patient}_{scan} from {cnn_path}.\")\n",
    "                            else:\n",
    "                                g_mat, cnn_mat = apply_model_to_projections(PD_model, scan_type, odd_index, angles, prj_gcbct, prj_ngcbct_li, odd, CUDA_DEVICE, train_at_inference=config['PD_settings']['train_at_inference'], _batch_size=16)\n",
    "                                logger.debug(f\"Applied model {model_version} to projections for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                                # NOTE: Uncomment this is you want to save the CNN output projections\n",
    "                                #       these take up a lot of space and we don't really need them typically...so I commented it out\n",
    "                                # if split != 'TRAIN':\n",
    "                                #     scipy.io.savemat(cnn_path, cnn_mat)\n",
    "                                #     logger.debug(f\"Saved CNN projections for {scan_type} p{patient}_{scan} to {cnn_path}.\")\n",
    "\n",
    "                            # We only need to do & save FDK recons once\n",
    "                            if not os.path.exists(g_recon_path):   \n",
    "                                if RECON_METHOD == 'matlab':\n",
    "                                    prj_ = matlab.single(g_mat['prj'].astype(np.float32))\n",
    "                                    angles_ = matlab.single(g_mat['angles'].astype(np.float32))\n",
    "                                    del g_mat\n",
    "                                    if scan_type == \"HF\":\n",
    "                                        g_fdk = np.array(eng.HFrecon_nsFDK(prj_, angles_, nargout=1))\n",
    "                                    else:\n",
    "                                        g_fdk = np.array(eng.FFrecon_reconFDK(prj_, angles_, nargout=1))\n",
    "                                    del prj_, angles_\n",
    "\n",
    "                                    # Convert to Pytorch tensor\n",
    "                                    g_fdk = torch.from_numpy(g_fdk).detach()\n",
    "                                    g_fdk = torch.permute(g_fdk, (2, 0, 1))\n",
    "                                elif RECON_METHOD == 'CTorch':\n",
    "                                    g_fdk = CTorchReconstruct(torch.flip(torch.from_numpy(g_mat['prj'].copy()), (0, 2) if flipped else (2,)), angles - np.pi/2, scan_type, CUDA_DEVICE)\n",
    "                                else:\n",
    "                                    raise ValueError(f\"Unknown reconstruction method: {RECON_METHOD}\")\n",
    "\n",
    "                                if scan_type == \"FF\":\n",
    "                                    g_fdk = g_fdk[:, 128:-128, 128:-128].clone()\n",
    "                                \n",
    "                                # Save the recon results as .pt\n",
    "                                torch.save(g_fdk, g_recon_path)\n",
    "                                del g_fdk\n",
    "                                logger.debug(f\"Saved gated reconstruction for {scan_type} p{patient}_{scan} to {g_recon_path}.\")\n",
    "                            else:\n",
    "                                logger.debug(f\"Gated reconstruction already exists for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                            # We only need to do & save FDK recons once\n",
    "                            if not os.path.exists(raw_recon_path) and split != 'TRAIN':\n",
    "                                if not odd:\n",
    "                                    odd_index = get_even_index(odd_index, prj_gcbct_.shape[0]) # NOTE: this is actually even indices now\n",
    "                                if RECON_METHOD == 'matlab': \n",
    "                                    raw_prj = undersample_projections(prj_gcbct_, odd_index)[0]\n",
    "                                    raw_prj = raw_prj.contiguous()\n",
    "                                    prj_ = matlab.single(raw_prj[odd_index.astype(np.int64) - 1].numpy().astype(np.float32))\n",
    "                                    del raw_prj\n",
    "                                    angles_ = matlab.single(angles1[odd_index.astype(np.int64) - 1].numpy().astype(np.float32))\n",
    "                                    if scan_type == \"HF\":\n",
    "                                        raw_fdk = np.array(eng.HFrecon_nsFDK(prj_, angles_, nargout=1))\n",
    "                                    else:\n",
    "                                        raw_fdk = np.array(eng.FFrecon_reconFDK(prj_, angles_, nargout=1))\n",
    "                                    del prj_, angles_\n",
    "\n",
    "                                    # Convert to Pytorch tensor\n",
    "                                    raw_fdk = torch.from_numpy(raw_fdk).detach()\n",
    "                                    raw_fdk = torch.permute(raw_fdk, (2, 0, 1))\n",
    "                                elif RECON_METHOD == 'CTorch':\n",
    "                                    raw_fdk = CTorchReconstruct(torch.flip(prj_gcbct_[odd_index.astype(np.int64) - 1], (0, 2) if flipped else (2,)), (torch.flip(torch.flip(angles, (0,))[odd_index.astype(np.int64) - 1], (0,)) if flipped else angles[odd_index.astype(np.int64) - 1]) - np.pi/2, scan_type, CUDA_DEVICE)\n",
    "\n",
    "                                if scan_type == \"FF\":\n",
    "                                    raw_fdk = raw_fdk[:, 128:-128, 128:-128].clone()\n",
    "                                \n",
    "                                # Save the recon results as .pt\n",
    "                                torch.save(raw_fdk, raw_recon_path)\n",
    "                                del raw_fdk\n",
    "                                logger.debug(f\"Saved raw reconstruction for {scan_type} p{patient}_{scan} to {raw_recon_path}.\")\n",
    "                            else:\n",
    "                                logger.debug(f\"Raw reconstruction already exists for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                            # # NOTE: This only needs to be done if you are using an auxiliary model for error prediction -- otherwise it's not needed\n",
    "                            # # We only need to do & save FDK recons once\n",
    "                            # if not os.path.exists(nsg_recon_path):\n",
    "                            #     if RECON_METHOD == 'matlab':\n",
    "                            #         prj_ = matlab.single(prj_ngcbct_li_.numpy().astype(np.float32))\n",
    "                            #         angles_ = matlab.single(angles1.numpy().astype(np.float32))\n",
    "                            #         if scan_type == \"HF\":\n",
    "                            #             nsg_fdk = np.array(eng.HFrecon_nsFDK(prj_, angles_, nargout=1))\n",
    "                            #         else:\n",
    "                            #             nsg_fdk = np.array(eng.FFrecon_reconFDK(prj_, angles_, nargout=1))\n",
    "                            #         del prj_, angles_\n",
    "\n",
    "                            #         # Convert to Pytorch tensor\n",
    "                            #         nsg_fdk = torch.from_numpy(nsg_fdk).detach()\n",
    "                            #         nsg_fdk = torch.permute(nsg_fdk, (2, 0, 1))\n",
    "                            #     elif RECON_METHOD == 'CTorch':\n",
    "                            #         nsg_fdk = CTorchReconstruct(torch.flip(prj_ngcbct_li_, (0, 2) if flipped else (2,)), angles - np.pi/2, scan_type, CUDA_DEVICE)\n",
    "\n",
    "                            #     if scan_type == \"FF\":\n",
    "                            #         nsg_fdk = nsg_fdk[:, 128:-128, 128:-128].clone()\n",
    "                                \n",
    "                            #     # Save the recon results as .pt\n",
    "                            #     torch.save(nsg_fdk, nsg_recon_path)\n",
    "                            #     del nsg_fdk\n",
    "                            #     logger.debug(f\"Saved nonstop-gated reconstruction for {scan_type} p{patient}_{scan} to {nsg_recon_path}.\")\n",
    "                            # else:\n",
    "                            #     logger.debug(f\"Nonstop-gated reconstruction already exists for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                            # We only need to do & save FDK recons once\n",
    "                            if not os.path.exists(cnn_recon_path):\n",
    "                                if RECON_METHOD == 'matlab':\n",
    "                                    prj_ = matlab.single(cnn_mat['prj'].astype(np.float32))\n",
    "                                    angles_ = matlab.single(cnn_mat['angles'].astype(np.float32))\n",
    "                                    del cnn_mat\n",
    "                                    if scan_type == \"HF\":\n",
    "                                        cnn_fdk = np.array(eng.HFrecon_nsFDK(prj_, angles_, nargout=1))\n",
    "                                    else:\n",
    "                                        cnn_fdk = np.array(eng.FFrecon_reconFDK(prj_, angles_, nargout=1))\n",
    "                                    del prj_, angles_\n",
    "\n",
    "                                    # Convert to Pytorch tensor\n",
    "                                    cnn_fdk = torch.from_numpy(cnn_fdk).detach()\n",
    "                                    cnn_fdk = torch.permute(cnn_fdk, (2, 0, 1))\n",
    "                                elif RECON_METHOD == 'CTorch':\n",
    "                                    cnn_fdk = CTorchReconstruct(torch.flip(torch.from_numpy(cnn_mat['prj'].copy()), (0, 2) if flipped else (2,)), angles - np.pi/2, scan_type, CUDA_DEVICE)\n",
    "                                    del cnn_mat\n",
    "\n",
    "                                if scan_type == \"FF\":\n",
    "                                    cnn_fdk = cnn_fdk[:, 128:-128, 128:-128].clone()\n",
    "\n",
    "                                # Save the recon results as .pt\n",
    "                                torch.save(cnn_fdk, cnn_recon_path)\n",
    "                                logger.debug(f\"Saved CNN reconstruction for {scan_type} p{patient}_{scan} to {cnn_recon_path} with shape {cnn_fdk.shape}.\")\n",
    "                                del cnn_fdk\n",
    "                            else:\n",
    "                                logger.debug(f\"CNN reconstruction already exists for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                            logger.debug(f\"Saved projections for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                        del prj_gcbct, prj_ngcbct_li, prj_ngcbct_li_\n",
    "\n",
    "                    del odd_index, angles, prj, prj_gcbct_, angles1\n",
    "\n",
    "            # Free up memory\n",
    "            del PD_model\n",
    "\n",
    "    if RECON_METHOD == 'matlab':\n",
    "        eng.quit()\n",
    "\n",
    "    logger.info(\"All models applied to projections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09b672",
   "metadata": {},
   "source": [
    "# Aggregate CT volumes for train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCANS_AGG is not None:\n",
    "    scans_agg, scan_type = read_scans_agg_file(SCANS_AGG)\n",
    "    logger.debug(f\"Loaded scan list for aggregation: {scans_agg}\")\n",
    "\n",
    "    for config_file in CONFIG_FILES:\n",
    "\n",
    "        # Load the yaml configuration file\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        \n",
    "        logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "        # Skip if they want on-the-fly aggregation\n",
    "        if config['ID_settings']['augmented_id_training_set']:\n",
    "            logger.warning(f\"Skipping reconstruction data aggregation for {config_file} as on-the-fly aggregation is enabled.\")\n",
    "            continue\n",
    "\n",
    "        # Get the ensemble size, and loop through it\n",
    "        ensemble_size = config['ID_settings']['ensemble_size']\n",
    "\n",
    "        # If the input type is a dict, we assume it is an error-predicting auxiliary model\n",
    "        # The input type is of the form {'PD': ['v1', 10], 'ID': ['v2', 1]}\n",
    "        error = isinstance(config['ID_settings']['input_type'], dict)\n",
    "\n",
    "        # For simplicity, we only allow one ensemble size for error-predicting auxiliary models\n",
    "        # There's really not much point in using an ensemble for this\n",
    "        if ensemble_size > 1 and error:\n",
    "            raise ValueError(\"For error-predicting auxiliary models, please use an ensemble size of 1.\")\n",
    "\n",
    "        for i in range(ensemble_size):\n",
    "            # If we are training an ensemble, we add an identifier to the model version\n",
    "            if ensemble_size > 1 and config['ID_settings']['input_type_match_ensemble']:\n",
    "                input_type = f\"{config['ID_settings']['input_type']}_{i+1:02}\" # e.g., \"v1_01\"\n",
    "            else:\n",
    "                input_type = config['ID_settings']['input_type']\n",
    "\n",
    "            # Only aggregate reconstructions if they don't already exist\n",
    "            agg_dir = DIRECTORIES.get_images_aggregate_dir(input_type['ID'][0] if error else input_type)\n",
    "            if len(os.listdir(agg_dir)) > 0:\n",
    "                logger.warning(f\"Aggregated reconstruction data already exists in {os.path.dirname(agg_dir)}. Skipping...\")\n",
    "            else:\n",
    "                logger.info(\"Starting to aggregate reconstruction data...\")\n",
    "\n",
    "                # Aggregate and save reconstruction data sets\n",
    "                for split in ['TRAIN', 'VALIDATION']:\n",
    "                    ng_agg_path = FILES.get_images_aggregate_filepath(input_type['ID'][0] if error else input_type, split, truth=False, error=error)\n",
    "                    if len(scans_agg[split]) > 0:\n",
    "                        if error:\n",
    "                            if input_type['PD'][1] == 1 and input_type['ID'][1] == 1:\n",
    "                                ng_paths = []\n",
    "\n",
    "                                # Get the nonstop-gated reconstruction paths\n",
    "                                ng_paths.append([FILES.get_recon_filepath('nsg', patient, scan, scan_type, gated=False, odd=True) for patient, scan, scan_type in scans_agg[split]])\n",
    "\n",
    "                                # Get the PD model reconstruction paths\n",
    "                                ng_paths.append([FILES.get_recon_filepath(input_type['PD'][0], patient, scan, scan_type, gated=False, odd=True) for patient, scan, scan_type in scans_agg[split]])\n",
    "\n",
    "                                # Get the ID model reconstruction paths\n",
    "                                ng_paths.append([FILES.get_images_results_filepath(input_type['ID'][0], patient, scan, odd=True) for patient, scan, scan_type in scans_agg[split]])\n",
    "                            \n",
    "                                if USE_EVEN_INDICES:\n",
    "                                    ng_paths[0] += [FILES.get_recon_filepath('nsg', patient, scan, scan_type, gated=False, odd=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                                    ng_paths[1] += [FILES.get_recon_filepath(input_type['PD'][0], patient, scan, scan_type, gated=False, odd=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                                    ng_paths[2] += [FILES.get_images_results_filepath(input_type['ID'][0], patient, scan, odd=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                            else:\n",
    "                                logger.warning(f\"Skipping aggregation for error-predicting auxiliary model since passthrough count is greater than 1. Please use on-the-fly aggregation during training instead.\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            ng_paths = [FILES.get_recon_filepath(input_type, patient, scan, scan_type, gated=False, odd=True) for patient, scan, scan_type in scans_agg[split]]\n",
    "                            if USE_EVEN_INDICES:\n",
    "                                ng_paths += [FILES.get_recon_filepath(input_type, patient, scan, scan_type, gated=False, odd=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                        \n",
    "                        aggregate_saved_recons(ng_paths, ng_agg_path, scan_type)\n",
    "                        logger.debug(\"Done with nonstop-gated...\")\n",
    "\n",
    "                        g_agg_path = FILES.get_images_aggregate_filepath(input_type['ID'][0] if error else 'fdk', split, truth=True, error=error)\n",
    "                        if os.path.exists(g_agg_path):\n",
    "                            logger.warning(f\"Gated aggregation file {g_agg_path} already exists. Skipping aggregation for gated data.\")\n",
    "                            continue\n",
    "                        \n",
    "                        if error:\n",
    "                            g_paths = []\n",
    "\n",
    "                            # Get the ID model reconstruction paths\n",
    "                            g_paths.append([FILES.get_images_results_filepath(input_type['ID'][0], patient, scan, odd=True) for patient, scan, scan_type in scans_agg[split]])\n",
    "\n",
    "                            # Get the gated reconstruction paths\n",
    "                            g_paths.append([FILES.get_recon_filepath(None, patient, scan, scan_type, gated=True, odd=True) for patient, scan, scan_type in scans_agg[split]])\n",
    "\n",
    "                            if USE_EVEN_INDICES:\n",
    "                                g_paths[0] += [FILES.get_images_results_filepath(input_type['ID'][0], patient, scan, odd=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                                g_paths[1] += [FILES.get_recon_filepath(None, patient, scan, scan_type, gated=True, odd=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                        else:\n",
    "                            g_paths = [FILES.get_recon_filepath(None, patient, scan, scan_type, gated=True) for patient, scan, scan_type in scans_agg[split]]\n",
    "                            if USE_EVEN_INDICES:\n",
    "                                g_paths *= 2\n",
    "                                \n",
    "                        aggregate_saved_recons(g_paths, g_agg_path, scan_type, compute_errors=error)\n",
    "                        logger.debug(\"Done with gated...\")\n",
    "\n",
    "                        logger.debug(f\"Aggregated reconstructions saved for {scan_type} {split}.\\n\")\n",
    "                    else:\n",
    "                        logger.debug(f\"No scans to aggregate for {scan_type} {split}. Skipping aggregation.\")\n",
    "\n",
    "            logger.info(\"Reconstruction data aggregation completed successfully.\")\n",
    "            logger.info(\"Aggregated reconstruction data saved in: %s\", agg_dir)\n",
    "else:\n",
    "    logger.info(\"No scans to aggregate. Skipping reconstruction data aggregation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e933115",
   "metadata": {},
   "source": [
    "# Train ID CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b35e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_file in CONFIG_FILES:\n",
    "    # Load the yaml configuration file\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "    # Skip this config if the user has set ID_training to False\n",
    "    if not config['ID_settings']['training']:\n",
    "        logger.info(f\"Skipping ID training for {config_file} as ID training is set to False.\")\n",
    "        continue\n",
    "\n",
    "    # Get the training application\n",
    "    module_name, class_name = config['ID_settings']['training_app'].rsplit('.', 1)\n",
    "    module = importlib.import_module(\"pipeline.\" + module_name)\n",
    "    cls = getattr(module, class_name)\n",
    "\n",
    "    logger.debug(f\"Loaded class {class_name} from module {module_name}\")\n",
    "\n",
    "    # Get the model version (for naming purposes)\n",
    "    model_version = config['ID_settings']['model_version']\n",
    "\n",
    "    # Get the ensemble size, and loop through it\n",
    "    ensemble_size = config['ID_settings']['ensemble_size']\n",
    "    for i in range(ensemble_size):\n",
    "        # If we are training an ensemble, we add an identifier to the model version\n",
    "        if ensemble_size > 1:\n",
    "            # Deepcopy config so we don't affect the original\n",
    "            cfg = copy.deepcopy(config)\n",
    "            cfg['ID_settings']['model_version'] = f\"{model_version}_{i+1:02}\" # e.g., \"v1_01\"\n",
    "            if config['ID_settings']['input_type_match_ensemble']:\n",
    "                cfg['ID_settings']['input_type'] = f\"{cfg['ID_settings']['input_type']}_{i+1:02}\"\n",
    "        else:\n",
    "            cfg = config\n",
    "\n",
    "        # Add the data version to the configuration\n",
    "        cfg['ID_settings']['data_version'] = DATA_VERSION\n",
    "\n",
    "        # Pass the scan list and augmentation flag to the TrainingApp\n",
    "        scans_agg, _ = read_scans_agg_file(SCANS_AGG)\n",
    "        cfg['ID_settings']['augment_id'] = AUGMENT_ID\n",
    "\n",
    "        checkpoint = FILES.get_model_filepath(model_version=cfg['ID_settings']['model_version'], domain='IMAG', checkpoint=cfg['ID_settings']['start_checkpoint'], ensure_exists=False)\n",
    "        if cfg['ID_settings']['start_checkpoint'] is not None and os.path.exists(checkpoint):\n",
    "            checkpoint = torch.load(checkpoint)\n",
    "            epoch = checkpoint['epoch']\n",
    "            state_dict = checkpoint['state_dict']\n",
    "            optimizer = checkpoint['optimizer']\n",
    "\n",
    "            # Instantiate with the loaded configuration\n",
    "            instance = cls(cfg, \"IMAG\", DEBUG, FILES, epoch, optimizer, state_dict)\n",
    "        else:\n",
    "            instance = cls(cfg, \"IMAG\", DEBUG, FILES)\n",
    "\n",
    "        logger.info(f\"Going to try training the {i + 1}-th model with configuration from {config_file}...\")\n",
    "\n",
    "        # Run the training\n",
    "        instance.main()\n",
    "\n",
    "        logger.info(f\"Finished training the {i + 1}-th model.\\n\")\n",
    "\n",
    "        del instance, cfg\n",
    "        gc.collect()\n",
    "\n",
    "    # Free up memory\n",
    "    del module, cls, config, module_name, class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f74da1",
   "metadata": {},
   "source": [
    "# Pass all samples through the ID model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCANS_AGG is None:\n",
    "    logger.info(\"Skipping model application as the aggregation scan list is not provided.\")\n",
    "else:\n",
    "    # Loop through the configurations again\n",
    "    for config_file in CONFIG_FILES:\n",
    "        # Load the yaml configuration file\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "\n",
    "        logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "        # Check if the model is evidential or error\n",
    "        is_evidential = config['ID_settings']['is_evidential']\n",
    "        error = isinstance(config['ID_settings']['input_type'], dict)\n",
    "        if is_evidential or error:\n",
    "            # For evidential models (deterministic), passthrough_count should be 1\n",
    "            # For error-predicting auxiliary models, we enforce that passthrough_count is 1\n",
    "            #     although they technically don't need to be deterministic. It's kind of unnecessary to use >1.\n",
    "            if config['ID_settings']['passthrough_count'] > 1:\n",
    "                raise ValueError(\"Evidential/error models are deterministic. 'passthrough_count' should be 1.\")\n",
    "\n",
    "        # Get the ensemble size, and loop through it\n",
    "        ensemble_size = config['ID_settings']['ensemble_size']\n",
    "        for i in range(ensemble_size):\n",
    "            model_version = config['ID_settings']['model_version']\n",
    "            input_type = config['ID_settings']['input_type']\n",
    "\n",
    "            # If we are training an ensemble, we add an identifier to the model version\n",
    "            if ensemble_size > 1:\n",
    "                model_version = f\"{model_version}_{i+1:02}\"\n",
    "                if config['ID_settings']['input_type_match_ensemble']:\n",
    "                    if error:\n",
    "                        input_type['PD'][0] = f\"{input_type['PD'][0]}_{i+1:02}\"\n",
    "                        input_type['ID'][0] = f\"{input_type['ID'][0]}_{i+1:02}\"\n",
    "                    else:\n",
    "                        input_type = f\"{input_type}_{i+1:02}\"\n",
    "\n",
    "            # Load the trained ID model onto the GPU\n",
    "            model_path = FILES.get_model_filepath(model_version, \"IMAG\")\n",
    "            ID_model = load_model(config['ID_settings']['network_name'], config['ID_settings']['network_kwargs'], model_path, CUDA_DEVICE)\n",
    "\n",
    "            passthrough_count = config['ID_settings']['passthrough_count']\n",
    "\n",
    "            scans_agg, scan_type = read_scans_agg_file(SCANS_AGG, list_=False)\n",
    "            if scan_type != config['ID_settings']['scan_type']:\n",
    "                raise ValueError(f\"Scan type in aggregation file ({scan_type}) does not match scan type in config ({config['ID_settings']['scan_type']}).\")\n",
    "            \n",
    "            for patient, scan, scan_type in tqdm(scans_agg[\"VALIDATION\"] + scans_agg[\"TEST\"], desc=f\"Applying model {model_version} to projections\"):\n",
    "                for passthrough_num in range(passthrough_count):\n",
    "                    \n",
    "                    # Determine input path\n",
    "                    # For evidential models, which are deterministic, we assume the input should also be\n",
    "                    # deterministic. We use passthrough 0 from the stochastic predecessor model.\n",
    "                    if is_evidential:\n",
    "                        input_passthrough = 0\n",
    "                    elif error:\n",
    "                        input_passthrough = 0 if input_type['PD'][1] > 1 else None\n",
    "                    else:\n",
    "                        input_passthrough = passthrough_num if passthrough_count > 1 else None\n",
    "\n",
    "                    for odd in [True, False] if USE_EVEN_INDICES else [True]:\n",
    "\n",
    "                        if error:                    \n",
    "                            ng_pt_path = []\n",
    "                            ng_pt_path.append(FILES.get_recon_filepath('nsg', patient, scan, scan_type, gated=False, odd=odd))\n",
    "                            ng_pt_path.append(FILES.get_recon_filepath(input_type['PD'][0], patient, scan, scan_type, gated=False, passthrough_num=input_passthrough, odd=odd))\n",
    "                            ng_pt_path.append(FILES.get_images_results_filepath(input_type['ID'][0], patient, scan, odd=odd))\n",
    "\n",
    "                            ng_path = FILES.get_error_results_filepath(model_version, patient, scan, passthrough_num=None, odd=odd)\n",
    "                        else:\n",
    "                            ng_pt_path = FILES.get_recon_filepath(input_type, patient, scan, scan_type, gated=False, passthrough_num=input_passthrough, odd=odd)\n",
    "                            \n",
    "                            ng_path = FILES.get_images_results_filepath(\n",
    "                                model_version, patient, scan, passthrough_num=passthrough_num if passthrough_count > 1 else None, odd=odd\n",
    "                            )\n",
    "\n",
    "                        if os.path.exists(ng_path):\n",
    "                            logger.info(f\"ID CNN results already exist for {scan_type} p{patient}_{scan} for model {model_version} (passthrough {passthrough_num}). Skipping...\")\n",
    "                            continue\n",
    "\n",
    "                        # Apply model and save results\n",
    "                        results = apply_model_to_recons(\n",
    "                            ID_model, ng_pt_path, CUDA_DEVICE,\n",
    "                            scan_type=scan_type,\n",
    "                            train_at_inference=config['ID_settings']['train_at_inference'],\n",
    "                            _batch_size=8,\n",
    "                        )\n",
    "\n",
    "                        if is_evidential:\n",
    "                            gamma, nu, alpha, beta = results\n",
    "                            # Save all 4 outputs in a dictionary. Squeeze the channel dimension.\n",
    "                            results_dict = {\n",
    "                                'gamma': gamma.squeeze(1),\n",
    "                                'nu': nu.squeeze(1),\n",
    "                                'alpha': alpha.squeeze(1),\n",
    "                                'beta': beta.squeeze(1)\n",
    "                            }\n",
    "                            torch.save(results_dict, ng_path)\n",
    "                            del gamma, nu, alpha, beta, results_dict\n",
    "                        else:\n",
    "                            # Original behavior for non-evidential models\n",
    "                            torch.save(results, ng_path)\n",
    "\n",
    "                        logger.debug(f\"Saved results for {scan_type} p{patient}_{scan} (passthrough {passthrough_num}).\")\n",
    "                        del results\n",
    "\n",
    "            # Free up memory\n",
    "            del ID_model\n",
    "\n",
    "    logger.info(\"All models applied to projections.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-CTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
