{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b5c8d3",
   "metadata": {},
   "source": [
    "### Setup/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0320969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from pipeline.paths import Directories, Files\n",
    "from pipeline.utils import read_scans_agg_file\n",
    "import scipy.stats\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec7764",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eaa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE = \"7\"\n",
    "DATA_VERSION = \"13\"\n",
    "WORK_ROOT = \"D:/NoahSilverberg/ngCBCT\"\n",
    "SPLIT_TO_ANALYZE = 'TEST'  # Options: 'TRAIN', 'VALIDATION', 'TEST'\n",
    "\n",
    "MODELS_TO_ANALYZE = [\n",
    "    # {\n",
    "    #     'name': 'SWAG Learning Rate 1e-2',\n",
    "    #     'type': 'stochastic',\n",
    "    #     'domain': 'FDK',\n",
    "    #     'model_version_root': 'MK7_MCDROPOUT_15_pct_NEW_SWAG_lr1e-2',\n",
    "    #     'count': 33,\n",
    "    # },\n",
    "    {\n",
    "        'name': 'MC Dropoout 15%',\n",
    "        'type': 'stochastic',\n",
    "        'domain': 'FDK',\n",
    "        'model_version_root': 'MK7_MCDROPOUT_15_pct_NEW',\n",
    "        'count': 50,\n",
    "    },\n",
    "    {\n",
    "        'name': 'MC Dropoout 30%',\n",
    "        'type': 'stochastic',\n",
    "        'domain': 'FDK',\n",
    "        'model_version_root': 'MK7_MCDROPOUT_30_pct_NEW',\n",
    "        'count': 50,\n",
    "    },\n",
    "    # {\n",
    "    #     'name': 'MC Dropoout 50%',\n",
    "    #     'type': 'stochastic',\n",
    "    #     'domain': 'FDK',\n",
    "    #     'model_version_root': 'MK7_MCDROPOUT_50_pct_NEW',\n",
    "    #     'count': 50,\n",
    "    # },\n",
    "    {\n",
    "        'name': 'Ensemble',\n",
    "        'type': 'ensemble',\n",
    "        'domain': 'FDK',\n",
    "        'model_version_root': 'MK7',\n",
    "        'count': 7,\n",
    "    },\n",
    "    # Add other models here\n",
    "]\n",
    "\n",
    "# Path to the .pt file containing tumor locations.\n",
    "# This is a 5D tensor [patient, scan, (x, y, z)]\n",
    "TUMOR_LOCATIONS_FILE = 'D:/NoahSilverberg/ngCBCT/3D_recon/tumor_location.pt'\n",
    "\n",
    "# --- Advanced Config ---\n",
    "SCANS_AGG_FILE = 'scans_to_agg.txt'\n",
    "SSIM_KWARGS = {\"K1\": 0.03, \"K2\": 0.06, \"win_size\": 15}\n",
    "SSIM_KWARGS_ = {\"k1\": 0.03, \"k2\": 0.06, \"kernel_size\": 15}\n",
    "\n",
    "# --- Setup ---\n",
    "# Create Directories and Files objects\n",
    "phase_dataver_dir = os.path.join(WORK_ROOT, f\"phase{PHASE}\", f\"DS{DATA_VERSION}\")\n",
    "DIRECTORIES = Directories(\n",
    "    projections_results_dir=os.path.join(phase_dataver_dir, \"results\", \"projections\"),\n",
    "    projections_gated_dir=os.path.join(WORK_ROOT, \"gated\", \"prj_mat\"),\n",
    "    reconstructions_dir=os.path.join(phase_dataver_dir, \"reconstructions\"),\n",
    "    reconstructions_gated_dir=os.path.join(WORK_ROOT, \"gated\", \"fdk_recon\"),\n",
    "    images_results_dir=os.path.join(phase_dataver_dir, \"results\", \"images\"),\n",
    ")\n",
    "FILES = Files(DIRECTORIES)\n",
    "\n",
    "# Load the list of scans\n",
    "scans_agg, scan_type_agg = read_scans_agg_file(SCANS_AGG_FILE)\n",
    "analysis_scans = scans_agg[SPLIT_TO_ANALYZE][1:2]\n",
    "\n",
    "# Load tumor locations\n",
    "tumor_locations = torch.load(TUMOR_LOCATIONS_FILE, weights_only=False)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE} named '{torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}'\")\n",
    "\n",
    "print(f\"\\nConfiguration loaded.\")\n",
    "print(f\"Analyzing {len(analysis_scans)} scans from the '{SPLIT_TO_ANALYZE}' split.\")\n",
    "print(f\"Found {len(MODELS_TO_ANALYZE)} model(s) to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114d02c",
   "metadata": {},
   "source": [
    "### Data loading/prep functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b635426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(files_obj: Files, scan_info, domain, slice_idx=None):\n",
    "    \"\"\"\n",
    "    Loads the ground truth data for a given scan and domain.\n",
    "    \"\"\"\n",
    "    patient, scan, scan_type = scan_info\n",
    "    \n",
    "    if domain == 'PROJ':\n",
    "        gt_path = files_obj.get_projections_results_filepath('fdk', patient, scan, scan_type, gated=True)\n",
    "        data = torch.from_numpy(scipy.io.loadmat(gt_path)['prj']).detach().permute(1, 0, 2)\n",
    "    elif domain == 'FDK':\n",
    "        gt_path = files_obj.get_recon_filepath(\"fdk\", patient, scan, scan_type, gated=True, ensure_exists=False)\n",
    "        data = torch.load(gt_path).detach()\n",
    "        data = data[20:-20, :, :]\n",
    "        data = 25. * torch.clip(data, min=0.0, max=0.04)\n",
    "    elif domain == 'IMAG':\n",
    "        # The ground truth for the IMAG domain is the FDK of the gated projection\n",
    "        gt_path = files_obj.get_recon_filepath(\"fdk\", patient, scan, scan_type, gated=True, ensure_exists=False)\n",
    "        data = torch.load(gt_path).detach()\n",
    "        data = data[20:-20, :, :]\n",
    "        data = 25. * torch.clip(data, min=0.0, max=0.04)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown domain: {domain}\")\n",
    "\n",
    "    if slice_idx is not None and data.ndim == 3:\n",
    "        return data[slice_idx]\n",
    "    return data\n",
    "\n",
    "def load_predictions(files_obj: Files, model_config, scan_info, slice_idx=None):\n",
    "    \"\"\"\n",
    "    Loads all predictions for a given model, scan, and domain.\n",
    "    \"\"\"\n",
    "    patient, scan, scan_type = scan_info\n",
    "    domain = model_config['domain']\n",
    "    root = model_config['model_version_root']\n",
    "    count = model_config['count']\n",
    "    model_type = model_config['type']\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    print(f\"Loading {count} predictions for {model_config['name']}...\")\n",
    "    \n",
    "    for i in tqdm(range(count), desc=\"Loading predictions\", leave=False):\n",
    "        passthrough_num = None\n",
    "        model_version = root\n",
    "\n",
    "        if model_type == 'ensemble':\n",
    "            model_version = f\"{root}_{i+1:02d}\"\n",
    "        elif model_type == 'stochastic':\n",
    "            passthrough_num = i\n",
    "\n",
    "        if domain == 'PROJ':\n",
    "            pred_path = files_obj.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "            pred = torch.from_numpy(scipy.io.loadmat(pred_path)['prj']).detach().permute(1, 0, 2)\n",
    "        elif domain == 'FDK':\n",
    "            pred_path = files_obj.get_recon_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "            pred = torch.load(pred_path).detach()\n",
    "            pred = pred[20:-20, :, :]\n",
    "            pred = 25. * torch.clip(pred, min=0.0, max=0.04)\n",
    "        elif domain == 'IMAG':\n",
    "            # This assumes the results are saved with the ID model version name\n",
    "            pred_path = files_obj.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "            pred = torch.load(pred_path).detach()\n",
    "            pred = torch.squeeze(pred, dim=1)\n",
    "            pred = torch.permute(pred, (0, 2, 1))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown domain: {domain}\")\n",
    "            \n",
    "        predictions.append(pred)\n",
    "\n",
    "    predictions_tensor = torch.stack(predictions)\n",
    "    \n",
    "    if slice_idx is not None and predictions_tensor.ndim == 4:\n",
    "        return predictions_tensor[:, slice_idx, :, :]\n",
    "        \n",
    "    return predictions_tensor\n",
    "\n",
    "print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3cbb74",
   "metadata": {},
   "source": [
    "### Metric calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723009ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ause_sparsification(uncertainty, errors):\n",
    "    \"\"\"\n",
    "    Calculates the Area Under the Sparsification Error curve (AUSE) efficiently.\n",
    "    \"\"\"\n",
    "    uncertainty_flat = uncertainty.flatten()\n",
    "    errors_flat = errors.flatten()\n",
    "    \n",
    "    # Normalize by overall MAE so the curve starts at 1\n",
    "    overall_mae = np.mean(errors_flat)\n",
    "    \n",
    "    def get_sparsification_curve_fast(sorted_errs):\n",
    "        n_pixels = len(sorted_errs)\n",
    "        cumulative_errors = np.cumsum(sorted_errs)\n",
    "        total_error_sum = cumulative_errors[-1]\n",
    "        sum_errors_removed = np.insert(cumulative_errors[:-1], 0, 0)\n",
    "        sum_errors_remaining = total_error_sum - sum_errors_removed\n",
    "        n_remaining = np.arange(n_pixels, 0, -1)\n",
    "        curve = sum_errors_remaining / n_remaining\n",
    "        if overall_mae > 0:\n",
    "            curve = curve / overall_mae # Normalize the curve\n",
    "        return curve\n",
    "\n",
    "    # Move arrays to GPU using torch for sorting\n",
    "    uncertainty_tensor = torch.from_numpy(uncertainty_flat).cuda()\n",
    "    errors_tensor = torch.from_numpy(errors_flat).cuda()\n",
    "\n",
    "    # Model curve (sorted by uncertainty)\n",
    "    model_sorted_indices = torch.argsort(uncertainty_tensor, descending=True)\n",
    "    model_sorted_errors = errors_tensor[model_sorted_indices].cpu().numpy()\n",
    "    model_curve = get_sparsification_curve_fast(model_sorted_errors)\n",
    "\n",
    "    # Oracle curve (sorted by error)\n",
    "    oracle_sorted_errors = torch.sort(errors_tensor, descending=True)[0].cpu().numpy()\n",
    "    oracle_curve = get_sparsification_curve_fast(oracle_sorted_errors)\n",
    "    \n",
    "    # The AUSE is the area between the two normalized curves\n",
    "    ause = np.mean(np.abs(model_curve - oracle_curve))\n",
    "    return ause\n",
    "\n",
    "def calculate_ece(ground_truth, mean_pred, uncertainty_map, n_levels=20):\n",
    "    \"\"\"\n",
    "    Calculates the weighted calibration error for regression tasks based on Kuleshov et al., 2018.\n",
    "    \"\"\"\n",
    "    gt_flat = ground_truth.flatten()\n",
    "    pred_flat = mean_pred.flatten()\n",
    "    uncert_flat = uncertainty_map.flatten()\n",
    "\n",
    "    pred_cdfs = scipy.stats.norm.cdf(gt_flat, loc=pred_flat, scale=uncert_flat)\n",
    "    expected_confidence_levels = np.linspace(0, 1, n_levels)\n",
    "    observed_frequencies = np.array([np.mean(pred_cdfs <= p_j) for p_j in expected_confidence_levels])\n",
    "    \n",
    "    bin_boundaries = np.copy(expected_confidence_levels)\n",
    "    bin_weights = np.zeros(n_levels)\n",
    "    for i in range(1, n_levels):\n",
    "        lower_bound = bin_boundaries[i-1]\n",
    "        upper_bound = bin_boundaries[i]\n",
    "        points_in_bin = (pred_cdfs > lower_bound) & (pred_cdfs <= upper_bound)\n",
    "        bin_weights[i] = np.mean(points_in_bin)\n",
    "        \n",
    "    if np.sum(bin_weights) > 0:\n",
    "        bin_weights /= np.sum(bin_weights)\n",
    "\n",
    "    squared_errors = (expected_confidence_levels - observed_frequencies)**2\n",
    "    weighted_calibration_error = np.sum(bin_weights * squared_errors)\n",
    "    return weighted_calibration_error\n",
    "\n",
    "def calculate_spearman_correlation(uncertainty, errors):\n",
    "    \"\"\"\n",
    "    Calculates the Spearman's Rank Correlation Coefficient between\n",
    "    the uncertainty and the absolute error.\n",
    "    \"\"\"\n",
    "    uncertainty_flat = uncertainty.flatten()\n",
    "    errors_flat = errors.flatten()\n",
    "    \n",
    "    # spearmanr returns correlation and p-value; we only need the correlation\n",
    "    correlation, _ = scipy.stats.spearmanr(uncertainty_flat, errors_flat)\n",
    "    return correlation\n",
    "\n",
    "import torchmetrics\n",
    "import torchmetrics.image\n",
    "\n",
    "def calculate_volume_metrics_2_pass(files_obj, model_config, scan_info, gt_volume, device):\n",
    "    \"\"\"\n",
    "    Calculates stats and metrics using a two-pass algorithm for variance for improved stability.\n",
    "    Also includes a robust PSNR calculation that handles infinite values.\n",
    "    Pass 1: Calculate the mean of all predictions.\n",
    "    Pass 2: Calculate variance and other metrics using the pre-calculated mean.\n",
    "    \"\"\"\n",
    "    n_samples = model_config['count']\n",
    "    gt_volume = gt_volume.to(device) # Ensure GT is on the correct device\n",
    "\n",
    "    def prediction_generator():\n",
    "        # This generator yields tensors directly on the GPU\n",
    "        patient, scan, scan_type = scan_info\n",
    "        domain = model_config['domain']\n",
    "        root = model_config['model_version_root']\n",
    "        model_type = model_config['type']\n",
    "        for i in range(n_samples):\n",
    "            passthrough_num = None\n",
    "            model_version = root\n",
    "            if model_type == 'ensemble': model_version = f\"{root}_{i+1:02d}\"\n",
    "            elif model_type == 'stochastic': passthrough_num = i\n",
    "\n",
    "            if domain == 'PROJ':\n",
    "                pred_path = files_obj.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                pred = torch.from_numpy(scipy.io.loadmat(pred_path)['prj']).detach().permute(1, 0, 2)\n",
    "            elif domain == 'FDK':\n",
    "                pred_path = files_obj.get_recon_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                pred = torch.load(pred_path).detach()\n",
    "                pred = pred[20:-20, :, :]\n",
    "                pred = 25. * torch.clip(pred, min=0.0, max=0.04)\n",
    "            elif domain == 'IMAG':\n",
    "                pred_path = files_obj.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                pred = torch.load(pred_path).detach()\n",
    "                pred = torch.squeeze(pred, dim=1)\n",
    "                pred = torch.permute(pred, (0, 2, 1))\n",
    "            yield pred.to(device)\n",
    "\n",
    "    # --- Pass 1: Calculate Mean ---\n",
    "    print(\"Pass 1: Calculating mean prediction...\")\n",
    "    mean_volume = torch.zeros_like(gt_volume)\n",
    "    # Using a simple sum and divide for the mean\n",
    "    for pred_volume in tqdm(prediction_generator(), total=n_samples, desc=\"Pass 1/2 (Mean)\", leave=False):\n",
    "        mean_volume += pred_volume\n",
    "    mean_volume /= n_samples\n",
    "\n",
    "    # --- Pass 2: Calculate Variance and Metrics ---\n",
    "    print(\"Pass 2: Calculating variance and metrics...\")\n",
    "    sum_sq_diff_volume = torch.zeros_like(gt_volume)\n",
    "    sample_avg_ssims, sample_avg_psnrs, sample_avg_mses, sample_avg_maes = [], [], [], []\n",
    "\n",
    "    # Initialize metrics on the specified device\n",
    "    data_range = gt_volume.max() - gt_volume.min()\n",
    "    ssim_metric = torchmetrics.image.StructuralSimilarityIndexMeasure(data_range=data_range, **SSIM_KWARGS_).to(device)\n",
    "\n",
    "    # PSNR metric that returns per-slice results to handle 'inf'\n",
    "    psnr_metric = torchmetrics.image.PeakSignalNoiseRatio(data_range=data_range, reduction='none').to(device)\n",
    "\n",
    "    for pred_volume in tqdm(prediction_generator(), total=n_samples, desc=\"Pass 2/2 (Var & Metrics)\", leave=False):\n",
    "        # Variance calculation\n",
    "        diff = pred_volume - mean_volume\n",
    "        sum_sq_diff_volume += diff * diff\n",
    "\n",
    "        # Per-sample metrics\n",
    "        if gt_volume.ndim > 2:\n",
    "            pred_vol_batch = pred_volume.unsqueeze(1)\n",
    "            gt_vol_batch = gt_volume.unsqueeze(1)\n",
    "            \n",
    "            sample_avg_ssims.append(ssim_metric(pred_vol_batch, gt_vol_batch).item())\n",
    "            sample_avg_mses.append(torch.mean((gt_volume - pred_volume)**2).item())\n",
    "            sample_avg_maes.append(torch.mean(torch.abs(gt_volume - pred_volume)).item())\n",
    "\n",
    "            # --- Robust PSNR Calculation ---\n",
    "            psnr_per_slice = psnr_metric(pred_vol_batch, gt_vol_batch)\n",
    "            finite_psnrs = psnr_per_slice[torch.isfinite(psnr_per_slice)] # Filter out inf values\n",
    "            if finite_psnrs.numel() > 0:\n",
    "                sample_avg_psnrs.append(torch.mean(finite_psnrs).item())\n",
    "            else:\n",
    "                # Handle case where all slices are perfect matches\n",
    "                sample_avg_psnrs.append(100.0) # Assign a high value\n",
    "\n",
    "    # Finalize variance and uncertainty\n",
    "    if n_samples > 1:\n",
    "        # Using n_samples for population standard deviation, as in the original code.\n",
    "        # For sample standard deviation, use (n_samples - 1).\n",
    "        variance_volume_map = sum_sq_diff_volume / n_samples\n",
    "        uncertainty_volume_map = torch.sqrt(variance_volume_map)\n",
    "    else:\n",
    "        uncertainty_volume_map = torch.zeros_like(mean_volume)\n",
    "\n",
    "    # --- Calculate metrics for the mean prediction ---\n",
    "    metrics = {}\n",
    "    if gt_volume.ndim > 2:\n",
    "        mean_vol_batch = mean_volume.unsqueeze(1)\n",
    "        gt_vol_batch = gt_volume.unsqueeze(1)\n",
    "        \n",
    "        metrics['mean_ssim'] = ssim_metric(mean_vol_batch, gt_vol_batch).item()\n",
    "        metrics['mean_mse'] = torch.mean((gt_volume - mean_volume)**2).item()\n",
    "        metrics['mean_mae'] = torch.mean(torch.abs(gt_volume - mean_volume)).item()\n",
    "\n",
    "        # Robust PSNR for the mean prediction\n",
    "        mean_psnr_per_slice = psnr_metric(mean_vol_batch, gt_vol_batch)\n",
    "        finite_mean_psnrs = mean_psnr_per_slice[torch.isfinite(mean_psnr_per_slice)]\n",
    "        if finite_mean_psnrs.numel() > 0:\n",
    "            metrics['mean_psnr'] = torch.mean(finite_mean_psnrs).item()\n",
    "        else:\n",
    "            metrics['mean_psnr'] = 100.0\n",
    "\n",
    "    # --- Aggregate per-sample metrics ---\n",
    "    metrics['sample_avg_ssim'] = np.mean(sample_avg_ssims) if sample_avg_ssims else 0\n",
    "    metrics['sample_avg_psnr'] = np.mean(sample_avg_psnrs) if sample_avg_psnrs else 0\n",
    "    metrics['sample_avg_mse'] = np.mean(sample_avg_mses) if sample_avg_mses else 0\n",
    "    metrics['sample_avg_mae'] = np.mean(sample_avg_maes) if sample_avg_maes else 0\n",
    "\n",
    "    return metrics, mean_volume, uncertainty_volume_map\n",
    "\n",
    "print(\"Metric calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e85d476",
   "metadata": {},
   "source": [
    "### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b12fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_comparison(mean_pred, ground_truth, uncertainty_map, model_name, scan_name, slice_idx, tumor_coords_xy=None):\n",
    "    \"\"\"Plots the GT, mean prediction, absolute error, and uncertainty map.\"\"\"\n",
    "    error_map = np.abs(ground_truth - mean_pred)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    fig.suptitle(f'{model_name} - {scan_name} - Slice {slice_idx} (Mean vs. GT)', fontsize=16)\n",
    "\n",
    "    im1 = axes[0].imshow(ground_truth, cmap='gray')\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "    fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "    if tumor_coords_xy:\n",
    "        x, y = tumor_coords_xy\n",
    "        for i in range(4):\n",
    "            axes[i].annotate('', xy=(x, y), xytext=(x - 30, y - 30),\n",
    "                            arrowprops=dict(facecolor='red', edgecolor='red', shrink=0.05, width=1, headwidth=5, headlength=5))\n",
    "\n",
    "    im2 = axes[1].imshow(mean_pred, cmap='gray')\n",
    "    axes[1].set_title('Mean Prediction')\n",
    "    axes[1].axis('off')\n",
    "    fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    im3 = axes[2].imshow(error_map, cmap='magma')\n",
    "    axes[2].set_title('Absolute Error Map')\n",
    "    axes[2].axis('off')\n",
    "    fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "    im4 = axes[3].imshow(uncertainty_map, cmap='viridis')\n",
    "    axes[3].set_title('Uncertainty (Std Dev)')\n",
    "    axes[3].axis('off')\n",
    "    fig.colorbar(im4, ax=axes[3])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_ssim_map(ssim_map, model_name, scan_name):\n",
    "    \"\"\"Plots the SSIM map.\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(ssim_map, cmap='viridis', vmin=0, vmax=1)\n",
    "    plt.title(f'SSIM Map - {model_name} - {scan_name}')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration_curve(ground_truth, mean_pred, uncertainty_map, model_name, scan_name, n_levels=20):\n",
    "    \"\"\"\n",
    "    Plots the calibration curve with a marginal histogram below the x-axis\n",
    "    showing the distribution of the predicted CDF values.\n",
    "    \"\"\"\n",
    "    gt_flat = ground_truth.flatten()\n",
    "    pred_flat = mean_pred.flatten()\n",
    "    uncert_flat = uncertainty_map.flatten()\n",
    "\n",
    "    # Calculate the predicted CDF value for each point\n",
    "    pred_cdfs = scipy.stats.norm.cdf(gt_flat, loc=pred_flat, scale=uncert_flat)\n",
    "    \n",
    "    # --- Create figure with two subplots, sharing the x-axis ---\n",
    "    fig, (ax_cal, ax_hist) = plt.subplots(\n",
    "        2, 1,\n",
    "        figsize=(8, 8),\n",
    "        sharex=True,\n",
    "        gridspec_kw={'height_ratios': [3, 1]} # Main plot is 3x taller\n",
    "    )\n",
    "    \n",
    "    # --- Main Calibration Plot (top) ---\n",
    "    expected_confidence_levels = np.linspace(0, 1, n_levels)\n",
    "    observed_frequencies = np.array([np.mean(pred_cdfs <= p_j) for p_j in expected_confidence_levels])\n",
    "\n",
    "    ax_cal.plot([0, 1], [0, 1], '--', color='grey', label='Perfectly Calibrated')\n",
    "    ax_cal.plot(expected_confidence_levels, observed_frequencies, '-o', label='Model Calibration')\n",
    "    ax_cal.set_ylabel('Observed Confidence Level')\n",
    "    ax_cal.set_title(f'Calibration Plot - {model_name} - {scan_name}')\n",
    "    ax_cal.legend()\n",
    "    ax_cal.grid(True, linestyle=':')\n",
    "\n",
    "    # --- Marginal Histogram (bottom) ---\n",
    "    ax_hist.hist(pred_cdfs, bins=50, range=(0,1), density=True, color='steelblue', alpha=0.8)\n",
    "    ax_hist.set_xlabel('Expected Confidence Level (Predicted CDF)')\n",
    "    ax_hist.set_ylabel('Density')\n",
    "    ax_hist.set_yscale('log')\n",
    "    # ax_hist.set_yticks([]) # Hide y-ticks for clarity\n",
    "\n",
    "    # Final adjustments\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_sparsification_curve(uncertainty, errors, model_name, scan_name):\n",
    "    \"\"\"\n",
    "    Plots the model and oracle sparsification curves used for AUSE calculation.\n",
    "    \"\"\"\n",
    "    uncertainty_flat = uncertainty.flatten()\n",
    "    errors_flat = errors.flatten()\n",
    "    \n",
    "    def get_sparsification_curve_fast(sorted_errs, overall_mae):\n",
    "        n_pixels = len(sorted_errs)\n",
    "        cumulative_errors = np.cumsum(sorted_errs)\n",
    "        total_error_sum = cumulative_errors[-1]\n",
    "        sum_errors_removed = np.insert(cumulative_errors[:-1], 0, 0)\n",
    "        sum_errors_remaining = total_error_sum - sum_errors_removed\n",
    "        n_remaining = np.arange(n_pixels, 0, -1)\n",
    "        curve = sum_errors_remaining / n_remaining\n",
    "        if overall_mae > 0:\n",
    "            curve = curve / overall_mae\n",
    "        return curve\n",
    "    \n",
    "    overall_mae = np.mean(errors_flat)\n",
    "\n",
    "    # Model curve (sorted by uncertainty)\n",
    "    model_sorted_indices = np.argsort(uncertainty_flat)[::-1]\n",
    "    model_sorted_errors = errors_flat[model_sorted_indices]\n",
    "    model_curve = get_sparsification_curve_fast(model_sorted_errors, overall_mae)\n",
    "    \n",
    "    # Oracle curve (sorted by error)\n",
    "    oracle_sorted_errors = np.sort(errors_flat)[::-1]\n",
    "    oracle_curve = get_sparsification_curve_fast(oracle_sorted_errors, overall_mae)\n",
    "    \n",
    "    # X-axis: fraction of pixels removed\n",
    "    fraction_removed = np.linspace(0, 1, len(model_curve))\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fraction_removed, model_curve, label='Model (Sort by Uncertainty)')\n",
    "    plt.plot(fraction_removed, oracle_curve, '--', label='Oracle (Sort by Error)')\n",
    "    plt.xlabel('Fraction of Pixels Removed')\n",
    "    plt.ylabel('Mean Absolute Error of Remaining Pixels')\n",
    "    plt.title(f'Sparsification Curve - {model_name} - {scan_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.show()\n",
    "\n",
    "def plot_samples_comparison(ground_truth, mean_pred, samples, model_name, scan_name, slice_idx, tumor_coords_xy=None):\n",
    "    \"\"\"\n",
    "    Plots the ground truth, mean prediction, and a few individual sample predictions.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth (np.ndarray): The 2D ground truth slice.\n",
    "        mean_pred (np.ndarray): The 2D mean prediction slice.\n",
    "        samples (list of np.ndarray): A list of 2D sample prediction slices.\n",
    "        model_name (str): The name of the model for the title.\n",
    "        scan_name (str): The name of the scan for the title.\n",
    "        slice_idx (int): The index of the slice for the title.\n",
    "        tumor_coords_xy (tuple, optional): (x, y) coordinates for the tumor arrow.\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "    # Total columns = 1 for GT + 1 for Mean + N for samples\n",
    "    num_cols = 2 + num_samples\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_cols, figsize=(4 * num_cols, 4.5), constrained_layout=True)\n",
    "    fig.suptitle(f'{model_name} - {scan_name} - Slice {slice_idx} (GT, Mean, and Samples)', fontsize=16)\n",
    "\n",
    "    # Determine a consistent grayscale range based on the ground truth and mean\n",
    "    vmin = min(ground_truth.min(), mean_pred.min())\n",
    "    vmax = max(ground_truth.max(), mean_pred.max())\n",
    "\n",
    "    # --- Plot Ground Truth ---\n",
    "    axes[0].imshow(ground_truth, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # --- Plot Mean Prediction ---\n",
    "    axes[1].imshow(mean_pred, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[1].set_title('Mean Prediction')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # --- Plot Samples ---\n",
    "    for i in range(num_samples):\n",
    "        ax = axes[i + 2]\n",
    "        im = ax.imshow(samples[i], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f'Sample {i+1}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # --- Add Tumor Arrow ---\n",
    "    if tumor_coords_xy:\n",
    "        x, y = tumor_coords_xy\n",
    "        for ax in axes:\n",
    "            ax.annotate('', xy=(x, y), xytext=(x - 30, y - 30),\n",
    "                        arrowprops=dict(facecolor='red', edgecolor='red', shrink=0.05, \n",
    "                                        width=1, headwidth=5, headlength=5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_worst_samples_comparison(ground_truth, mean_pred, worst_samples_data, model_name, scan_name, slice_idx, tumor_coords_xy=None):\n",
    "    \"\"\"\n",
    "    Plots the ground truth, mean prediction, and the worst-performing sample predictions.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth (np.ndarray): The 2D ground truth slice.\n",
    "        mean_pred (np.ndarray): The 2D mean prediction slice.\n",
    "        worst_samples_data (list): A list of tuples, where each tuple is \n",
    "                                   (loss, sample_slice_numpy, sample_index).\n",
    "        model_name (str): The name of the model for the title.\n",
    "        scan_name (str): The name of the scan for the title.\n",
    "        slice_idx (int): The index of the slice for the title.\n",
    "        tumor_coords_xy (tuple, optional): (x, y) coordinates for the tumor arrow.\n",
    "    \"\"\"\n",
    "    num_samples = len(worst_samples_data)\n",
    "    num_cols = 2 + num_samples\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_cols, figsize=(4 * num_cols, 5), constrained_layout=True)\n",
    "    fig.suptitle(f'{model_name} - {scan_name} - Slice {slice_idx} (Top {num_samples} Worst Samples by SmoothL1Loss)', fontsize=16)\n",
    "\n",
    "    # Determine a consistent grayscale range\n",
    "    vmin = min(ground_truth.min(), mean_pred.min())\n",
    "    vmax = max(ground_truth.max(), mean_pred.max())\n",
    "\n",
    "    # --- Plot Ground Truth ---\n",
    "    axes[0].imshow(ground_truth, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # --- Plot Mean Prediction ---\n",
    "    axes[1].imshow(mean_pred, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[1].set_title('Mean Prediction')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # --- Plot Worst Samples ---\n",
    "    for i in range(num_samples):\n",
    "        loss, sample_slice, sample_idx = worst_samples_data[i]\n",
    "        ax = axes[i + 2]\n",
    "        im = ax.imshow(sample_slice, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        # Add the loss and original sample number to the title\n",
    "        ax.set_title(f'Sample #{sample_idx}\\nLoss: {loss:.4f}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # --- Add Tumor Arrow ---\n",
    "    if tumor_coords_xy:\n",
    "        x, y = tumor_coords_xy\n",
    "        for ax in axes:\n",
    "            ax.annotate('', xy=(x, y), xytext=(x - 30, y - 30),\n",
    "                        arrowprops=dict(facecolor='red', edgecolor='red', shrink=0.05, \n",
    "                                        width=1, headwidth=5, headlength=5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c49df",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f091a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will store dictionaries of results for each scan and model\n",
    "all_results = []\n",
    "\n",
    "for model_config in MODELS_TO_ANALYZE:\n",
    "    model_name = model_config['name']\n",
    "    domain = model_config['domain']\n",
    "    \n",
    "    scan_results = []\n",
    "\n",
    "    for scan_info in tqdm(analysis_scans, desc=f\"Analyzing Model: {model_name}\"):\n",
    "        patient, scan, _ = scan_info\n",
    "        scan_name = f\"p{patient}_{scan}\"\n",
    "        \n",
    "        # --- Determine Domain and Plotting Slice ---\n",
    "        is_visual_domain = domain in ['FDK', 'IMAG']\n",
    "        plot_slice_idx = None\n",
    "        tumor_xy = None\n",
    "        \n",
    "        if is_visual_domain:\n",
    "            if 'tumor_locations' in locals() and tumor_locations is not None:\n",
    "                try:\n",
    "                    loc = tumor_locations[int(patient), int(scan)]\n",
    "                    tumor_xy = (loc[1].item(), loc[0].item())\n",
    "                    plot_slice_idx = int(loc[2].item()) - 20\n",
    "                except (IndexError, TypeError):\n",
    "                    print(f\"Warning: Could not find tumor location for {scan_name}. Plotting will not have an arrow.\")\n",
    "                    plot_slice_idx = 100\n",
    "            else:\n",
    "                plot_slice_idx = 100\n",
    "        \n",
    "        # --- Data Loading (Ground Truth Only) ---\n",
    "        gt_volume = load_ground_truth(FILES, scan_info, domain, slice_idx=None)\n",
    "        gt_volume_np = gt_volume.cpu().numpy()\n",
    "        \n",
    "        # --- Iterative Metric Calculation ---\n",
    "        print(\"Calculating metrics iteratively...\")\n",
    "        iq_metrics, mean_pred_vol, uncertainty_map_vol = calculate_volume_metrics_2_pass(\n",
    "            FILES, model_config, scan_info, gt_volume.to(DEVICE), DEVICE\n",
    "        )\n",
    "        mean_pred_vol = mean_pred_vol.cpu().numpy()\n",
    "        uncertainty_map_vol = uncertainty_map_vol.cpu().numpy()\n",
    "        \n",
    "        # --- Uncertainty Metric Calculation ---\n",
    "        errors_vol = np.abs(gt_volume_np - mean_pred_vol)\n",
    "        print(\"Calculating AUSE...\")\n",
    "        ause_val = calculate_ause_sparsification(uncertainty_map_vol, errors_vol)\n",
    "        # print(\"Calculating ECE...\")\n",
    "        # ece_val = calculate_ece(gt_volume_np, mean_pred_vol, uncertainty_map_vol)\n",
    "        print(\"Calculating Spearman's correlation...\")\n",
    "        spearman_val = calculate_spearman_correlation(uncertainty_map_vol, errors_vol)\n",
    "        \n",
    "        # --- Store Results ---\n",
    "        scan_result = {\n",
    "            'model_name': model_name,\n",
    "            'scan_name': scan_name,\n",
    "            **iq_metrics,\n",
    "            'ause': ause_val,\n",
    "            # 'ece': ece_val,\n",
    "            'spearman_corr': spearman_val,\n",
    "        }\n",
    "        scan_results.append(scan_result)\n",
    "        \n",
    "        # --- Visualization ---\n",
    "        print(f\"\\n--- Results for {model_name} on {scan_name} ---\")\n",
    "        \n",
    "        # plot_calibration_curve(gt_volume_np, mean_pred_vol, uncertainty_map_vol, model_name, scan_name)\n",
    "        plot_sparsification_curve(uncertainty_map_vol, errors_vol, model_name, scan_name)\n",
    "        \n",
    "        if is_visual_domain:\n",
    "            gt_slice_np = gt_volume_np[plot_slice_idx]\n",
    "            mean_pred_slice = mean_pred_vol[plot_slice_idx]\n",
    "            uncertainty_map_slice = uncertainty_map_vol[plot_slice_idx]\n",
    "            _, ssim_map_val = ssim(gt_slice_np, mean_pred_slice, \n",
    "                                  data_range=(np.max(gt_slice_np) - np.min(gt_slice_np)), \n",
    "                                  full=True, **SSIM_KWARGS)\n",
    "            \n",
    "            plot_mean_comparison(mean_pred_slice, gt_slice_np, uncertainty_map_slice, \n",
    "                                 model_name, scan_name, plot_slice_idx, tumor_coords_xy=tumor_xy)\n",
    "            plot_ssim_map(ssim_map_val, model_name, scan_name)\n",
    "\n",
    "            # --- Load and plot a few samples for visual comparison ---\n",
    "            print(\"Loading and plotting samples...\")\n",
    "            SAMPLES_TO_PLOT = 5\n",
    "            sample_slices_for_plotting = []\n",
    "            \n",
    "            # Determine the number of samples to load (can't be more than what's available)\n",
    "            num_to_load = min(SAMPLES_TO_PLOT, model_config['count'])\n",
    "\n",
    "            for i in range(num_to_load):\n",
    "                passthrough_num = None\n",
    "                model_version = model_config['model_version_root']\n",
    "                model_type = model_config['type']\n",
    "\n",
    "                if model_type == 'ensemble':\n",
    "                    model_version = f\"{model_config['model_version_root']}_{i+1:02d}\"\n",
    "                elif model_type == 'stochastic':\n",
    "                    passthrough_num = i\n",
    "                \n",
    "                # This loading logic is copied from your metrics function\n",
    "                pred = None\n",
    "                if domain == 'FDK':\n",
    "                    pred_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type_agg, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred = torch.load(pred_path).detach()\n",
    "                    pred = pred[20:-20, :, :]\n",
    "                    pred = 25. * torch.clip(pred, min=0.0, max=0.04)\n",
    "                elif domain == 'IMAG':\n",
    "                    pred_path = FILES.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred = \n",
    "                    (pred_path).detach()\n",
    "                    pred = torch.squeeze(pred, dim=1)\n",
    "                    pred = torch.permute(pred, (0, 2, 1))\n",
    "                \n",
    "                # Get the specific slice and convert to a numpy array for plotting\n",
    "                if pred is not None:\n",
    "                    sample_slice = pred[plot_slice_idx].cpu().numpy()\n",
    "                    sample_slices_for_plotting.append(sample_slice)\n",
    "\n",
    "            # Call the new plotting function\n",
    "            if sample_slices_for_plotting:\n",
    "                plot_samples_comparison(\n",
    "                    ground_truth=gt_slice_np,\n",
    "                    mean_pred=mean_pred_slice,\n",
    "                    samples=sample_slices_for_plotting,\n",
    "                    model_name=model_name,\n",
    "                    scan_name=scan_name,\n",
    "                    slice_idx=plot_slice_idx,\n",
    "                    tumor_coords_xy=tumor_xy\n",
    "                )\n",
    "\n",
    "            print(\"Finding and plotting worst samples by Smooth L1 Loss...\")\n",
    "            WORST_SAMPLES_TO_PLOT = 5\n",
    "\n",
    "            # List to store tuples of (loss, sample_slice_numpy, sample_index)\n",
    "            worst_samples_data = []\n",
    "            # Get the ground truth slice as a tensor on the correct device\n",
    "            gt_slice_tensor = gt_volume[plot_slice_idx].to(DEVICE)\n",
    "\n",
    "            # Loop through all available samples to find the worst ones\n",
    "            for i in tqdm(range(model_config['count']), desc=\"Finding Worst Samples\", leave=False):\n",
    "                passthrough_num = None\n",
    "                model_version = model_config['model_version_root']\n",
    "                model_type = model_config['type']\n",
    "\n",
    "                if model_type == 'ensemble':\n",
    "                    model_version = f\"{model_config['model_version_root']}_{i+1:02d}\"\n",
    "                elif model_type == 'stochastic':\n",
    "                    passthrough_num = i\n",
    "                \n",
    "                # Load the prediction volume as a tensor on the GPU\n",
    "                pred_vol_tensor = None\n",
    "                if domain == 'FDK':\n",
    "                    pred_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type_agg, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred_vol_tensor = torch.load(pred_path, map_location=DEVICE).detach()\n",
    "                    pred_vol_tensor = pred_vol_tensor[20:-20, :, :]\n",
    "                    pred_vol_tensor = 25. * torch.clip(pred_vol_tensor, min=0.0, max=0.04)\n",
    "                elif domain == 'IMAG':\n",
    "                    pred_path = FILES.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred_vol_tensor = torch.load(pred_path, map_location=DEVICE).detach()\n",
    "                    pred_vol_tensor = torch.squeeze(pred_vol_tensor, dim=1)\n",
    "                    pred_vol_tensor = torch.permute(pred_vol_tensor, (0, 2, 1))\n",
    "\n",
    "                if pred_vol_tensor is not None:\n",
    "                    pred_slice_tensor = pred_vol_tensor[plot_slice_idx]\n",
    "                    \n",
    "                    # Calculate Smooth L1 Loss for the current slice\n",
    "                    import torch.nn.functional as F\n",
    "                    loss = F.smooth_l1_loss(pred_slice_tensor, gt_slice_tensor, reduction='mean').item()\n",
    "\n",
    "                    # Keep track of the top 5 worst samples (highest loss)\n",
    "                    if len(worst_samples_data) < WORST_SAMPLES_TO_PLOT:\n",
    "                        worst_samples_data.append((loss, pred_slice_tensor.cpu().numpy(), i))\n",
    "                    else:\n",
    "                        # Find the sample with the minimum loss currently in our list\n",
    "                        min_loss_in_list = min(worst_samples_data, key=lambda x: x[0])\n",
    "                        if loss > min_loss_in_list[0]:\n",
    "                            # If current sample is worse, replace the \"best of the worst\"\n",
    "                            worst_samples_data.remove(min_loss_in_list)\n",
    "                            worst_samples_data.append((loss, pred_slice_tensor.cpu().numpy(), i))\n",
    "\n",
    "            # Sort the final list from worst to best for plotting\n",
    "            worst_samples_data.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "            # Call the new plotting function with the results\n",
    "            if worst_samples_data:\n",
    "                plot_worst_samples_comparison(\n",
    "                    ground_truth=gt_slice_np,\n",
    "                    mean_pred=mean_pred_slice,\n",
    "                    worst_samples_data=worst_samples_data,\n",
    "                    model_name=model_name,\n",
    "                    scan_name=scan_name,\n",
    "                    slice_idx=plot_slice_idx,\n",
    "                    tumor_coords_xy=tumor_xy\n",
    "                )\n",
    "\n",
    "        # --- Clean up memory ---\n",
    "        del gt_volume, gt_volume_np, mean_pred_vol, uncertainty_map_vol, errors_vol\n",
    "        gc.collect()\n",
    "        \n",
    "    all_results.extend(scan_results)\n",
    "\n",
    "# Convert results to a pandas DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n\\n✅ Analysis complete for all models and scans.\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1de2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will store dictionaries of results for each scan and model\n",
    "all_results = []\n",
    "\n",
    "for model_config in MODELS_TO_ANALYZE:\n",
    "    model_name = model_config['name']\n",
    "    domain = model_config['domain']\n",
    "    \n",
    "    scan_results = []\n",
    "\n",
    "    for scan_info in tqdm(analysis_scans, desc=f\"Analyzing Model: {model_name}\"):\n",
    "        patient, scan, _ = scan_info\n",
    "        scan_name = f\"p{patient}_{scan}\"\n",
    "        \n",
    "        # --- Determine Domain and Plotting Slice ---\n",
    "        is_visual_domain = domain in ['FDK', 'IMAG']\n",
    "        plot_slice_idx = None\n",
    "        tumor_xy = None\n",
    "        \n",
    "        if is_visual_domain:\n",
    "            if 'tumor_locations' in locals() and tumor_locations is not None:\n",
    "                try:\n",
    "                    loc = tumor_locations[int(patient), int(scan)]\n",
    "                    tumor_xy = (loc[1].item(), loc[0].item())\n",
    "                    plot_slice_idx = int(loc[2].item()) - 20\n",
    "                except (IndexError, TypeError):\n",
    "                    print(f\"Warning: Could not find tumor location for {scan_name}. Plotting will not have an arrow.\")\n",
    "                    plot_slice_idx = 100\n",
    "            else:\n",
    "                plot_slice_idx = 100\n",
    "        \n",
    "        # --- Data Loading (Ground Truth Only) ---\n",
    "        gt_volume = load_ground_truth(FILES, scan_info, domain, slice_idx=None)\n",
    "        gt_volume_np = gt_volume.cpu().numpy()\n",
    "        \n",
    "        # --- Iterative Metric Calculation ---\n",
    "        print(\"Calculating metrics iteratively...\")\n",
    "        iq_metrics, mean_pred_vol, uncertainty_map_vol = calculate_volume_metrics_2_pass(\n",
    "            FILES, model_config, scan_info, gt_volume.to(DEVICE), DEVICE\n",
    "        )\n",
    "        mean_pred_vol = mean_pred_vol.cpu().numpy()\n",
    "        uncertainty_map_vol = uncertainty_map_vol.cpu().numpy()\n",
    "        \n",
    "        # --- Uncertainty Metric Calculation ---\n",
    "        errors_vol = np.abs(gt_volume_np - mean_pred_vol)\n",
    "        print(\"Calculating AUSE...\")\n",
    "        ause_val = calculate_ause_sparsification(uncertainty_map_vol, errors_vol)\n",
    "        # print(\"Calculating ECE...\")\n",
    "        # ece_val = calculate_ece(gt_volume_np, mean_pred_vol, uncertainty_map_vol)\n",
    "        print(\"Calculating Spearman's correlation...\")\n",
    "        spearman_val = calculate_spearman_correlation(uncertainty_map_vol, errors_vol)\n",
    "        \n",
    "        # --- Store Results ---\n",
    "        scan_result = {\n",
    "            'model_name': model_name,\n",
    "            'scan_name': scan_name,\n",
    "            **iq_metrics,\n",
    "            'ause': ause_val,\n",
    "            # 'ece': ece_val,\n",
    "            'spearman_corr': spearman_val,\n",
    "        }\n",
    "        scan_results.append(scan_result)\n",
    "        \n",
    "        # --- Visualization ---\n",
    "        print(f\"\\n--- Results for {model_name} on {scan_name} ---\")\n",
    "        \n",
    "        # plot_calibration_curve(gt_volume_np, mean_pred_vol, uncertainty_map_vol, model_name, scan_name)\n",
    "        plot_sparsification_curve(uncertainty_map_vol, errors_vol, model_name, scan_name)\n",
    "        \n",
    "        if is_visual_domain:\n",
    "            gt_slice_np = gt_volume_np[plot_slice_idx]\n",
    "            mean_pred_slice = mean_pred_vol[plot_slice_idx]\n",
    "            uncertainty_map_slice = uncertainty_map_vol[plot_slice_idx]\n",
    "            _, ssim_map_val = ssim(gt_slice_np, mean_pred_slice, \n",
    "                                  data_range=(np.max(gt_slice_np) - np.min(gt_slice_np)), \n",
    "                                  full=True, **SSIM_KWARGS)\n",
    "            \n",
    "            plot_mean_comparison(mean_pred_slice, gt_slice_np, uncertainty_map_slice, \n",
    "                                 model_name, scan_name, plot_slice_idx, tumor_coords_xy=tumor_xy)\n",
    "            plot_ssim_map(ssim_map_val, model_name, scan_name)\n",
    "\n",
    "            # --- Load and plot a few samples for visual comparison ---\n",
    "            print(\"Loading and plotting samples...\")\n",
    "            SAMPLES_TO_PLOT = 5\n",
    "            sample_slices_for_plotting = []\n",
    "            \n",
    "            # Determine the number of samples to load (can't be more than what's available)\n",
    "            num_to_load = min(SAMPLES_TO_PLOT, model_config['count'])\n",
    "\n",
    "            for i in range(num_to_load):\n",
    "                passthrough_num = None\n",
    "                model_version = model_config['model_version_root']\n",
    "                model_type = model_config['type']\n",
    "\n",
    "                if model_type == 'ensemble':\n",
    "                    model_version = f\"{model_config['model_version_root']}_{i+1:02d}\"\n",
    "                elif model_type == 'stochastic':\n",
    "                    passthrough_num = i\n",
    "                \n",
    "                # This loading logic is copied from your metrics function\n",
    "                pred = None\n",
    "                if domain == 'FDK':\n",
    "                    pred_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type_agg, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred = torch.load(pred_path).detach()\n",
    "                    pred = pred[20:-20, :, :]\n",
    "                    pred = 25. * torch.clip(pred, min=0.0, max=0.04)\n",
    "                elif domain == 'IMAG':\n",
    "                    pred_path = FILES.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred = torch.load(pred_path).detach()\n",
    "                    pred = torch.squeeze(pred, dim=1)\n",
    "                    pred = torch.permute(pred, (0, 2, 1))\n",
    "                \n",
    "                # Get the specific slice and convert to a numpy array for plotting\n",
    "                if pred is not None:\n",
    "                    sample_slice = pred[plot_slice_idx].cpu().numpy()\n",
    "                    sample_slices_for_plotting.append(sample_slice)\n",
    "\n",
    "            # Call the new plotting function\n",
    "            if sample_slices_for_plotting:\n",
    "                plot_samples_comparison(\n",
    "                    ground_truth=gt_slice_np,\n",
    "                    mean_pred=mean_pred_slice,\n",
    "                    samples=sample_slices_for_plotting,\n",
    "                    model_name=model_name,\n",
    "                    scan_name=scan_name,\n",
    "                    slice_idx=plot_slice_idx,\n",
    "                    tumor_coords_xy=tumor_xy\n",
    "                )\n",
    "\n",
    "            print(\"Finding and plotting worst samples by Smooth L1 Loss...\")\n",
    "            WORST_SAMPLES_TO_PLOT = 5\n",
    "\n",
    "            # List to store tuples of (loss, sample_slice_numpy, sample_index)\n",
    "            worst_samples_data = []\n",
    "            # Get the ground truth slice as a tensor on the correct device\n",
    "            gt_slice_tensor = gt_volume[plot_slice_idx].to(DEVICE)\n",
    "\n",
    "            # Loop through all available samples to find the worst ones\n",
    "            for i in tqdm(range(model_config['count']), desc=\"Finding Worst Samples\", leave=False):\n",
    "                passthrough_num = None\n",
    "                model_version = model_config['model_version_root']\n",
    "                model_type = model_config['type']\n",
    "\n",
    "                if model_type == 'ensemble':\n",
    "                    model_version = f\"{model_config['model_version_root']}_{i+1:02d}\"\n",
    "                elif model_type == 'stochastic':\n",
    "                    passthrough_num = i\n",
    "                \n",
    "                # Load the prediction volume as a tensor on the GPU\n",
    "                pred_vol_tensor = None\n",
    "                if domain == 'FDK':\n",
    "                    pred_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type_agg, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred_vol_tensor = torch.load(pred_path, map_location=DEVICE).detach()\n",
    "                    pred_vol_tensor = pred_vol_tensor[20:-20, :, :]\n",
    "                    pred_vol_tensor = 25. * torch.clip(pred_vol_tensor, min=0.0, max=0.04)\n",
    "                elif domain == 'IMAG':\n",
    "                    pred_path = FILES.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                    pred_vol_tensor = torch.load(pred_path, map_location=DEVICE).detach()\n",
    "                    pred_vol_tensor = torch.squeeze(pred_vol_tensor, dim=1)\n",
    "                    pred_vol_tensor = torch.permute(pred_vol_tensor, (0, 2, 1))\n",
    "\n",
    "                if pred_vol_tensor is not None:\n",
    "                    pred_slice_tensor = pred_vol_tensor[plot_slice_idx]\n",
    "                    \n",
    "                    # Calculate Smooth L1 Loss for the current slice\n",
    "                    import torch.nn.functional as F\n",
    "                    loss = F.smooth_l1_loss(pred_slice_tensor, gt_slice_tensor, reduction='mean').item()\n",
    "\n",
    "                    # Keep track of the top 5 worst samples (highest loss)\n",
    "                    if len(worst_samples_data) < WORST_SAMPLES_TO_PLOT:\n",
    "                        worst_samples_data.append((loss, pred_slice_tensor.cpu().numpy(), i))\n",
    "                    else:\n",
    "                        # Find the sample with the minimum loss currently in our list\n",
    "                        min_loss_in_list = min(worst_samples_data, key=lambda x: x[0])\n",
    "                        if loss > min_loss_in_list[0]:\n",
    "                            # If current sample is worse, replace the \"best of the worst\"\n",
    "                            worst_samples_data.remove(min_loss_in_list)\n",
    "                            worst_samples_data.append((loss, pred_slice_tensor.cpu().numpy(), i))\n",
    "\n",
    "            # Sort the final list from worst to best for plotting\n",
    "            worst_samples_data.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "            # Call the new plotting function with the results\n",
    "            if worst_samples_data:\n",
    "                plot_worst_samples_comparison(\n",
    "                    ground_truth=gt_slice_np,\n",
    "                    mean_pred=mean_pred_slice,\n",
    "                    worst_samples_data=worst_samples_data,\n",
    "                    model_name=model_name,\n",
    "                    scan_name=scan_name,\n",
    "                    slice_idx=plot_slice_idx,\n",
    "                    tumor_coords_xy=tumor_xy\n",
    "                )\n",
    "\n",
    "        # --- Clean up memory ---\n",
    "        del gt_volume, gt_volume_np, mean_pred_vol, uncertainty_map_vol, errors_vol\n",
    "        gc.collect()\n",
    "        \n",
    "    all_results.extend(scan_results)\n",
    "\n",
    "# Convert results to a pandas DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n\\n✅ Analysis complete for all models and scans.\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a72ce",
   "metadata": {},
   "source": [
    "### Setup/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from pipeline.paths import Directories, Files\n",
    "from pipeline.utils import read_scans_agg_file\n",
    "import scipy.stats\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3b1eb",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f06590",
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE = \"7\"\n",
    "DATA_VERSION = \"13\"\n",
    "WORK_ROOT = \"D:/NoahSilverberg/ngCBCT\"\n",
    "SPLIT_TO_ANALYZE = 'VALIDATION'  # Options: 'TRAIN', 'VALIDATION', 'TEST'\n",
    "\n",
    "MODELS_TO_ANALYZE = [\n",
    "    # {\n",
    "    #     'name': 'SWAG Learning Rate 1e-2',\n",
    "    #     'type': 'stochastic',\n",
    "    #     'domain': 'FDK',\n",
    "    #     'model_version_root': 'MK7_MCDROPOUT_15_pct_NEW_SWAG_lr1e-2',\n",
    "    #     'count': 33,\n",
    "    # },\n",
    "    {\n",
    "        'name': 'MC Dropoout 15%',\n",
    "        'type': 'stochastic',\n",
    "        'domain': 'FDK',\n",
    "        'model_version_root': 'MK7_MCDROPOUT_15_pct_NEW',\n",
    "        'count': 50,\n",
    "    },\n",
    "    {\n",
    "        'name': 'MC Dropoout 30%',\n",
    "        'type': 'stochastic',\n",
    "        'domain': 'FDK',\n",
    "        'model_version_root': 'MK7_MCDROPOUT_30_pct_NEW',\n",
    "        'count': 50,\n",
    "    },\n",
    "    {\n",
    "        'name': 'MC Dropoout 50%',\n",
    "        'type': 'stochastic',\n",
    "        'domain': 'FDK',\n",
    "        'model_version_root': 'MK7_MCDROPOUT_50_pct_NEW',\n",
    "        'count': 50,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ensemble',\n",
    "        'type': 'ensemble',\n",
    "        'domain': 'FDK',\n",
    "        'model_version_root': 'MK7',\n",
    "        'count': 7,\n",
    "    },\n",
    "    # Add other models here\n",
    "]\n",
    "\n",
    "# Path to the .pt file containing tumor locations.\n",
    "# This is a 5D tensor [patient, scan, (x, y, z)]\n",
    "TUMOR_LOCATIONS_FILE = 'D:/NoahSilverberg/ngCBCT/3D_recon/tumor_location.pt'\n",
    "\n",
    "# --- Advanced Config ---\n",
    "SCANS_AGG_FILE = 'scans_to_agg.txt'\n",
    "SSIM_KWARGS = {\"K1\": 0.03, \"K2\": 0.06, \"win_size\": 15}\n",
    "SSIM_KWARGS_ = {\"k1\": 0.03, \"k2\": 0.06, \"kernel_size\": 15}\n",
    "\n",
    "# --- Setup ---\n",
    "# Create Directories and Files objects\n",
    "phase_dataver_dir = os.path.join(WORK_ROOT, f\"phase{PHASE}\", f\"DS{DATA_VERSION}\")\n",
    "DIRECTORIES = Directories(\n",
    "    projections_results_dir=os.path.join(phase_dataver_dir, \"results\", \"projections\"),\n",
    "    projections_gated_dir=os.path.join(WORK_ROOT, \"gated\", \"prj_mat\"),\n",
    "    reconstructions_dir=os.path.join(phase_dataver_dir, \"reconstructions\"),\n",
    "    reconstructions_gated_dir=os.path.join(WORK_ROOT, \"gated\", \"fdk_recon\"),\n",
    "    images_results_dir=os.path.join(phase_dataver_dir, \"results\", \"images\"),\n",
    ")\n",
    "FILES = Files(DIRECTORIES)\n",
    "\n",
    "# Load the list of scans\n",
    "scans_agg, scan_type_agg = read_scans_agg_file(SCANS_AGG_FILE)\n",
    "analysis_scans = scans_agg[SPLIT_TO_ANALYZE][:4]\n",
    "\n",
    "# Load tumor locations\n",
    "tumor_locations = torch.load(TUMOR_LOCATIONS_FILE, weights_only=False)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE} named '{torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}'\")\n",
    "\n",
    "print(f\"\\nConfiguration loaded.\")\n",
    "print(f\"Analyzing {len(analysis_scans)} scans from the '{SPLIT_TO_ANALYZE}' split.\")\n",
    "print(f\"Found {len(MODELS_TO_ANALYZE)} model(s) to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593c5fe",
   "metadata": {},
   "source": [
    "### Data loading/prep functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ground_truth(files_obj: Files, scan_info, domain, slice_idx=None):\n",
    "    \"\"\"\n",
    "    Loads the ground truth data for a given scan and domain.\n",
    "    \"\"\"\n",
    "    patient, scan, scan_type = scan_info\n",
    "    \n",
    "    if domain == 'PROJ':\n",
    "        gt_path = files_obj.get_projections_results_filepath('fdk', patient, scan, scan_type, gated=True)\n",
    "        data = torch.from_numpy(scipy.io.loadmat(gt_path)['prj']).detach().permute(1, 0, 2)\n",
    "    elif domain == 'FDK':\n",
    "        gt_path = files_obj.get_recon_filepath(\"fdk\", patient, scan, scan_type, gated=True, ensure_exists=False)\n",
    "        data = torch.load(gt_path).detach()\n",
    "        data = data[20:-20, :, :]\n",
    "        data = 25. * torch.clip(data, min=0.0, max=0.04)\n",
    "    elif domain == 'IMAG':\n",
    "        # The ground truth for the IMAG domain is the FDK of the gated projection\n",
    "        gt_path = files_obj.get_recon_filepath(\"fdk\", patient, scan, scan_type, gated=True, ensure_exists=False)\n",
    "        data = torch.load(gt_path).detach()\n",
    "        data = data[20:-20, :, :]\n",
    "        data = 25. * torch.clip(data, min=0.0, max=0.04)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown domain: {domain}\")\n",
    "\n",
    "    if slice_idx is not None and data.ndim == 3:\n",
    "        return data[slice_idx]\n",
    "    return data\n",
    "\n",
    "def load_predictions(files_obj: Files, model_config, scan_info, slice_idx=None):\n",
    "    \"\"\"\n",
    "    Loads all predictions for a given model, scan, and domain.\n",
    "    \"\"\"\n",
    "    patient, scan, scan_type = scan_info\n",
    "    domain = model_config['domain']\n",
    "    root = model_config['model_version_root']\n",
    "    count = model_config['count']\n",
    "    model_type = model_config['type']\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    print(f\"Loading {count} predictions for {model_config['name']}...\")\n",
    "    \n",
    "    for i in tqdm(range(count), desc=\"Loading predictions\", leave=False):\n",
    "        passthrough_num = None\n",
    "        model_version = root\n",
    "\n",
    "        if model_type == 'ensemble':\n",
    "            model_version = f\"{root}_{i+1:02d}\"\n",
    "        elif model_type == 'stochastic':\n",
    "            passthrough_num = i\n",
    "\n",
    "        if domain == 'PROJ':\n",
    "            pred_path = files_obj.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "            pred = torch.from_numpy(scipy.io.loadmat(pred_path)['prj']).detach().permute(1, 0, 2)\n",
    "        elif domain == 'FDK':\n",
    "            pred_path = files_obj.get_recon_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "            pred = torch.load(pred_path).detach()\n",
    "            pred = pred[20:-20, :, :]\n",
    "            pred = 25. * torch.clip(pred, min=0.0, max=0.04)\n",
    "        elif domain == 'IMAG':\n",
    "            # This assumes the results are saved with the ID model version name\n",
    "            pred_path = files_obj.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "            pred = torch.load(pred_path).detach()\n",
    "            pred = torch.squeeze(pred, dim=1)\n",
    "            pred = torch.permute(pred, (0, 2, 1))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown domain: {domain}\")\n",
    "            \n",
    "        predictions.append(pred)\n",
    "\n",
    "    predictions_tensor = torch.stack(predictions)\n",
    "    \n",
    "    if slice_idx is not None and predictions_tensor.ndim == 4:\n",
    "        return predictions_tensor[:, slice_idx, :, :]\n",
    "        \n",
    "    return predictions_tensor\n",
    "\n",
    "print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f8db4",
   "metadata": {},
   "source": [
    "### Metric calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d913366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ause_sparsification(uncertainty, errors):\n",
    "    \"\"\"\n",
    "    Calculates the Area Under the Sparsification Error curve (AUSE) efficiently.\n",
    "    \"\"\"\n",
    "    uncertainty_flat = uncertainty.flatten()\n",
    "    errors_flat = errors.flatten()\n",
    "    \n",
    "    # Normalize by overall MAE so the curve starts at 1\n",
    "    overall_mae = np.mean(errors_flat)\n",
    "    \n",
    "    def get_sparsification_curve_fast(sorted_errs):\n",
    "        n_pixels = len(sorted_errs)\n",
    "        cumulative_errors = np.cumsum(sorted_errs)\n",
    "        total_error_sum = cumulative_errors[-1]\n",
    "        sum_errors_removed = np.insert(cumulative_errors[:-1], 0, 0)\n",
    "        sum_errors_remaining = total_error_sum - sum_errors_removed\n",
    "        n_remaining = np.arange(n_pixels, 0, -1)\n",
    "        curve = sum_errors_remaining / n_remaining\n",
    "        if overall_mae > 0:\n",
    "            curve = curve / overall_mae # Normalize the curve\n",
    "        return curve\n",
    "\n",
    "    # Move arrays to GPU using torch for sorting\n",
    "    uncertainty_tensor = torch.from_numpy(uncertainty_flat).cuda()\n",
    "    errors_tensor = torch.from_numpy(errors_flat).cuda()\n",
    "\n",
    "    # Model curve (sorted by uncertainty)\n",
    "    model_sorted_indices = torch.argsort(uncertainty_tensor, descending=True)\n",
    "    model_sorted_errors = errors_tensor[model_sorted_indices].cpu().numpy()\n",
    "    model_curve = get_sparsification_curve_fast(model_sorted_errors)\n",
    "\n",
    "    # Oracle curve (sorted by error)\n",
    "    oracle_sorted_errors = torch.sort(errors_tensor, descending=True)[0].cpu().numpy()\n",
    "    oracle_curve = get_sparsification_curve_fast(oracle_sorted_errors)\n",
    "    \n",
    "    # The AUSE is the area between the two normalized curves\n",
    "    ause = np.mean(np.abs(model_curve - oracle_curve))\n",
    "    return ause\n",
    "\n",
    "def calculate_ece(ground_truth, mean_pred, uncertainty_map, n_levels=20):\n",
    "    \"\"\"\n",
    "    Calculates the weighted calibration error for regression tasks based on Kuleshov et al., 2018.\n",
    "    \"\"\"\n",
    "    gt_flat = ground_truth.flatten()\n",
    "    pred_flat = mean_pred.flatten()\n",
    "    uncert_flat = uncertainty_map.flatten()\n",
    "\n",
    "    pred_cdfs = scipy.stats.norm.cdf(gt_flat, loc=pred_flat, scale=uncert_flat)\n",
    "    expected_confidence_levels = np.linspace(0, 1, n_levels)\n",
    "    observed_frequencies = np.array([np.mean(pred_cdfs <= p_j) for p_j in expected_confidence_levels])\n",
    "    \n",
    "    bin_boundaries = np.copy(expected_confidence_levels)\n",
    "    bin_weights = np.zeros(n_levels)\n",
    "    for i in range(1, n_levels):\n",
    "        lower_bound = bin_boundaries[i-1]\n",
    "        upper_bound = bin_boundaries[i]\n",
    "        points_in_bin = (pred_cdfs > lower_bound) & (pred_cdfs <= upper_bound)\n",
    "        bin_weights[i] = np.mean(points_in_bin)\n",
    "        \n",
    "    if np.sum(bin_weights) > 0:\n",
    "        bin_weights /= np.sum(bin_weights)\n",
    "\n",
    "    squared_errors = (expected_confidence_levels - observed_frequencies)**2\n",
    "    weighted_calibration_error = np.sum(bin_weights * squared_errors)\n",
    "    return weighted_calibration_error\n",
    "\n",
    "def calculate_spearman_correlation(uncertainty, errors):\n",
    "    \"\"\"\n",
    "    Calculates the Spearman's Rank Correlation Coefficient between\n",
    "    the uncertainty and the absolute error.\n",
    "    \"\"\"\n",
    "    uncertainty_flat = uncertainty.flatten()\n",
    "    errors_flat = errors.flatten()\n",
    "    \n",
    "    # spearmanr returns correlation and p-value; we only need the correlation\n",
    "    correlation, _ = scipy.stats.spearmanr(uncertainty_flat, errors_flat)\n",
    "    return correlation\n",
    "\n",
    "import torchmetrics\n",
    "import torchmetrics.image\n",
    "\n",
    "def calculate_volume_metrics_2_pass(files_obj, model_config, scan_info, gt_volume, device):\n",
    "    \"\"\"\n",
    "    Calculates stats and metrics using a two-pass algorithm for variance for improved stability.\n",
    "    Also includes a robust PSNR calculation that handles infinite values.\n",
    "    Pass 1: Calculate the mean of all predictions.\n",
    "    Pass 2: Calculate variance and other metrics using the pre-calculated mean.\n",
    "    \"\"\"\n",
    "    n_samples = model_config['count']\n",
    "    gt_volume = gt_volume.to(device) # Ensure GT is on the correct device\n",
    "\n",
    "    def prediction_generator():\n",
    "        # This generator yields tensors directly on the GPU\n",
    "        patient, scan, scan_type = scan_info\n",
    "        domain = model_config['domain']\n",
    "        root = model_config['model_version_root']\n",
    "        model_type = model_config['type']\n",
    "        for i in range(n_samples):\n",
    "            passthrough_num = None\n",
    "            model_version = root\n",
    "            if model_type == 'ensemble': model_version = f\"{root}_{i+1:02d}\"\n",
    "            elif model_type == 'stochastic': passthrough_num = i\n",
    "\n",
    "            if domain == 'PROJ':\n",
    "                pred_path = files_obj.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                pred = torch.from_numpy(scipy.io.loadmat(pred_path)['prj']).detach().permute(1, 0, 2)\n",
    "            elif domain == 'FDK':\n",
    "                pred_path = files_obj.get_recon_filepath(model_version, patient, scan, scan_type, gated=False, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                pred = torch.load(pred_path).detach()\n",
    "                pred = pred[20:-20, :, :]\n",
    "                pred = 25. * torch.clip(pred, min=0.0, max=0.04)\n",
    "            elif domain == 'IMAG':\n",
    "                pred_path = files_obj.get_images_results_filepath(model_version, patient, scan, passthrough_num=passthrough_num, ensure_exists=False)\n",
    "                pred = torch.load(pred_path).detach()\n",
    "                pred = torch.squeeze(pred, dim=1)\n",
    "                pred = torch.permute(pred, (0, 2, 1))\n",
    "            yield pred.to(device)\n",
    "\n",
    "    # --- Pass 1: Calculate Mean ---\n",
    "    print(\"Pass 1: Calculating mean prediction...\")\n",
    "    mean_volume = torch.zeros_like(gt_volume)\n",
    "    # Using a simple sum and divide for the mean\n",
    "    for pred_volume in tqdm(prediction_generator(), total=n_samples, desc=\"Pass 1/2 (Mean)\", leave=False):\n",
    "        mean_volume += pred_volume\n",
    "    mean_volume /= n_samples\n",
    "\n",
    "    # --- Pass 2: Calculate Variance and Metrics ---\n",
    "    print(\"Pass 2: Calculating variance and metrics...\")\n",
    "    sum_sq_diff_volume = torch.zeros_like(gt_volume)\n",
    "    sample_avg_ssims, sample_avg_psnrs, sample_avg_mses, sample_avg_maes = [], [], [], []\n",
    "\n",
    "    # Initialize metrics on the specified device\n",
    "    data_range = gt_volume.max() - gt_volume.min()\n",
    "    ssim_metric = torchmetrics.image.StructuralSimilarityIndexMeasure(data_range=data_range, **SSIM_KWARGS_).to(device)\n",
    "\n",
    "    # PSNR metric that returns per-slice results to handle 'inf'\n",
    "    psnr_metric = torchmetrics.image.PeakSignalNoiseRatio(data_range=data_range, reduction='none').to(device)\n",
    "\n",
    "    for pred_volume in tqdm(prediction_generator(), total=n_samples, desc=\"Pass 2/2 (Var & Metrics)\", leave=False):\n",
    "        # Variance calculation\n",
    "        diff = pred_volume - mean_volume\n",
    "        sum_sq_diff_volume += diff * diff\n",
    "\n",
    "        # Per-sample metrics\n",
    "        if gt_volume.ndim > 2:\n",
    "            pred_vol_batch = pred_volume.unsqueeze(1)\n",
    "            gt_vol_batch = gt_volume.unsqueeze(1)\n",
    "            \n",
    "            sample_avg_ssims.append(ssim_metric(pred_vol_batch, gt_vol_batch).item())\n",
    "            sample_avg_mses.append(torch.mean((gt_volume - pred_volume)**2).item())\n",
    "            sample_avg_maes.append(torch.mean(torch.abs(gt_volume - pred_volume)).item())\n",
    "\n",
    "            # --- Robust PSNR Calculation ---\n",
    "            psnr_per_slice = psnr_metric(pred_vol_batch, gt_vol_batch)\n",
    "            finite_psnrs = psnr_per_slice[torch.isfinite(psnr_per_slice)] # Filter out inf values\n",
    "            if finite_psnrs.numel() > 0:\n",
    "                sample_avg_psnrs.append(torch.mean(finite_psnrs).item())\n",
    "            else:\n",
    "                # Handle case where all slices are perfect matches\n",
    "                sample_avg_psnrs.append(100.0) # Assign a high value\n",
    "\n",
    "    # Finalize variance and uncertainty\n",
    "    if n_samples > 1:\n",
    "        # Using n_samples for population standard deviation, as in the original code.\n",
    "        # For sample standard deviation, use (n_samples - 1).\n",
    "        variance_volume_map = sum_sq_diff_volume / n_samples\n",
    "        uncertainty_volume_map = torch.sqrt(variance_volume_map)\n",
    "    else:\n",
    "        uncertainty_volume_map = torch.zeros_like(mean_volume)\n",
    "\n",
    "    # --- Calculate metrics for the mean prediction ---\n",
    "    metrics = {}\n",
    "    if gt_volume.ndim > 2:\n",
    "        mean_vol_batch = mean_volume.unsqueeze(1)\n",
    "        gt_vol_batch = gt_volume.unsqueeze(1)\n",
    "        \n",
    "        metrics['mean_ssim'] = ssim_metric(mean_vol_batch, gt_vol_batch).item()\n",
    "        metrics['mean_mse'] = torch.mean((gt_volume - mean_volume)**2).item()\n",
    "        metrics['mean_mae'] = torch.mean(torch.abs(gt_volume - mean_volume)).item()\n",
    "\n",
    "        # Robust PSNR for the mean prediction\n",
    "        mean_psnr_per_slice = psnr_metric(mean_vol_batch, gt_vol_batch)\n",
    "        finite_mean_psnrs = mean_psnr_per_slice[torch.isfinite(mean_psnr_per_slice)]\n",
    "        if finite_mean_psnrs.numel() > 0:\n",
    "            metrics['mean_psnr'] = torch.mean(finite_mean_psnrs).item()\n",
    "        else:\n",
    "            metrics['mean_psnr'] = 100.0\n",
    "\n",
    "    # --- Aggregate per-sample metrics ---\n",
    "    metrics['sample_avg_ssim'] = np.mean(sample_avg_ssims) if sample_avg_ssims else 0\n",
    "    metrics['sample_avg_psnr'] = np.mean(sample_avg_psnrs) if sample_avg_psnrs else 0\n",
    "    metrics['sample_avg_mse'] = np.mean(sample_avg_mses) if sample_avg_mses else 0\n",
    "    metrics['sample_avg_mae'] = np.mean(sample_avg_maes) if sample_avg_maes else 0\n",
    "\n",
    "    return metrics, mean_volume, uncertainty_volume_map\n",
    "\n",
    "print(\"Metric calculation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958c88d",
   "metadata": {},
   "source": [
    "### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfa6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_comparison(mean_pred, ground_truth, uncertainty_map, model_name, scan_name, slice_idx, tumor_coords_xy=None):\n",
    "    \"\"\"Plots the GT, mean prediction, absolute error, and uncertainty map.\"\"\"\n",
    "    error_map = np.abs(ground_truth - mean_pred)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    fig.suptitle(f'{model_name} - {scan_name} - Slice {slice_idx} (Mean vs. GT)', fontsize=16)\n",
    "\n",
    "    im1 = axes[0].imshow(ground_truth, cmap='gray')\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "    fig.colorbar(im1, ax=axes[0])\n",
    "\n",
    "    if tumor_coords_xy:\n",
    "        x, y = tumor_coords_xy\n",
    "        for i in range(4):\n",
    "            axes[i].annotate('', xy=(x, y), xytext=(x - 30, y - 30),\n",
    "                            arrowprops=dict(facecolor='red', edgecolor='red', shrink=0.05, width=1, headwidth=5, headlength=5))\n",
    "\n",
    "    im2 = axes[1].imshow(mean_pred, cmap='gray')\n",
    "    axes[1].set_title('Mean Prediction')\n",
    "    axes[1].axis('off')\n",
    "    fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    im3 = axes[2].imshow(error_map, cmap='magma')\n",
    "    axes[2].set_title('Absolute Error Map')\n",
    "    axes[2].axis('off')\n",
    "    fig.colorbar(im3, ax=axes[2])\n",
    "\n",
    "    im4 = axes[3].imshow(uncertainty_map, cmap='viridis')\n",
    "    axes[3].set_title('Uncertainty (Std Dev)')\n",
    "    axes[3].axis('off')\n",
    "    fig.colorbar(im4, ax=axes[3])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_ssim_map(ssim_map, model_name, scan_name):\n",
    "    \"\"\"Plots the SSIM map.\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(ssim_map, cmap='viridis', vmin=0, vmax=1)\n",
    "    plt.title(f'SSIM Map - {model_name} - {scan_name}')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_calibration_curve(ground_truth, mean_pred, uncertainty_map, model_name, scan_name, n_levels=20):\n",
    "    \"\"\"\n",
    "    Plots the calibration curve with a marginal histogram below the x-axis\n",
    "    showing the distribution of the predicted CDF values.\n",
    "    \"\"\"\n",
    "    gt_flat = ground_truth.flatten()\n",
    "    pred_flat = mean_pred.flatten()\n",
    "    uncert_flat = uncertainty_map.flatten()\n",
    "\n",
    "    # Calculate the predicted CDF value for each point\n",
    "    pred_cdfs = scipy.stats.norm.cdf(gt_flat, loc=pred_flat, scale=uncert_flat)\n",
    "    \n",
    "    # --- Create figure with two subplots, sharing the x-axis ---\n",
    "    fig, (ax_cal, ax_hist) = plt.subplots(\n",
    "        2, 1,\n",
    "        figsize=(8, 8),\n",
    "        sharex=True,\n",
    "        gridspec_kw={'height_ratios': [3, 1]} # Main plot is 3x taller\n",
    "    )\n",
    "    \n",
    "    # --- Main Calibration Plot (top) ---\n",
    "    expected_confidence_levels = np.linspace(0, 1, n_levels)\n",
    "    observed_frequencies = np.array([np.mean(pred_cdfs <= p_j) for p_j in expected_confidence_levels])\n",
    "\n",
    "    ax_cal.plot([0, 1], [0, 1], '--', color='grey', label='Perfectly Calibrated')\n",
    "    ax_cal.plot(expected_confidence_levels, observed_frequencies, '-o', label='Model Calibration')\n",
    "    ax_cal.set_ylabel('Observed Confidence Level')\n",
    "    ax_cal.set_title(f'Calibration Plot - {model_name} - {scan_name}')\n",
    "    ax_cal.legend()\n",
    "    ax_cal.grid(True, linestyle=':')\n",
    "\n",
    "    # --- Marginal Histogram (bottom) ---\n",
    "    ax_hist.hist(pred_cdfs, bins=50, range=(0,1), density=True, color='steelblue', alpha=0.8)\n",
    "    ax_hist.set_xlabel('Expected Confidence Level (Predicted CDF)')\n",
    "    ax_hist.set_ylabel('Density')\n",
    "    ax_hist.set_yscale('log')\n",
    "    # ax_hist.set_yticks([]) # Hide y-ticks for clarity\n",
    "\n",
    "    # Final adjustments\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_sparsification_curve(uncertainty, errors, model_name, scan_name):\n",
    "    \"\"\"\n",
    "    Plots the model and oracle sparsification curves used for AUSE calculation.\n",
    "    \"\"\"\n",
    "    uncertainty_flat = uncertainty.flatten()\n",
    "    errors_flat = errors.flatten()\n",
    "    \n",
    "    def get_sparsification_curve_fast(sorted_errs, overall_mae):\n",
    "        n_pixels = len(sorted_errs)\n",
    "        cumulative_errors = np.cumsum(sorted_errs)\n",
    "        total_error_sum = cumulative_errors[-1]\n",
    "        sum_errors_removed = np.insert(cumulative_errors[:-1], 0, 0)\n",
    "        sum_errors_remaining = total_error_sum - sum_errors_removed\n",
    "        n_remaining = np.arange(n_pixels, 0, -1)\n",
    "        curve = sum_errors_remaining / n_remaining\n",
    "        if overall_mae > 0:\n",
    "            curve = curve / overall_mae\n",
    "        return curve\n",
    "    \n",
    "    overall_mae = np.mean(errors_flat)\n",
    "\n",
    "    # Model curve (sorted by uncertainty)\n",
    "    model_sorted_indices = np.argsort(uncertainty_flat)[::-1]\n",
    "    model_sorted_errors = errors_flat[model_sorted_indices]\n",
    "    model_curve = get_sparsification_curve_fast(model_sorted_errors, overall_mae)\n",
    "    \n",
    "    # Oracle curve (sorted by error)\n",
    "    oracle_sorted_errors = np.sort(errors_flat)[::-1]\n",
    "    oracle_curve = get_sparsification_curve_fast(oracle_sorted_errors, overall_mae)\n",
    "    \n",
    "    # X-axis: fraction of pixels removed\n",
    "    fraction_removed = np.linspace(0, 1, len(model_curve))\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot(fraction_removed, model_curve, label='Model (Sort by Uncertainty)')\n",
    "    plt.plot(fraction_removed, oracle_curve, '--', label='Oracle (Sort by Error)')\n",
    "    plt.xlabel('Fraction of Pixels Removed')\n",
    "    plt.ylabel('Mean Absolute Error of Remaining Pixels')\n",
    "    plt.title(f'Sparsification Curve - {model_name} - {scan_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.show()\n",
    "\n",
    "def plot_samples_comparison(ground_truth, mean_pred, samples, model_name, scan_name, slice_idx, tumor_coords_xy=None):\n",
    "    \"\"\"\n",
    "    Plots the ground truth, mean prediction, and a few individual sample predictions.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth (np.ndarray): The 2D ground truth slice.\n",
    "        mean_pred (np.ndarray): The 2D mean prediction slice.\n",
    "        samples (list of np.ndarray): A list of 2D sample prediction slices.\n",
    "        model_name (str): The name of the model for the title.\n",
    "        scan_name (str): The name of the scan for the title.\n",
    "        slice_idx (int): The index of the slice for the title.\n",
    "        tumor_coords_xy (tuple, optional): (x, y) coordinates for the tumor arrow.\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "    # Total columns = 1 for GT + 1 for Mean + N for samples\n",
    "    num_cols = 2 + num_samples\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_cols, figsize=(4 * num_cols, 4.5), constrained_layout=True)\n",
    "    fig.suptitle(f'{model_name} - {scan_name} - Slice {slice_idx} (GT, Mean, and Samples)', fontsize=16)\n",
    "\n",
    "    # Determine a consistent grayscale range based on the ground truth and mean\n",
    "    vmin = min(ground_truth.min(), mean_pred.min())\n",
    "    vmax = max(ground_truth.max(), mean_pred.max())\n",
    "\n",
    "    # --- Plot Ground Truth ---\n",
    "    axes[0].imshow(ground_truth, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # --- Plot Mean Prediction ---\n",
    "    axes[1].imshow(mean_pred, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[1].set_title('Mean Prediction')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # --- Plot Samples ---\n",
    "    for i in range(num_samples):\n",
    "        ax = axes[i + 2]\n",
    "        im = ax.imshow(samples[i], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f'Sample {i+1}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # --- Add Tumor Arrow ---\n",
    "    if tumor_coords_xy:\n",
    "        x, y = tumor_coords_xy\n",
    "        for ax in axes:\n",
    "            ax.annotate('', xy=(x, y), xytext=(x - 30, y - 30),\n",
    "                        arrowprops=dict(facecolor='red', edgecolor='red', shrink=0.05, \n",
    "                                        width=1, headwidth=5, headlength=5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_worst_samples_comparison(ground_truth, mean_pred, worst_samples_data, model_name, scan_name, slice_idx, tumor_coords_xy=None):\n",
    "    \"\"\"\n",
    "    Plots the ground truth, mean prediction, and the worst-performing sample predictions.\n",
    "    \n",
    "    Args:\n",
    "        ground_truth (np.ndarray): The 2D ground truth slice.\n",
    "        mean_pred (np.ndarray): The 2D mean prediction slice.\n",
    "        worst_samples_data (list): A list of tuples, where each tuple is \n",
    "                                   (loss, sample_slice_numpy, sample_index).\n",
    "        model_name (str): The name of the model for the title.\n",
    "        scan_name (str): The name of the scan for the title.\n",
    "        slice_idx (int): The index of the slice for the title.\n",
    "        tumor_coords_xy (tuple, optional): (x, y) coordinates for the tumor arrow.\n",
    "    \"\"\"\n",
    "    num_samples = len(worst_samples_data)\n",
    "    num_cols = 2 + num_samples\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_cols, figsize=(4 * num_cols, 5), constrained_layout=True)\n",
    "    fig.suptitle(f'{model_name} - {scan_name} - Slice {slice_idx} (Top {num_samples} Worst Samples by SmoothL1Loss)', fontsize=16)\n",
    "\n",
    "    # Determine a consistent grayscale range\n",
    "    vmin = min(ground_truth.min(), mean_pred.min())\n",
    "    vmax = max(ground_truth.max(), mean_pred.max())\n",
    "\n",
    "    # --- Plot Ground Truth ---\n",
    "    axes[0].imshow(ground_truth, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title('Ground Truth')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # --- Plot Mean Prediction ---\n",
    "    axes[1].imshow(mean_pred, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    axes[1].set_title('Mean Prediction')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # --- Plot Worst Samples ---\n",
    "    for i in range(num_samples):\n",
    "        loss, sample_slice, sample_idx = worst_samples_data[i]\n",
    "        ax = axes[i + 2]\n",
    "        im = ax.imshow(sample_slice, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        # Add the loss and original sample number to the title\n",
    "        ax.set_title(f'Sample #{sample_idx}\\nLoss: {loss:.4f}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    # --- Add Tumor Arrow ---\n",
    "    if tumor_coords_xy:\n",
    "        x, y = tumor_coords_xy\n",
    "        for ax in axes:\n",
    "            ax.annotate('', xy=(x, y), xytext=(x - 30, y - 30),\n",
    "                        arrowprops=dict(facecolor='red', edgecolor='red', shrink=0.05, \n",
    "                                        width=1, headwidth=5, headlength=5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c321bd",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42610a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will store dictionaries of results for each scan and model\n",
    "all_results = []\n",
    "\n",
    "for model_config in MODELS_TO_ANALYZE:\n",
    "    model_name = model_config['name']\n",
    "    domain = model_config['domain']\n",
    "    \n",
    "    scan_results = []\n",
    "\n",
    "    for scan_info in tqdm(analysis_scans, desc=f\"Analyzing Model: {model_name}\"):\n",
    "        patient, scan, _ = scan_info\n",
    "        scan_name = f\"p{patient}_{scan}\"\n",
    "        \n",
    "        # --- Determine Domain and Plotting Slice ---\n",
    "        is_visual_domain = domain in ['FDK', 'IMAG']\n",
    "        plot_slice_idx = None\n",
    "        tumor_xy = None\n",
    "        \n",
    "        if is_visual_domain:\n",
    "            if 'tumor_locations' in locals() and tumor_locations is not None:\n",
    "                try:\n",
    "                    loc = tumor_locations[int(patient), int(scan)]\n",
    "                    tumor_xy = (loc[1].item(), loc[0].item())\n",
    "                    plot_slice_idx = int(loc[2].item()) - 20\n",
    "                except (IndexError, TypeError):\n",
    "                    print(f\"Warning: Could not find tumor location for {scan_name}. Plotting will not have an arrow.\")\n",
    "                    plot_slice_idx = 100\n",
    "            else:\n",
    "                plot_slice_idx = 100\n",
    "        \n",
    "        # --- Data Loading (Ground Truth Only) ---\n",
    "        gt_volume = load_ground_truth(FILES, scan_info, domain, slice_idx=None)\n",
    "        gt_volume_np = gt_volume.cpu().numpy()\n",
    "        \n",
    "        # --- Iterative Metric Calculation ---\n",
    "        print(\"Calculating metrics iteratively...\")\n",
    "        iq_metrics, mean_pred_vol, uncertainty_map_vol = calculate_volume_metrics_2_pass(\n",
    "            FILES, model_config, scan_info, gt_volume.to(DEVICE), DEVICE\n",
    "        )\n",
    "        mean_pred_vol = mean_pred_vol.cpu().numpy()\n",
    "        uncertainty_map_vol = uncertainty_map_vol.cpu().numpy()\n",
    "        \n",
    "        # --- Uncertainty Metric Calculation ---\n",
    "        errors_vol = np.abs(gt_volume_np - mean_pred_vol)\n",
    "        print(\"Calculating AUSE...\")\n",
    "        ause_val = calculate_ause_sparsification(uncertainty_map_vol, errors_vol)\n",
    "        # print(\"Calculating ECE...\")\n",
    "        # ece_val = calculate_ece(gt_volume_np, mean_pred_vol, uncertainty_map_vol)\n",
    "        print(\"Calculating Spearman's correlation...\")\n",
    "        spearman_val = calculate_spearman_correlation(uncertainty_map_vol, errors_vol)\n",
    "        \n",
    "        # --- Store Results ---\n",
    "        scan_result = {\n",
    "            'model_name': model_name,\n",
    "            'scan_name': scan_name,\n",
    "            **iq_metrics,\n",
    "            'ause': ause_val,\n",
    "            # 'ece': ece_val,\n",
    "            'spearman_corr': spearman_val,\n",
    "        }\n",
    "        scan_results.append(scan_result)\n",
    "        \n",
    "        # # --- Visualization ---\n",
    "        # print(f\"\\n--- Results for {model_name} on {scan_name} ---\")\n",
    "        \n",
    "        # # plot_calibration_curve(gt_volume_np, mean_pred_vol, uncertainty_map_vol, model_name, scan_name)\n",
    "        # plot_sparsification_curve(uncertainty_map_vol, errors_vol, model_name, scan_name)\n",
    "        \n",
    "        # if is_visual_domain:\n",
    "        #     gt_slice_np = gt_volume_np[plot_slice_idx]\n",
    "        #     mean_pred_slice = mean_pred_vol[plot_slice_idx]\n",
    "        #     uncertainty_map_slice = uncertainty_map_vol[plot_slice_idx]\n",
    "        #     _, ssim_map_val = ssim(gt_slice_np, mean_pred_slice, \n",
    "        #                           data_range=(np.max(gt_slice_np) - np.min(gt_slice_np)), \n",
    "        #                           full=True, **SSIM_KWARGS)\n",
    "            \n",
    "        #     plot_mean_comparison(mean_pred_slice, gt_slice_np, uncertainty_map_slice, \n",
    "        #                          model_name, scan_name, plot_slice_idx, tumor_coords_xy=tumor_xy)\n",
    "        #     plot_ssim_map(ssim_map_val, model_name, scan_name)\n",
    "\n",
    "        # --- Clean up memory ---\n",
    "        del gt_volume, gt_volume_np, mean_pred_vol, uncertainty_map_vol, errors_vol\n",
    "        gc.collect()\n",
    "        \n",
    "    all_results.extend(scan_results)\n",
    "\n",
    "# Convert results to a pandas DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n\\n✅ Analysis complete for all models and scans.\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60e045",
   "metadata": {},
   "source": [
    "### Summary/Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c599050",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(MODELS_TO_ANALYZE) > 1:\n",
    "    summary_data = []\n",
    "    \n",
    "    # Only aggregate numeric columns\n",
    "    numeric_cols = results_df.select_dtypes(include=[np.number]).columns\n",
    "    summary = results_df.groupby('model_name')[numeric_cols].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "    # Prepare summary_display with formatted mean ± std for each metric\n",
    "    summary_display = pd.DataFrame()\n",
    "    summary_display['model_name'] = summary['model_name']\n",
    "    for col in numeric_cols:\n",
    "        mean_col = (col, 'mean')\n",
    "        std_col = (col, 'std')\n",
    "        summary_display[col] = summary[mean_col].map('{:.4f}'.format) + ' ± ' + summary[std_col].map('{:.4f}'.format)\n",
    "    \n",
    "    print(\"\\n\\n=======================================================\")\n",
    "    print(\"               Model Comparison Summary\")\n",
    "    print(\"=======================================================\")\n",
    "    \n",
    "    display(summary_display)\n",
    "\n",
    "else:\n",
    "    print(\"\\nOnly one model was analyzed. No comparison table to generate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will store dictionaries of results for each scan and model\n",
    "all_results = []\n",
    "\n",
    "for model_config in MODELS_TO_ANALYZE:\n",
    "    model_name = model_config['name']\n",
    "    domain = model_config['domain']\n",
    "    \n",
    "    scan_results = []\n",
    "\n",
    "    for scan_info in tqdm(analysis_scans, desc=f\"Analyzing Model: {model_name}\"):\n",
    "        patient, scan, _ = scan_info\n",
    "        scan_name = f\"p{patient}_{scan}\"\n",
    "        \n",
    "        # --- Determine Domain and Plotting Slice ---\n",
    "        is_visual_domain = domain in ['FDK', 'IMAG']\n",
    "        plot_slice_idx = None\n",
    "        tumor_xy = None\n",
    "        \n",
    "        if is_visual_domain:\n",
    "            if 'tumor_locations' in locals() and tumor_locations is not None:\n",
    "                try:\n",
    "                    loc = tumor_locations[int(patient), int(scan)]\n",
    "                    tumor_xy = (loc[1].item(), loc[0].item())\n",
    "                    plot_slice_idx = int(loc[2].item()) - 20\n",
    "                except (IndexError, TypeError):\n",
    "                    print(f\"Warning: Could not find tumor location for {scan_name}. Plotting will not have an arrow.\")\n",
    "                    plot_slice_idx = 100\n",
    "            else:\n",
    "                plot_slice_idx = 100\n",
    "        \n",
    "        # --- Data Loading (Ground Truth Only) ---\n",
    "        gt_volume = load_ground_truth(FILES, scan_info, domain, slice_idx=None)\n",
    "        gt_volume_np = gt_volume.cpu().numpy()\n",
    "        \n",
    "        # --- Iterative Metric Calculation ---\n",
    "        print(\"Calculating metrics iteratively...\")\n",
    "        iq_metrics, mean_pred_vol, uncertainty_map_vol = calculate_volume_metrics_2_pass(\n",
    "            FILES, model_config, scan_info, gt_volume.to(DEVICE), DEVICE\n",
    "        )\n",
    "        mean_pred_vol = mean_pred_vol.cpu().numpy()\n",
    "        uncertainty_map_vol = uncertainty_map_vol.cpu().numpy()\n",
    "        \n",
    "        # --- Uncertainty Metric Calculation ---\n",
    "        errors_vol = np.abs(gt_volume_np - mean_pred_vol)\n",
    "        print(\"Calculating AUSE...\")\n",
    "        ause_val = calculate_ause_sparsification(uncertainty_map_vol, errors_vol)\n",
    "        # print(\"Calculating ECE...\")\n",
    "        # ece_val = calculate_ece(gt_volume_np, mean_pred_vol, uncertainty_map_vol)\n",
    "        print(\"Calculating Spearman's correlation...\")\n",
    "        spearman_val = calculate_spearman_correlation(uncertainty_map_vol, errors_vol)\n",
    "        \n",
    "        # --- Store Results ---\n",
    "        scan_result = {\n",
    "            'model_name': model_name,\n",
    "            'scan_name': scan_name,\n",
    "            **iq_metrics,\n",
    "            'ause': ause_val,\n",
    "            # 'ece': ece_val,\n",
    "            'spearman_corr': spearman_val,\n",
    "        }\n",
    "        scan_results.append(scan_result)\n",
    "        \n",
    "        # # --- Visualization ---\n",
    "        # print(f\"\\n--- Results for {model_name} on {scan_name} ---\")\n",
    "        \n",
    "        # # plot_calibration_curve(gt_volume_np, mean_pred_vol, uncertainty_map_vol, model_name, scan_name)\n",
    "        # plot_sparsification_curve(uncertainty_map_vol, errors_vol, model_name, scan_name)\n",
    "        \n",
    "        # if is_visual_domain:\n",
    "        #     gt_slice_np = gt_volume_np[plot_slice_idx]\n",
    "        #     mean_pred_slice = mean_pred_vol[plot_slice_idx]\n",
    "        #     uncertainty_map_slice = uncertainty_map_vol[plot_slice_idx]\n",
    "        #     _, ssim_map_val = ssim(gt_slice_np, mean_pred_slice, \n",
    "        #                           data_range=(np.max(gt_slice_np) - np.min(gt_slice_np)), \n",
    "        #                           full=True, **SSIM_KWARGS)\n",
    "            \n",
    "        #     plot_mean_comparison(mean_pred_slice, gt_slice_np, uncertainty_map_slice, \n",
    "        #                          model_name, scan_name, plot_slice_idx, tumor_coords_xy=tumor_xy)\n",
    "        #     plot_ssim_map(ssim_map_val, model_name, scan_name)\n",
    "\n",
    "        # --- Clean up memory ---\n",
    "        del gt_volume, gt_volume_np, mean_pred_vol, uncertainty_map_vol, errors_vol\n",
    "        gc.collect()\n",
    "        \n",
    "    all_results.extend(scan_results)\n",
    "\n",
    "# Convert results to a pandas DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"\\n\\n✅ Analysis complete for all models and scans.\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9dce6",
   "metadata": {},
   "source": [
    "### Summary/Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff11ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(MODELS_TO_ANALYZE) > 1:\n",
    "    summary_data = []\n",
    "    \n",
    "    # Only aggregate numeric columns\n",
    "    numeric_cols = results_df.select_dtypes(include=[np.number]).columns\n",
    "    summary = results_df.groupby('model_name')[numeric_cols].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "    # Prepare summary_display with formatted mean ± std for each metric\n",
    "    summary_display = pd.DataFrame()\n",
    "    summary_display['model_name'] = summary['model_name']\n",
    "    for col in numeric_cols:\n",
    "        mean_col = (col, 'mean')\n",
    "        std_col = (col, 'std')\n",
    "        summary_display[col] = summary[mean_col].map('{:.4f}'.format) + ' ± ' + summary[std_col].map('{:.4f}'.format)\n",
    "    \n",
    "    print(\"\\n\\n=======================================================\")\n",
    "    print(\"               Model Comparison Summary\")\n",
    "    print(\"=======================================================\")\n",
    "    \n",
    "    display(summary_display)\n",
    "\n",
    "else:\n",
    "    print(\"\\nOnly one model was analyzed. No comparison table to generate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
