{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85cca8e",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.config import CUDA_DEVICE, DEBUG, SCANS, PROJ_DIR, AGG_DIR, RESULT_DIR, data_version, PD_training_app, PD_epochs, PD_network_name, PD_model_name, PD_batch_size, PD_optimizer, PD_num_workers, ID_training_app, ID_epochs, ID_network_name, ID_model_name, ID_batch_size, ID_optimizer, ID_num_workers\n",
    "from pipeline.proj import load_projection_mat, reformat_sinogram, interpolate_projections, pad_and_reshape, divide_sinogram\n",
    "from pipeline.aggregate_prj import aggregate_saved_projections\n",
    "# from .aggregate_ct import aggregate_saved_volumes\n",
    "from pipeline.launcher import run_app\n",
    "from pipeline.apply_model import apply_model_to_projections, load_model\n",
    "# from .infer3d import inference_3d\n",
    "from pipeline.utils import ensure_dir\n",
    "import torch\n",
    "import scipy.io\n",
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Show info messages if DEBUG mode is enabled\n",
    "if DEBUG:\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logging.info(\"DEBUG mode is enabled. Detailed logs will be shown.\")\n",
    "else:\n",
    "    logging.basicConfig(level=logging.WARNING)\n",
    "    logging.warning(\"DEBUG mode is disabled. Only warnings and errors will be shown.\")\n",
    "\n",
    "# TODO run FDK via: FFrecon_reconFDK(input_mat, output_mat); in file \"FFrecon_fullFDK.m\"\n",
    "# TODO add DEBUG mode that prints out helpful info like shapes, etc. (and be sure to set logging level so 'info' shows up too)\n",
    "# TODO add some kind of logging for the hyperparameters used in the each run\n",
    "# TODO go through the training code and make sure it is consistent with new pipeline\n",
    "# TODO save everything as numpy arrays instead of torch tensors, and then convert to torch tensors when needed\n",
    "# TODO add more options for training like learning rate, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b49a2c",
   "metadata": {},
   "source": [
    "# 1. Data Preparation: projection interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, scan, scan_type, sample in SCANS:\n",
    "    # Load the projection data from the matlab files\n",
    "    odd_index, angles, prj = load_projection_mat(patient, scan, scan_type)\n",
    "\n",
    "    # Log shapes of loaded data\n",
    "    logging.info(f'Processing patient {patient}, scan {scan}, type {scan_type}, sample {sample}')\n",
    "    logging.info(f'Loaded odd_index shape: {odd_index.shape}')\n",
    "    logging.info(f'Loaded angles shape: {angles.shape}')\n",
    "    logging.info(f'Loaded projection shape: {prj.shape}')\n",
    "\n",
    "    # Flip and permute to get it in the right format\n",
    "    prj_gcbct, angles1 = reformat_sinogram(prj, angles)\n",
    "\n",
    "    # Log shapes after reformatting\n",
    "    logging.info(f'Reformatted projection shape: {prj_gcbct.shape}')\n",
    "\n",
    "    # Simulate ngCBCT projections\n",
    "    prj_ngcbct_li = interpolate_projections(prj_gcbct, odd_index)\n",
    "\n",
    "    # Log shapes after interpolation\n",
    "    logging.info(f'Interpolated ngCBCT projection shape: {prj_ngcbct_li.shape}')\n",
    "\n",
    "    # Split the projections into two halves so they are good dimensions for the CNN\n",
    "    combined_gcbct = divide_sinogram(pad_and_reshape(prj_gcbct), v_dim=512 if scan_type == \"HF\" else 256)\n",
    "    combined_ngcbct = divide_sinogram(pad_and_reshape(prj_ngcbct_li), v_dim=512 if scan_type == \"HF\" else 256)\n",
    "\n",
    "    # Log shapes after dividing sinograms\n",
    "    logging.info(f'Combined gCBCT shape: {combined_gcbct.shape}')\n",
    "    logging.info(f'Combined ngCBCT shape: {combined_ngcbct.shape}')\n",
    "\n",
    "    # Ensure the output directories exist\n",
    "    g_dir = os.path.join(PROJ_DIR, 'gated')\n",
    "    ng_dir = os.path.join(PROJ_DIR, 'ng')\n",
    "    ensure_dir(g_dir)\n",
    "    ensure_dir(ng_dir)\n",
    "\n",
    "    logging.info(f'Saving projections...')\n",
    "    \n",
    "    # Save the projections\n",
    "    # NOTE: These need to have the same name since later we will aggregate them, and we just sort by the name\n",
    "    torch.save(combined_gcbct, os.path.join(g_dir, f'{scan_type}_p{patient}_{scan}_{sample}.pt')) # e.g., HF_p01_01_TRAIN.pt\n",
    "    torch.save(combined_ngcbct, os.path.join(ng_dir, f'{scan_type}_p{patient}_{scan}_{sample}.pt'))\n",
    "\n",
    "    logging.info(f'Done with patient {patient}, scan {scan}, type {scan_type}, sample {sample}\\n')\n",
    "\n",
    "logging.info(\"All projections saved successfully.\")\n",
    "logging.info(\"Gated projections saved in: %s\", g_dir)\n",
    "logging.info(\"Non-gated projections saved in: %s\", ng_dir)\n",
    "\n",
    "# Free up memory\n",
    "del odd_index, angles, prj, prj_gcbct, angles1, prj_ngcbct_li, combined_gcbct, combined_ngcbct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23247d",
   "metadata": {},
   "source": [
    "### DEBUG: Sample projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b21297",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    # Pick the first HF scan and first FF scan\n",
    "    for patient, scan, scan_type, sample in SCANS:\n",
    "        if scan_type == \"HF\":\n",
    "            hf_scan = (patient, scan, scan_type, sample)\n",
    "            break\n",
    "    for patient, scan, scan_type, sample in SCANS:\n",
    "        if scan_type == \"FF\":\n",
    "            ff_scan = (patient, scan, scan_type, sample)\n",
    "            break\n",
    "\n",
    "    # Display the first HF scan\n",
    "    # Show the gated and nonstop-gated on subplots\n",
    "    hf_patient, hf_scan_num, hf_scan_type, hf_sample = hf_scan\n",
    "    hf_gated_prj = torch.load(os.path.join(g_dir, f'{hf_scan_type}_p{hf_patient}_{hf_scan_num}_{hf_sample}.pt'))\n",
    "    hf_ng_prj = torch.load(os.path.join(ng_dir, f'{hf_scan_type}_p{hf_patient}_{hf_scan_num}_{hf_sample}.pt'))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(hf_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "    plt.title(f'Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}_{hf_sample}')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(hf_ng_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "    plt.title(f'Nonstop-Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}_{hf_sample}')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Repeat for FF scan\n",
    "    ff_patient, ff_scan_num, ff_scan_type, ff_sample = ff_scan\n",
    "    ff_gated_prj = torch.load(os.path.join(g_dir, f'{ff_scan_type}_p{ff_patient}_{ff_scan_num}_{ff_sample}.pt'))\n",
    "    ff_ng_prj = torch.load(os.path.join(ng_dir, f'{ff_scan_type}_p{ff_patient}_{ff_scan_num}_{ff_sample}.pt'))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(ff_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "    plt.title(f'Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}_{ff_sample}')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(ff_ng_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "    plt.title(f'Nonstop-Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}_{ff_sample}')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Free up memory\n",
    "    del hf_gated_prj, hf_ng_prj, ff_gated_prj, ff_ng_prj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e695f",
   "metadata": {},
   "source": [
    "# 2. Aggregate projections for train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for aggregated data saving\n",
    "ensure_dir(AGG_DIR)\n",
    "\n",
    "# Aggregate and save projection data sets\n",
    "for scan_type in ['HF', 'FF']:\n",
    "    for sample in ['TRAIN', 'VALIDATION', 'TEST']:\n",
    "        prj_gcbct, prj_ngcbct = aggregate_saved_projections(scan_type, sample)\n",
    "        np.save(os.path.join(AGG_DIR, f\"PROJ_gated_{scan_type}_{sample}.npy\"), prj_gcbct.cpu().numpy()) # e.g., PROJ_gated_HF_TRAIN.npy\n",
    "        np.save(os.path.join(AGG_DIR, f\"PROJ_ng_{scan_type}_{sample}.npy\"), prj_ngcbct.cpu().numpy())\n",
    "\n",
    "# Free up memory\n",
    "del prj_gcbct, prj_ngcbct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae3e79",
   "metadata": {},
   "source": [
    "# 3. Training PD CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daead9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_app(PD_training_app, [f'--epoch={PD_epochs}', f'--network={PD_network_name}', f'--model_name={PD_model_name}', f'--data_ver={data_version}', f'--optimizer={PD_optimizer}', '--shuffle=True', f'--DEBUG={DEBUG}', f'--batch_size={PD_batch_size}'], f'--num_workers={PD_num_workers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef2c2c",
   "metadata": {},
   "source": [
    "# 4. Apply PD model to all nonstop-gated sinograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28452019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained PD model onto the GPU\n",
    "PD_model = load_model(PD_network_name, PD_model_name, device=torch.device(CUDA_DEVICE))\n",
    "\n",
    "for patient, scan, scan_type, sample in SCANS:\n",
    "    # Get the matlab dicts for the ground truth and CNN projections\n",
    "    g_mat, cnn_mat = apply_model_to_projections(patient, scan, scan_type, sample, PD_model)\n",
    "\n",
    "    # Save the ground truth and CNN projections\n",
    "    scipy.io.savemat(os.path.join(RESULT_DIR, f'PROJ_gated_{scan_type}_p{patient}_{scan}_{sample}.mat'), g_mat) # e.g., PROJ_gated_HF_p01_01_TRAIN.mat\n",
    "    scipy.io.savemat(os.path.join(RESULT_DIR, f'PROJ_ng_{scan_type}_p{patient}_{scan}_{sample}.mat'), cnn_mat)\n",
    "\n",
    "# Free up memory\n",
    "del PD_model, g_mat, cnn_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaa971",
   "metadata": {},
   "source": [
    "# 5. TODO: FDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09b672",
   "metadata": {},
   "source": [
    "# 6. Aggregate CT volumes for train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for aggregated data saving\n",
    "vol_agg_dir = os.path.join(DATA_DIR, \"agg\", \"volumes\")\n",
    "ensure_dir(vol_agg_dir)\n",
    "\n",
    "# Aggregate and save volume data sets\n",
    "for scan_type in ['HF', 'FF']:\n",
    "    for sample in ['train', 'validation', 'test']:\n",
    "        vol_gcbct, vol_ngcbct = aggregate_saved_volumes(scan_type, sample)\n",
    "        torch.save(vol_gcbct, os.path.join(vol_agg_dir, f\"{scan_type}_{sample}_gated.pt\"))\n",
    "        torch.save(vol_ngcbct, os.path.join(vol_agg_dir, f\"{scan_type}_{sample}_ng.pt\"))\n",
    "\n",
    "# Free up memory\n",
    "del vol_gcbct, vol_ngcbct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e933115",
   "metadata": {},
   "source": [
    "# 7. Train ID CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b35e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f74da1",
   "metadata": {},
   "source": [
    "# 8. Inference on test scans for full 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = inference_3d(patient_id, scan_id, 'HF', data_version, model_name, 'tumor_location_panc.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
