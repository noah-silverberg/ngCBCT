{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4229da",
   "metadata": {},
   "source": [
    "# Setup Logging & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3a1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a15cef",
   "metadata": {},
   "source": [
    "### Setting up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8c4bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pipeline:DEBUG mode is enabled. Detailed logs will be shown.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"pipeline\")\n",
    "\n",
    "# Show info messages if DEBUG mode is enabled\n",
    "if DEBUG:\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.debug(\"DEBUG mode is enabled. Detailed logs will be shown.\")\n",
    "else:\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.info(\"DEBUG mode is disabled. Only essential logs will be shown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0476a6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd091fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline:CUDA is available. Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# We set up CUDA first to ensure it is configured correctly\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "if torch.cuda.is_available():\n",
    "    CUDA_DEVICE = torch.device(\"cuda:0\")\n",
    "    logger.info(f\"CUDA is available. Using device: {CUDA_DEVICE}\")\n",
    "else:\n",
    "    logger.error(\"CUDA is not available. Please check your PyTorch installation. Using CPU instead...this will be slow.\")\n",
    "    CUDA_DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7075ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.proj import load_projection_mat, reformat_sinogram, interpolate_projections, pad_and_reshape, divide_sinogram\n",
    "from pipeline.aggregate_prj import aggregate_saved_projections\n",
    "from pipeline.aggregate_ct import aggregate_saved_recons\n",
    "from pipeline.apply_model import apply_model_to_projections, load_model\n",
    "# from .infer3d import inference_3d\n",
    "from pipeline.utils import ensure_dir, read_scans_agg_file\n",
    "from pipeline.paths import Directories, Files\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "import importlib\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import tigre.utilities.gpu as gpu\n",
    "from pipeline.FDK_half.FDK_half import FDKHalf\n",
    "from pipeline.utils import get_geometry\n",
    "\n",
    "# TODO run FDK via: FFrecon_reconFDK(input_mat, output_mat); in file \"FFrecon_fullFDK.m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d9f9e",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18df6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scans to convert to PyTorch tensors\n",
    "# Put None if you don't have any scans to convert\n",
    "# See the README for how to write this file correctly\n",
    "# NOTE: This will throw an error if the scan has already been converted\n",
    "#       If you would like to re-convert a scan,\n",
    "#       you can delete the file manually\n",
    "# SCANS_CONVERT = 'scans_convert_to_pt.txt'\n",
    "SCANS_CONVERT = None\n",
    "\n",
    "# Phase of the project (all data, models, etc. will be saved under this phase)\n",
    "PHASE = \"7\"\n",
    "\n",
    "# If this data version already exists in this phase, it will be loaded\n",
    "# Otherwise it will be created using whatever the most updated data creation script is\n",
    "DATA_VERSION = '13'\n",
    "\n",
    "# Scans to use for training, val, and testing\n",
    "# You should set this even if you are not doing aggregation\n",
    "# See the README for how to write this file correctly\n",
    "# NOTE: This will NOT throw an error if there are already aggregated scans\n",
    "#       it will just give a warning and skip the aggregation step\n",
    "SCANS_AGG = 'scans_to_agg.txt'\n",
    "# SCANS_AGG = None\n",
    "\n",
    "# Whether to augment the data for the image domain\n",
    "# This will only be used if you are doing image domain aggregation\n",
    "AUGMENT_ID = True\n",
    "\n",
    "# List of yaml files that contain configurations for the pipeline\n",
    "# Each file should contain the paramters for a specific model/ensemble\n",
    "CONFIG_FILES = [\n",
    "    # \"config_01epoch.yaml\",\n",
    "    \"config_20epoch.yaml\",\n",
    "]\n",
    "\n",
    "# Base directory\n",
    "WORK_ROOT = \"D:/NoahSilverberg/ngCBCT\"\n",
    "\n",
    "# NSG_CBCT Path where the raw matlab data is stored\n",
    "NSG_CBCT_PATH = \"D:/MitchellYu/NSG_CBCT\"\n",
    "\n",
    "# Directory with all files specific to this phase/data version\n",
    "PHASE_DATAVER_DIR = os.path.join(\n",
    "    WORK_ROOT, f\"phase{PHASE}\", f\"DS{DATA_VERSION}\"\n",
    ")\n",
    "\n",
    "DIRECTORIES = Directories(\n",
    "    mat_projections_dir=os.path.join(NSG_CBCT_PATH, \"data/prj/HF/mat\"),\n",
    "    pt_projections_dir=os.path.join(WORK_ROOT, \"prj_pt\"),\n",
    "    projections_aggregate_dir=os.path.join(PHASE_DATAVER_DIR, \"aggregates\", \"projections\"),\n",
    "    projections_model_dir=os.path.join(PHASE_DATAVER_DIR, \"models\", \"projections\"),\n",
    "    projections_results_dir=os.path.join(PHASE_DATAVER_DIR, \"results\", \"projections\"),\n",
    "    projections_gated_dir=os.path.join(WORK_ROOT, \"gated\", \"prj_mat\"),\n",
    "    reconstructions_dir=os.path.join(PHASE_DATAVER_DIR, \"reconstructions\"),\n",
    "    reconstructions_gated_dir=os.path.join(WORK_ROOT, \"gated\", \"fdk_recon\"),\n",
    "    images_aggregate_dir=os.path.join(PHASE_DATAVER_DIR, \"aggregates\", \"images\"),\n",
    "    images_model_dir=os.path.join(PHASE_DATAVER_DIR, \"models\", \"images\"),\n",
    "    images_results_dir=os.path.join(PHASE_DATAVER_DIR, \"results\", \"images\"),\n",
    ")\n",
    "\n",
    "FILES = Files(DIRECTORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b49a2c",
   "metadata": {},
   "source": [
    "# Data Preparation: projection interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ccc147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pipeline:No scans to convert. Skipping projection data processing.\n"
     ]
    }
   ],
   "source": [
    "if SCANS_CONVERT is not None:\n",
    "    # Read the scans to convert file\n",
    "    with open(SCANS_CONVERT, \"r\") as f:\n",
    "        SCANS_CONVERT = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            patient, scan, scan_type = line.split()\n",
    "            SCANS_CONVERT.append((patient, scan, scan_type))\n",
    "\n",
    "    logger.debug(f\"Loaded scan list for conversion: {SCANS_CONVERT}\")\n",
    "\n",
    "    logger.info(\"Starting to process projection data...\")\n",
    "\n",
    "    for patient, scan, scan_type in SCANS_CONVERT:\n",
    "        g_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=True)\n",
    "        ng_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=False)\n",
    "\n",
    "        # Make sure the files do not already exist\n",
    "        if os.path.exists(g_path) or os.path.exists(ng_path):\n",
    "            logger.warning(f\"Projection files already exist for patient {patient}, scan {scan}, type {scan_type}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Load the projection data from the matlab files\n",
    "        mat_path = FILES.get_projection_mat_filepath(patient, scan, scan_type)\n",
    "        odd_index, angles, prj = load_projection_mat(mat_path)\n",
    "\n",
    "        # Log shapes of loaded data\n",
    "        logger.debug(f'Processing patient {patient}, scan {scan}, type {scan_type}')\n",
    "        logger.debug(f'Loaded odd_index shape: {odd_index.shape}')\n",
    "        logger.debug(f'Loaded angles shape: {angles.shape}')\n",
    "        logger.debug(f'Loaded projection shape: {prj.shape}')\n",
    "\n",
    "        # Flip and permute to get it in the right format\n",
    "        prj_gcbct, angles1 = reformat_sinogram(prj, angles)\n",
    "\n",
    "        # Log shapes after reformatting\n",
    "        logger.debug(f'Reformatted projection shape: {prj_gcbct.shape}')\n",
    "\n",
    "        # Simulate ngCBCT projections\n",
    "        prj_ngcbct_li = interpolate_projections(prj_gcbct, odd_index)\n",
    "\n",
    "        # Log shapes after interpolation\n",
    "        logger.debug(f'Interpolated ngCBCT projection shape: {prj_ngcbct_li.shape}')\n",
    "\n",
    "        # Split the projections into two halves so they are good dimensions for the CNN\n",
    "        combined_gcbct = divide_sinogram(pad_and_reshape(prj_gcbct), v_dim=512 if scan_type == \"HF\" else 256)\n",
    "        combined_ngcbct = divide_sinogram(pad_and_reshape(prj_ngcbct_li), v_dim=512 if scan_type == \"HF\" else 256)\n",
    "\n",
    "        # Log shapes after dividing sinograms\n",
    "        logger.debug(f'Combined gCBCT shape: {combined_gcbct.shape}')\n",
    "        logger.debug(f'Combined ngCBCT shape: {combined_ngcbct.shape}')\n",
    "\n",
    "        logger.debug(f'Saving projections...')\n",
    "        \n",
    "        # Save the projections\n",
    "        torch.save(combined_gcbct, g_path)\n",
    "        torch.save(combined_ngcbct, ng_path)\n",
    "\n",
    "        logger.debug(f'Done with patient {patient}, scan {scan}, type {scan_type}\\n')\n",
    "\n",
    "    logger.info(\"All projections saved successfully.\")\n",
    "\n",
    "    # Free up memory\n",
    "    del odd_index, angles, prj, prj_gcbct, angles1, prj_ngcbct_li, combined_gcbct, combined_ngcbct\n",
    "else:\n",
    "    logger.info(\"No scans to convert. Skipping projection data processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23247d",
   "metadata": {},
   "source": [
    "### DEBUG: Sample projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b21297",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG and SCANS_CONVERT is not None:\n",
    "    # Pick the first HF scan and first FF scan\n",
    "    hf_scan = None\n",
    "    ff_scan = None\n",
    "    for patient, scan, scan_type in SCANS_CONVERT:\n",
    "        if scan_type == \"HF\":\n",
    "            hf_scan = (patient, scan, scan_type)\n",
    "            break\n",
    "    for patient, scan, scan_type in SCANS_CONVERT:\n",
    "        if scan_type == \"FF\":\n",
    "            ff_scan = (patient, scan, scan_type)\n",
    "            break\n",
    "\n",
    "    # Display the first HF scan\n",
    "    # Show the gated and nonstop-gated on subplots\n",
    "    if hf_scan:\n",
    "        hf_patient, hf_scan_num, hf_scan_type = hf_scan\n",
    "        g_path = FILES.get_projection_pt_filepath(hf_patient, hf_scan_num, hf_scan_type, gated=True)\n",
    "        ng_path = FILES.get_projection_pt_filepath(hf_patient, hf_scan_num, hf_scan_type, gated=False)\n",
    "        hf_gated_prj = torch.load(g_path)\n",
    "        hf_ng_prj = torch.load(ng_path)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(hf_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "        plt.title(f'Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(hf_ng_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "        plt.title(f'Nonstop-Gated Projection - {hf_scan_type} p{hf_patient}_{hf_scan_num}')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Free up memory\n",
    "        del hf_gated_prj, hf_ng_prj\n",
    "\n",
    "    # Repeat for FF scan\n",
    "    if ff_scan:\n",
    "        ff_patient, ff_scan_num, ff_scan_type = ff_scan\n",
    "        g_path = FILES.get_projection_pt_filepath(ff_patient, ff_scan_num, ff_scan_type, gated=True)\n",
    "        ff_gated_prj = torch.load(g_path)\n",
    "        ng_path = FILES.get_projection_pt_filepath(ff_patient, ff_scan_num, ff_scan_type, gated=False)\n",
    "        ff_ng_prj = torch.load(ng_path)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(ff_gated_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "        plt.title(f'Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(ff_ng_prj[0, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "        plt.title(f'Nonstop-Gated Projection - {ff_scan_type} p{ff_patient}_{ff_scan_num}')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Free up memory\n",
    "        del ff_gated_prj, ff_ng_prj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e695f",
   "metadata": {},
   "source": [
    "# Aggregate projections for train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188d3403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pipeline:Loaded scan list for aggregation: {'TRAIN': [('01', '01', 'HF'), ('01', '02', 'HF'), ('01', '03', 'HF'), ('01', '04', 'HF'), ('01', '05', 'HF'), ('01', '06', 'HF'), ('03', '01', 'HF'), ('04', '01', 'HF'), ('04', '02', 'HF'), ('04', '03', 'HF'), ('05', '01', 'HF'), ('06', '01', 'HF'), ('06', '02', 'HF'), ('09', '01', 'HF'), ('11', '01', 'HF'), ('11', '02', 'HF'), ('11', '03', 'HF'), ('11', '04', 'HF'), ('11', '05', 'HF'), ('12', '01', 'HF'), ('12', '02', 'HF'), ('12', '03', 'HF'), ('12', '04', 'HF'), ('13', '01', 'HF'), ('13', '02', 'HF'), ('13', '03', 'HF'), ('13', '04', 'HF'), ('13', '05', 'HF'), ('13', '06', 'HF'), ('17', '01', 'HF'), ('18', '01', 'HF'), ('18', '02', 'HF'), ('18', '03', 'HF'), ('18', '04', 'HF'), ('19', '01', 'HF'), ('19', '02', 'HF'), ('21', '01', 'HF'), ('21', '02', 'HF'), ('21', '03', 'HF'), ('21', '04', 'HF'), ('23', '01', 'HF'), ('23', '02', 'HF')], 'VALIDATION': [('02', '01', 'HF'), ('02', '02', 'HF'), ('16', '01', 'HF'), ('16', '02', 'HF'), ('22', '01', 'HF'), ('22', '02', 'HF')], 'TEST': [('08', '01', 'HF'), ('10', '01', 'HF'), ('14', '01', 'HF'), ('14', '02', 'HF'), ('15', '01', 'HF'), ('20', '01', 'HF')]}\n",
      "WARNING:pipeline:Aggregated projection data already exists in D:/NoahSilverberg/ngCBCT\\phase7\\DS13\\aggregates\\projections. Skipping...\n"
     ]
    }
   ],
   "source": [
    "if SCANS_AGG is not None:\n",
    "    scans_agg, scan_type = read_scans_agg_file(SCANS_AGG)\n",
    "    logger.debug(f\"Loaded scan list for aggregation: {scans_agg}\")\n",
    "\n",
    "    # Only aggregate projections if they don't already exist\n",
    "    agg_dir = DIRECTORIES.projections_aggregate_dir\n",
    "    if agg_dir is None:\n",
    "        logger.warning(\"No aggregation directory specified. Skipping projection data aggregation.\")\n",
    "    elif len(os.listdir(agg_dir)) > 0:\n",
    "        logger.warning(f\"Aggregated projection data already exists in {agg_dir}. Skipping...\")\n",
    "    else:\n",
    "        logger.info(\"Starting to aggregate projection data...\")\n",
    "        \n",
    "        # Aggregate and save projection data sets\n",
    "        for split in ['TRAIN', 'VALIDATION', 'TEST']:\n",
    "            if len(scans_agg[split]) > 0:\n",
    "                ng_paths = [FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                prj_ngcbct = aggregate_saved_projections(ng_paths)\n",
    "                ng_agg_path = FILES.get_projections_aggregate_filepath(split, gated=False)\n",
    "                np.save(ng_agg_path, prj_ngcbct.numpy())\n",
    "                del prj_ngcbct\n",
    "                logger.debug(\"Done with nonstop-gated...\")\n",
    "                g_paths = [FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=True) for patient, scan, scan_type in scans_agg[split]]\n",
    "                prj_gcbct = aggregate_saved_projections(g_paths)\n",
    "                g_agg_path = FILES.get_projections_aggregate_filepath(split, gated=True)\n",
    "                np.save(g_agg_path, prj_gcbct.numpy())\n",
    "                del prj_gcbct\n",
    "                logger.debug(\"Done with gated...\")\n",
    "\n",
    "                logger.debug(f\"Aggregated projections saved for {scan_type} {split}.\\n\")\n",
    "            else:\n",
    "                logger.debug(f\"No scans to aggregate for {scan_type} {split}. Skipping aggregation.\")\n",
    "\n",
    "        # Free up memory\n",
    "        del prj_gcbct, prj_ngcbct\n",
    "\n",
    "        logger.info(\"Projection data aggregation completed successfully.\")\n",
    "        logger.info(\"Aggregated projection data saved in: %s\", agg_dir)\n",
    "else:\n",
    "    logger.info(\"No scans to aggregate. Skipping projection data aggregation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae3e79",
   "metadata": {},
   "source": [
    "# Training PD CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daead9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pipeline:Loaded configuration from config_20epoch.yaml\n",
      "INFO:pipeline:Skipping PD training for config_20epoch.yaml as PD training is set to False.\n"
     ]
    }
   ],
   "source": [
    "for config_file in CONFIG_FILES:\n",
    "    # Load the yaml configuration file\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "    # Skip this config if the user has set PD_training to False\n",
    "    if not config['PD_settings']['training']:\n",
    "        logger.info(f\"Skipping PD training for {config_file} as PD training is set to False.\")\n",
    "        continue\n",
    "\n",
    "    # Get the training application\n",
    "    module_name, class_name = config['PD_settings']['training_app'].rsplit('.', 1)\n",
    "    module = importlib.import_module(\"pipeline.\" + module_name)\n",
    "    cls = getattr(module, class_name)\n",
    "\n",
    "    logger.debug(f\"Loaded class {class_name} from module {module_name}\")\n",
    "\n",
    "    # Get the model version (for naming purposes)\n",
    "    model_version = config['PD_settings']['model_version']\n",
    "\n",
    "    # Get the ensemble size, and loop through it\n",
    "    ensemble_size = config['PD_settings']['ensemble_size']\n",
    "    for i in range(ensemble_size):\n",
    "        # If we are training an ensemble, we add an identifier to the model version\n",
    "        if ensemble_size > 1:\n",
    "            # Deepcopy config so we don't affect the original\n",
    "            cfg = copy.deepcopy(config)\n",
    "            cfg['PD_settings']['model_version'] = f\"{model_version}_{i+1:02}\" # e.g., \"v1_01\"\n",
    "        else:\n",
    "            cfg = config\n",
    "\n",
    "        # Add the data version to the configuration\n",
    "        cfg['PD_settings']['data_version'] = DATA_VERSION\n",
    "\n",
    "        # Instantiate with the loaded configuration\n",
    "        instance = cls(cfg, \"PROJ\", DEBUG, FILES)\n",
    "\n",
    "        logger.info(f\"Going to try training the {i + 1}-th model with configuration from {config_file}...\")\n",
    "\n",
    "        # Run the training\n",
    "        instance.main()\n",
    "\n",
    "        logger.info(f\"Finished training the {i + 1}-th model.\\n\")\n",
    "\n",
    "        del instance, cfg\n",
    "        gc.collect()\n",
    "\n",
    "    # Free up memory\n",
    "    del module, cls, config, module_name, class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb52db",
   "metadata": {},
   "source": [
    "# TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ffadb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pipeline:Loaded configuration from config_20epoch.yaml\n",
      "Applying model MK7_01 to projections split TRAIN:   0%|          | 0/42 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p01_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_03 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_04 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_05 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_06 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p03_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_03 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p05_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p09_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_03 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_04 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_05 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_03 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_04 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_03 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_04 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_05 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_06 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p17_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_03 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_04 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_03 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_04 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_02 for model MK7_01. Skipping...\n",
      "Applying model MK7_01 to projections split TRAIN: 100%|██████████| 42/42 [00:00<00:00, 890.63it/s]\n",
      "Applying model MK7_01 to projections split VALIDATION:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p02_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p02_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_02 for model MK7_01. Skipping...\n",
      "Applying model MK7_01 to projections split VALIDATION: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Applying model MK7_01 to projections split TEST:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p08_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p10_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_02 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p15_01 for model MK7_01. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p20_01 for model MK7_01. Skipping...\n",
      "Applying model MK7_01 to projections split TEST: 100%|██████████| 6/6 [00:00<00:00, 386.72it/s]\n",
      "Applying model MK7_02 to projections split TRAIN:   0%|          | 0/42 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p01_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_03 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_04 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_05 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_06 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p03_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_03 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p05_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p09_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_03 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_04 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_05 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_03 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_04 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_03 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_04 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_05 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_06 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p17_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_03 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_04 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_03 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_04 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_02 for model MK7_02. Skipping...\n",
      "Applying model MK7_02 to projections split TRAIN: 100%|██████████| 42/42 [00:00<00:00, 716.52it/s]\n",
      "Applying model MK7_02 to projections split VALIDATION:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p02_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p02_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_02 for model MK7_02. Skipping...\n",
      "Applying model MK7_02 to projections split VALIDATION: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Applying model MK7_02 to projections split TEST:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p08_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p10_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_02 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p15_01 for model MK7_02. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p20_01 for model MK7_02. Skipping...\n",
      "Applying model MK7_02 to projections split TEST: 100%|██████████| 6/6 [00:00<00:00, 1495.83it/s]\n",
      "Applying model MK7_03 to projections split TRAIN:   0%|          | 0/42 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p01_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_03 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_04 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_05 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_06 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p03_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_03 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p05_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p09_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_03 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_04 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_05 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_03 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_04 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_03 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_04 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_05 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_06 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p17_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_03 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_04 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_03 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_04 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_02 for model MK7_03. Skipping...\n",
      "Applying model MK7_03 to projections split TRAIN: 100%|██████████| 42/42 [00:00<00:00, 888.20it/s]\n",
      "Applying model MK7_03 to projections split VALIDATION:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p02_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p02_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_02 for model MK7_03. Skipping...\n",
      "Applying model MK7_03 to projections split VALIDATION: 100%|██████████| 6/6 [00:00<00:00, 374.60it/s]\n",
      "Applying model MK7_03 to projections split TEST:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p08_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p10_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_02 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p15_01 for model MK7_03. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p20_01 for model MK7_03. Skipping...\n",
      "Applying model MK7_03 to projections split TEST: 100%|██████████| 6/6 [00:00<00:00, 383.74it/s]\n",
      "Applying model MK7_04 to projections split TRAIN:   0%|          | 0/42 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p01_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_03 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_04 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_05 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_06 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p03_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_03 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p05_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p09_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_03 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_04 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_05 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_03 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_04 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_03 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_04 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_05 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_06 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p17_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_03 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_04 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_03 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_04 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_02 for model MK7_04. Skipping...\n",
      "Applying model MK7_04 to projections split TRAIN: 100%|██████████| 42/42 [00:00<00:00, 930.03it/s]\n",
      "Applying model MK7_04 to projections split VALIDATION:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p02_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p02_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_02 for model MK7_04. Skipping...\n",
      "Applying model MK7_04 to projections split VALIDATION: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Applying model MK7_04 to projections split TEST:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p08_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p10_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_02 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p15_01 for model MK7_04. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p20_01 for model MK7_04. Skipping...\n",
      "Applying model MK7_04 to projections split TEST: 100%|██████████| 6/6 [00:00<00:00, 413.56it/s]\n",
      "Applying model MK7_05 to projections split TRAIN:   0%|          | 0/42 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p01_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_03 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_04 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_05 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_06 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p03_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_03 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p05_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p09_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_03 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_04 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_05 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_03 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_04 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_03 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_04 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_05 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_06 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p17_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_03 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_04 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_03 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_04 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_02 for model MK7_05. Skipping...\n",
      "Applying model MK7_05 to projections split TRAIN: 100%|██████████| 42/42 [00:00<00:00, 682.81it/s]\n",
      "Applying model MK7_05 to projections split VALIDATION:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p02_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p02_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_02 for model MK7_05. Skipping...\n",
      "Applying model MK7_05 to projections split VALIDATION: 100%|██████████| 6/6 [00:00<00:00, 1326.26it/s]\n",
      "Applying model MK7_05 to projections split TEST:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p08_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p10_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_02 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p15_01 for model MK7_05. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p20_01 for model MK7_05. Skipping...\n",
      "Applying model MK7_05 to projections split TEST: 100%|██████████| 6/6 [00:00<00:00, 410.93it/s]\n",
      "Applying model MK7_06 to projections split TRAIN:   0%|          | 0/42 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p01_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_03 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_04 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_05 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p01_06 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p03_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p04_03 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p05_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p06_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p09_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_03 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_04 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p11_05 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_03 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p12_04 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_03 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_04 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_05 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p13_06 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p17_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_03 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p18_04 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p19_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_03 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p21_04 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p23_02 for model MK7_06. Skipping...\n",
      "Applying model MK7_06 to projections split TRAIN: 100%|██████████| 42/42 [00:00<00:00, 778.82it/s]\n",
      "Applying model MK7_06 to projections split VALIDATION:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Projections and reconstructions results already exist for HF p02_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p02_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p16_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Projections and reconstructions results already exist for HF p22_02 for model MK7_06. Skipping...\n",
      "Applying model MK7_06 to projections split VALIDATION: 100%|██████████| 6/6 [00:00<00:00, 749.96it/s]\n",
      "Applying model MK7_06 to projections split TEST:   0%|          | 0/6 [00:00<?, ?it/s]INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p08_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p10_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p14_02 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p15_01 for model MK7_06. Skipping...\n",
      "INFO:pipeline:Nonstop-gated projections and reconstructions already exist for HF p20_01 for model MK7_06. Skipping...\n",
      "Applying model MK7_06 to projections split TEST: 100%|██████████| 6/6 [00:00<00:00, 3607.49it/s]\n",
      "INFO:pipeline:All models applied to projections.\n"
     ]
    }
   ],
   "source": [
    "gpuids = gpu.getGpuIds()\n",
    "gpuids.devices = [0]\n",
    "geo = get_geometry()\n",
    "\n",
    "if SCANS_AGG is None:\n",
    "    logger.info(\"Skipping model application as the aggregation scan list is not provided.\")\n",
    "else:\n",
    "    # Loop through the configurations again\n",
    "    for config_file in CONFIG_FILES:\n",
    "        # Load the yaml configuration file\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "\n",
    "        logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "        # Get the ensemble size, and loop through it\n",
    "        ensemble_size = config['PD_settings']['ensemble_size']\n",
    "        for i in range(ensemble_size):\n",
    "            model_version = config['PD_settings']['model_version']\n",
    "\n",
    "            # If we are training an ensemble, we add an identifier to the model version\n",
    "            if ensemble_size > 1:\n",
    "                model_version = f\"{model_version}_{i+1:02}\"\n",
    "\n",
    "            scan_type_model = config['PD_settings']['scan_type']\n",
    "\n",
    "            # Load the trained PD model onto the GPU\n",
    "            model_path = FILES.get_model_filepath(model_version, \"PROJ\")\n",
    "            PD_model = load_model(config['PD_settings']['network_name'], model_path, CUDA_DEVICE)\n",
    "\n",
    "            scans_agg, scan_type = read_scans_agg_file(SCANS_AGG)\n",
    "            if scan_type != config['PD_settings']['scan_type']:\n",
    "                raise ValueError(f\"Scan type in aggregation file ({scan_type}) does not match scan type in config ({config['PD_settings']['scan_type']}).\")\n",
    "            \n",
    "            for split in ['TRAIN', 'VALIDATION', 'TEST']:\n",
    "                for patient, scan, scan_type in tqdm(scans_agg[split], desc=f\"Applying model {model_version} to projections split {split}\"):\n",
    "                    # Get the matlab dicts for the ground truth and CNN projections\n",
    "                    mat_path = FILES.get_projection_mat_filepath(patient, scan, scan_type)\n",
    "                    gated_pt_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=True)\n",
    "                    ng_pt_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=False)\n",
    "                    \n",
    "                    # Save the ground truth and CNN projections\n",
    "                    gated_path = FILES.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=True)\n",
    "                    ng_path = FILES.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=False)\n",
    "                    g_recon_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type, gated=True)\n",
    "                    ng_recon_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type, gated=False)\n",
    "\n",
    "                    if split != \"TEST\" and os.path.exists(ng_recon_path):\n",
    "                        logger.info(f\"Projections and reconstructions results already exist for {scan_type} p{patient}_{scan} for model {model_version}. Skipping...\")\n",
    "                        continue\n",
    "\n",
    "                    if split == \"TEST\" and os.path.exists(ng_path) and os.path.exists(ng_recon_path):\n",
    "                        logger.info(f\"Nonstop-gated projections and reconstructions already exist for {scan_type} p{patient}_{scan} for model {model_version}. Skipping...\")\n",
    "                        continue\n",
    "\n",
    "                    g_mat, cnn_mat = apply_model_to_projections(PD_model, scan_type, mat_path, gated_pt_path, ng_pt_path, CUDA_DEVICE)\n",
    "\n",
    "                    if split == \"TEST\" and not os.path.exists(ng_path):\n",
    "                        scipy.io.savemat(ng_path, cnn_mat)\n",
    "                        logger.debug(f\"Saved CNN projections for {scan_type} p{patient}_{scan} to {ng_path}.\")\n",
    "\n",
    "                    if not os.path.exists(g_recon_path):    \n",
    "                        g_fdk_half = FDKHalf()(g_mat['prj'], get_geometry(), g_mat['angles'].flatten(), filter='hann', parker=True)\n",
    "                        g_fdk_half = torch.from_numpy(g_fdk_half).detach()\n",
    "                        \n",
    "                        # Save the recon results as .pt\n",
    "                        torch.save(g_fdk_half, g_recon_path)\n",
    "                        logger.debug(f\"Saved gated reconstruction for {scan_type} p{patient}_{scan} to {g_recon_path}.\")\n",
    "                    else:\n",
    "                        logger.debug(f\"Gated reconstruction already exists for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                    if not os.path.exists(ng_recon_path):\n",
    "                        ng_fdk_half = FDKHalf()(cnn_mat['prj'], get_geometry(), cnn_mat['angles'].flatten(), filter='hann', parker=True)\n",
    "                        ng_fdk_half = torch.from_numpy(ng_fdk_half).detach()\n",
    "                        \n",
    "                        # Save the recon results as .pt\n",
    "                        torch.save(ng_fdk_half, ng_recon_path)\n",
    "                        logger.debug(f\"Saved nonstop-gated reconstruction for {scan_type} p{patient}_{scan} to {ng_recon_path}.\")\n",
    "                    else:\n",
    "                        logger.debug(f\"Nonstop-gated reconstruction already exists for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                    logger.debug(f\"Saved projections for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "                    del g_mat, cnn_mat, ng_fdk_half\n",
    "                    try:\n",
    "                        del g_fdk_half\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            # Free up memory\n",
    "            del PD_model\n",
    "\n",
    "    logger.info(\"All models applied to projections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef2c2c",
   "metadata": {},
   "source": [
    "# Apply PD model to all nonstop-gated sinograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8672f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SCANS_AGG is None:\n",
    "#     logger.info(\"Skipping model application as the aggregation scan list is not provided.\")\n",
    "# else:\n",
    "#     # Loop through the configurations again\n",
    "#     for config_file in CONFIG_FILES:\n",
    "#         # Load the yaml configuration file\n",
    "#         with open(config_file, \"r\") as f:\n",
    "#             config = yaml.safe_load(f)\n",
    "\n",
    "#         logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "#         # Get the ensemble size, and loop through it\n",
    "#         ensemble_size = config['PD_settings']['ensemble_size']\n",
    "#         for i in range(ensemble_size):\n",
    "#             model_version = config['PD_settings']['model_version']\n",
    "\n",
    "#             # If we are training an ensemble, we add an identifier to the model version\n",
    "#             if ensemble_size > 1:\n",
    "#                 model_version = f\"{model_version}_{i+1:02}\"\n",
    "\n",
    "#             scan_type_model = config['PD_settings']['scan_type']\n",
    "\n",
    "#             # Load the trained PD model onto the GPU\n",
    "#             model_path = FILES.get_model_filepath(model_version, \"PROJ\")\n",
    "#             PD_model = load_model(config['PD_settings']['network_name'], model_path, CUDA_DEVICE)\n",
    "\n",
    "#             scans_agg, scan_type = read_scans_agg_file(SCANS_AGG, list_=True)\n",
    "#             if scan_type != config['PD_settings']['scan_type']:\n",
    "#                 raise ValueError(f\"Scan type in aggregation file ({scan_type}) does not match scan type in config ({config['PD_settings']['scan_type']}).\")\n",
    "            \n",
    "#             for patient, scan, scan_type in tqdm(scans_agg, desc=f\"Applying model {model_version} to projections\"):\n",
    "#                 # Get the matlab dicts for the ground truth and CNN projections\n",
    "#                 mat_path = FILES.get_projection_mat_filepath(patient, scan, scan_type)\n",
    "#                 gated_pt_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=True)\n",
    "#                 ng_pt_path = FILES.get_projection_pt_filepath(patient, scan, scan_type, gated=False)\n",
    "                \n",
    "#                 # Save the ground truth and CNN projections\n",
    "#                 gated_path = FILES.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=True)\n",
    "#                 ng_path = FILES.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=False)\n",
    "\n",
    "#                 if os.path.exists(ng_path):\n",
    "#                     logger.info(f\"Projections results already exist for {scan_type} p{patient}_{scan} for model {model_version}. Skipping...\")\n",
    "#                     continue\n",
    "\n",
    "#                 g_mat, cnn_mat = apply_model_to_projections(PD_model, scan_type, mat_path, gated_pt_path, ng_pt_path, CUDA_DEVICE)\n",
    "\n",
    "#                 if os.path.exists(gated_path):\n",
    "#                     logger.info(f\"Ground-truth projections already exist for {scan_type} p{patient}_{scan}. Skipping...\")\n",
    "#                 else:\n",
    "#                     scipy.io.savemat(gated_path, g_mat)\n",
    "#                 scipy.io.savemat(ng_path, cnn_mat)\n",
    "\n",
    "#                 logger.debug(f\"Saved projections for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "#                 del g_mat, cnn_mat\n",
    "\n",
    "#             # Free up memory\n",
    "#             del PD_model\n",
    "\n",
    "#     logger.info(\"All models applied to projections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaa971",
   "metadata": {},
   "source": [
    "# Apply FDK to all projections that were processed by the PD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0b1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO do we do this differently for FF?\n",
    "# gpuids = gpu.getGpuIds()\n",
    "# gpuids.devices = [0]\n",
    "# geo = get_geometry()\n",
    "\n",
    "# # Loop through the configurations again\n",
    "# for config_file in CONFIG_FILES:\n",
    "#     # Load the yaml configuration file\n",
    "#     with open(config_file, \"r\") as f:\n",
    "#         config = yaml.safe_load(f)\n",
    "\n",
    "#     logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "#     # Get the ensemble size, and loop through it\n",
    "#     ensemble_size = config['PD_settings']['ensemble_size']\n",
    "#     for i in range(ensemble_size):\n",
    "#         model_version = config['PD_settings']['model_version']\n",
    "\n",
    "#         # If we are training an ensemble, we add an identifier to the model version\n",
    "#         if ensemble_size > 1:\n",
    "#             model_version = f\"{model_version}_{i+1:02}\"\n",
    "\n",
    "#         scan_type_model = config['PD_settings']['scan_type']\n",
    "\n",
    "#         # Load the trained PD model onto the GPU\n",
    "#         model_path = FILES.get_model_filepath(model_version, \"PROJ\")\n",
    "#         PD_model = load_model(config['PD_settings']['network_name'], model_path, torch.device(CUDA_DEVICE))\n",
    "            \n",
    "#         scans_agg, scan_type = read_scans_agg_file(SCANS_AGG, list_=True)\n",
    "#         if scan_type != config['PD_settings']['scan_type']:\n",
    "#             raise ValueError(f\"Scan type in aggregation file ({scan_type}) does not match scan type in config ({config['PD_settings']['scan_type']}).\")\n",
    "\n",
    "#         for patient, scan, scan_type in tqdm(scans_agg, desc=f\"Applying FDK to gated and nonstop-gated projections for model {model_version}\"):\n",
    "#             for gated in [True, False]:\n",
    "#                 # Load the scan and perform FDK reconstruction\n",
    "#                 result_path = FILES.get_projections_results_filepath(model_version, patient, scan, scan_type, gated=gated)\n",
    "                \n",
    "#                 recon_path = FILES.get_recon_filepath(model_version, patient, scan, scan_type, gated=gated)\n",
    "#                 if os.path.exists(recon_path):\n",
    "#                     logger.info(f\"{'Gated' if gated else 'Nonstop-gated'} reconstruction already exists for {scan_type} p{patient}_{scan}. Skipping...\")\n",
    "#                     continue\n",
    "\n",
    "#                 mat = scipy.io.loadmat(result_path)\n",
    "#                 fdk_half = FDKHalf()(mat['prj'], get_geometry(), mat['angles'].flatten(), filter='hann', parker=True)\n",
    "#                 fdk_half = torch.from_numpy(fdk_half).detach()\n",
    "\n",
    "#                 # Save the recon results as .pt\n",
    "#                 torch.save(fdk_half, recon_path)\n",
    "\n",
    "#                 logger.debug(f\"Saved {'gated' if gated else 'nonstop-gated'} projection for {scan_type} p{patient}_{scan}.\")\n",
    "\n",
    "#                 # Delete the nonstop-gated result to free storage space\n",
    "#                 if not gated:\n",
    "#                     os.remove(result_path)\n",
    "#                     logger.debug(f\"Deleted nonstop-gated projection file {result_path} to save storage space.\")\n",
    "\n",
    "#                 del fdk_half, mat\n",
    "\n",
    "#         # Free up memory\n",
    "#         del PD_model\n",
    "\n",
    "# logger.info(\"All models applied to projections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09b672",
   "metadata": {},
   "source": [
    "# Aggregate CT volumes for train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97c6c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pipeline:Loaded scan list for aggregation: {'TRAIN': [('01', '01', 'HF'), ('01', '02', 'HF'), ('01', '03', 'HF'), ('01', '04', 'HF'), ('01', '05', 'HF'), ('01', '06', 'HF'), ('03', '01', 'HF'), ('04', '01', 'HF'), ('04', '02', 'HF'), ('04', '03', 'HF'), ('05', '01', 'HF'), ('06', '01', 'HF'), ('06', '02', 'HF'), ('09', '01', 'HF'), ('11', '01', 'HF'), ('11', '02', 'HF'), ('11', '03', 'HF'), ('11', '04', 'HF'), ('11', '05', 'HF'), ('12', '01', 'HF'), ('12', '02', 'HF'), ('12', '03', 'HF'), ('12', '04', 'HF'), ('13', '01', 'HF'), ('13', '02', 'HF'), ('13', '03', 'HF'), ('13', '04', 'HF'), ('13', '05', 'HF'), ('13', '06', 'HF'), ('17', '01', 'HF'), ('18', '01', 'HF'), ('18', '02', 'HF'), ('18', '03', 'HF'), ('18', '04', 'HF'), ('19', '01', 'HF'), ('19', '02', 'HF'), ('21', '01', 'HF'), ('21', '02', 'HF'), ('21', '03', 'HF'), ('21', '04', 'HF'), ('23', '01', 'HF'), ('23', '02', 'HF')], 'VALIDATION': [('02', '01', 'HF'), ('02', '02', 'HF'), ('16', '01', 'HF'), ('16', '02', 'HF'), ('22', '01', 'HF'), ('22', '02', 'HF')], 'TEST': [('08', '01', 'HF'), ('10', '01', 'HF'), ('14', '01', 'HF'), ('14', '02', 'HF'), ('15', '01', 'HF'), ('20', '01', 'HF')]}\n",
      "DEBUG:pipeline:Loaded configuration from config_20epoch.yaml\n",
      "WARNING:pipeline:Aggregated reconstruction data already exists in D:/NoahSilverberg/ngCBCT\\phase7\\DS13\\aggregates\\images\\MK7_07. Skipping...\n",
      "INFO:pipeline:Reconstruction data aggregation completed successfully.\n",
      "INFO:pipeline:Aggregated reconstruction data saved in: D:/NoahSilverberg/ngCBCT\\phase7\\DS13\\aggregates\\images\\MK7_07\n"
     ]
    }
   ],
   "source": [
    "if SCANS_AGG is not None:\n",
    "    scans_agg, scan_type = read_scans_agg_file(SCANS_AGG)\n",
    "    logger.debug(f\"Loaded scan list for aggregation: {scans_agg}\")\n",
    "\n",
    "    # Load the yaml configuration file\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "    input_type = config['ID_settings']['input_type']\n",
    "\n",
    "    # Get the ensemble size, and loop through it\n",
    "    ensemble_size = config['ID_settings']['ensemble_size']\n",
    "    for i in range(ensemble_size):\n",
    "        # If we are training an ensemble, we add an identifier to the model version\n",
    "        if ensemble_size > 1 and config['ID_settings']['input_type_match_ensemble']:\n",
    "            input_type = f\"{input_type}_{i+1:02}\" # e.g., \"v1_01\"\n",
    "\n",
    "        # Only aggregate reconstructions if they don't already exist\n",
    "        agg_dir = DIRECTORIES.get_images_aggregate_dir(input_type)\n",
    "        if len(os.listdir(agg_dir)) > 0:\n",
    "            logger.warning(f\"Aggregated reconstruction data already exists in {agg_dir}. Skipping...\")\n",
    "        else:\n",
    "            logger.info(\"Starting to aggregate reconstruction data...\")\n",
    "\n",
    "            # Aggregate and save reconstruction data sets\n",
    "            for split in ['TRAIN', 'VALIDATION', 'TEST']:\n",
    "                if len(scans_agg[split]) > 0:\n",
    "                    ng_paths = [FILES.get_recon_filepath(input_type, patient, scan, scan_type, gated=False) for patient, scan, scan_type in scans_agg[split]]\n",
    "                    recon_ngcbct = aggregate_saved_recons(ng_paths, augment=AUGMENT_ID)\n",
    "                    ng_agg_path = FILES.get_images_aggregate_filepath(input_type, split, gated=False)\n",
    "                    np.save(ng_agg_path, recon_ngcbct.numpy())\n",
    "                    del recon_ngcbct\n",
    "                    logger.debug(\"Done with nonstop-gated...\")\n",
    "                    g_paths = [FILES.get_recon_filepath(input_type, patient, scan, scan_type, gated=True) for patient, scan, scan_type in scans_agg[split]]\n",
    "                    recon_gcbct = aggregate_saved_recons(g_paths, augment=AUGMENT_ID)\n",
    "                    g_agg_path = FILES.get_images_aggregate_filepath('fdk', split, gated=True)\n",
    "                    np.save(g_agg_path, recon_gcbct.numpy())\n",
    "                    del recon_gcbct\n",
    "                    logger.debug(\"Done with gated...\")\n",
    "\n",
    "                    logger.debug(f\"Aggregated reconstructions saved for {scan_type} {split}.\\n\")\n",
    "                else:\n",
    "                    logger.debug(f\"No scans to aggregate for {scan_type} {split}. Skipping aggregation.\")\n",
    "\n",
    "        logger.info(\"Reconstruction data aggregation completed successfully.\")\n",
    "        logger.info(\"Aggregated reconstruction data saved in: %s\", agg_dir)\n",
    "else:\n",
    "    logger.info(\"No scans to aggregate. Skipping reconstruction data aggregation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e933115",
   "metadata": {},
   "source": [
    "# Train ID CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b35e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:pipeline:Loaded configuration from config_20epoch.yaml\n",
      "DEBUG:pipeline:Using CUDA; 1 devices.\n",
      "DEBUG:pipeline:Loaded class TrainingApp from module train_app_MK6_numpy\n",
      "DEBUG:pipeline:Optimizer: NAdam with learning rate 0.001, betas (0.9, 0.999), momentum_decay 0.0004\n",
      "INFO:pipeline:Going to try training the 1-th model with configuration from config_20epoch.yaml...\n",
      "DEBUG:pipeline:Starting TrainingApp, {'training': True, 'training_app': 'train_app_MK6_numpy.TrainingApp', 'epochs': 50, 'learning_rate': 0.001, 'network_name': 'IResNet', 'model_version': 'MK7_07', 'batch_size': 8, 'optimizer': 'NAdam', 'num_workers': 0, 'shuffle': True, 'grad_clip': True, 'grad_max': 0.01, 'betas_NAdam': (0.9, 0.999), 'momentum_decay_NAdam': 0.0004, 'momentum_SGD': 0.99, 'weight_decay_SGD': 1e-08, 'checkpoint_save_step': 10, 'tensor_board': False, 'tensor_board_comment': '', 'train_during_inference': False, 'ensemble_size': 1, 'scan_type': 'HF', 'input_type': 'MK7_07', 'input_type_match_ensemble': True, 'data_version': '13', 'domain': 'IMAG'}\n",
      "DEBUG:pipeline:TRAIN images path: D:/NoahSilverberg/ngCBCT\\phase7\\DS13\\aggregates\\images\\MK7_07\\ng_train.npy\n",
      "DEBUG:pipeline:TRAIN ground truth images path: D:/NoahSilverberg/ngCBCT\\phase7\\DS13\\aggregates\\images\\fdk\\gated_train.npy\n",
      "DEBUG:pipeline:TRAIN dataset loaded with 20160 samples, each with shape torch.Size([1, 512, 512]).\n",
      "DEBUG:pipeline:TRAIN dataloader initialized with 2520 batches of size 8, with 0 workers, shuffle=True, and pin_memory=False.\n",
      "DEBUG:pipeline:VALIDATION images path: D:/NoahSilverberg/ngCBCT\\phase7\\DS13\\aggregates\\images\\MK7_07\\ng_validation.npy\n",
      "DEBUG:pipeline:VALIDATION ground truth images path: D:/NoahSilverberg/ngCBCT\\phase7\\DS13\\aggregates\\images\\fdk\\gated_validation.npy\n",
      "DEBUG:pipeline:VALIDATION dataset loaded with 2880 samples, each with shape torch.Size([1, 512, 512]).\n",
      "DEBUG:pipeline:VALIDATION dataloader initialized with 360 batches of size 8, with 0 workers, shuffle=True, and pin_memory=False.\n",
      "INFO:pipeline:TRAINING SETTINGS:\n",
      "INFO:pipeline:{'training': True, 'training_app': 'train_app_MK6_numpy.TrainingApp', 'epochs': 50, 'learning_rate': 0.001, 'network_name': 'IResNet', 'model_version': 'MK7_07', 'batch_size': 8, 'optimizer': 'NAdam', 'num_workers': 0, 'shuffle': True, 'grad_clip': True, 'grad_max': 0.01, 'betas_NAdam': (0.9, 0.999), 'momentum_decay_NAdam': 0.0004, 'momentum_SGD': 0.99, 'weight_decay_SGD': 1e-08, 'checkpoint_save_step': 10, 'tensor_board': False, 'tensor_board_comment': '', 'train_during_inference': False, 'ensemble_size': 1, 'scan_type': 'HF', 'input_type': 'MK7_07', 'input_type_match_ensemble': True, 'data_version': '13', 'domain': 'IMAG'}\n",
      "INFO:pipeline:STARTING TRAINING...\n",
      "DEBUG:pipeline:Learning rate is 0.001 at epoch 1.\n",
      "DEBUG:pipeline:Model set to training mode for training.\n",
      "Epoch 1 Training: 100%|██████████| 2520/2520 [31:02<00:00,  1.35it/s]\n",
      "INFO:pipeline:Epoch: 1 \tAvg Training Loss: 0.000739  \tTime(s) 1862.7122\n",
      "DEBUG:pipeline:Model set to evaluation mode for validation.\n",
      "Epoch 1 Validation: 100%|██████████| 360/360 [01:36<00:00,  3.74it/s]\n",
      "INFO:pipeline:Epoch: 1 \tAvg Validation Loss: 0.000462  \tTime(s) 96.2809\n",
      "\n",
      "DEBUG:pipeline:Learning rate is 0.001 at epoch 2.\n",
      "DEBUG:pipeline:Model set to training mode for training.\n",
      "Epoch 2 Training:  14%|█▍        | 362/2520 [04:18<25:37,  1.40it/s]"
     ]
    }
   ],
   "source": [
    "for config_file in CONFIG_FILES:\n",
    "    # Load the yaml configuration file\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    logger.debug(f\"Loaded configuration from {config_file}\")\n",
    "\n",
    "    # Skip this config if the user has set ID_training to False\n",
    "    if not config['ID_settings']['training']:\n",
    "        logger.info(f\"Skipping ID training for {config_file} as ID training is set to False.\")\n",
    "        continue\n",
    "\n",
    "    # Get the training application\n",
    "    module_name, class_name = config['ID_settings']['training_app'].rsplit('.', 1)\n",
    "    module = importlib.import_module(\"pipeline.\" + module_name)\n",
    "    cls = getattr(module, class_name)\n",
    "\n",
    "    logger.debug(f\"Loaded class {class_name} from module {module_name}\")\n",
    "\n",
    "    # Get the model version (for naming purposes)\n",
    "    model_version = config['ID_settings']['model_version']\n",
    "\n",
    "    # Get the ensemble size, and loop through it\n",
    "    ensemble_size = config['ID_settings']['ensemble_size']\n",
    "    for i in range(ensemble_size):\n",
    "        # If we are training an ensemble, we add an identifier to the model version\n",
    "        if ensemble_size > 1:\n",
    "            # Deepcopy config so we don't affect the original\n",
    "            cfg = copy.deepcopy(config)\n",
    "            cfg['ID_settings']['model_version'] = f\"{model_version}_{i+1:02}\" # e.g., \"v1_01\"\n",
    "            if config['ID_settings']['input_type_match_ensemble']:\n",
    "                cfg['ID_settings']['input_type'] = f\"{cfg['ID_settings']['input_type']}_{i+1:02}\"\n",
    "        else:\n",
    "            cfg = config\n",
    "\n",
    "        # Add the data version to the configuration\n",
    "        cfg['ID_settings']['data_version'] = DATA_VERSION\n",
    "\n",
    "        # Instantiate with the loaded configuration\n",
    "        instance = cls(cfg, \"IMAG\", DEBUG, FILES)\n",
    "\n",
    "        logger.info(f\"Going to try training the {i + 1}-th model with configuration from {config_file}...\")\n",
    "\n",
    "        # Run the training\n",
    "        instance.main()\n",
    "\n",
    "        logger.info(f\"Finished training the {i + 1}-th model.\\n\")\n",
    "\n",
    "        del instance, cfg\n",
    "        gc.collect()\n",
    "\n",
    "    # Free up memory\n",
    "    del module, cls, config, module_name, class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f74da1",
   "metadata": {},
   "source": [
    "# Pass all samples through the ID model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4461679",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
