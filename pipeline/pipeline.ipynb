{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85cca8e",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .config import CUDA_DEVICE, DEBUG, SCANS, DATA_DIR, RESULT_DIR, data_version, PD_training_app, PD_epochs, PD_network_name, PD_model_name, PD_batch_size, PD_optimizer, PD_num_workers, ID_training_app, ID_epochs, ID_network_name, ID_model_name, ID_batch_size, ID_optimizer, ID_num_workers\n",
    "from .proj import load_projection_mat, reformat_sinogram, interpolate_projections, pad_and_reshape, divide_sinogram\n",
    "from .aggregate_prj import aggregate_saved_projections\n",
    "from .launcher import run_app\n",
    "from .apply_model import apply_model_to_projections, load_model\n",
    "from .infer3d import inference_3d\n",
    "from .utils import ensure_dir\n",
    "import torch\n",
    "import scipy.io\n",
    "import os\n",
    "# TODO run FDK via: FFrecon_reconFDK(input_mat, output_mat); in file \"FFrecon_fullFDK.m\"\n",
    "# TODO add DEBUG mode that prints out helpful info like shapes, etc. (and be sure to set logging level so 'info' shows up too)\n",
    "# TODO add some kind of logging for the hyperparameters used in the each run\n",
    "# TODO go through the training code and make sure it is consistent with new pipeline\n",
    "# TODO save everything as numpy arrays instead of torch tensors, and then convert to torch tensors when needed\n",
    "# TODO add more options for training like learning rate, etc.\n",
    "# TODO the user needs to pick which scans go in the training, val, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b49a2c",
   "metadata": {},
   "source": [
    "# 1. Data Preparation: projection interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient, scan, scan_type in SCANS:\n",
    "    # Load the projection data from the matlab files\n",
    "    odd_index, angles, prj = load_projection_mat(patient, scan, scan_type)\n",
    "\n",
    "    # Flip and permute to get it in the right format\n",
    "    prj_gcbct, angles1 = reformat_sinogram(prj, angles)\n",
    "\n",
    "    # Simulate ngCBCT projections\n",
    "    prj_ngcbct_li = interpolate_projections(prj_gcbct, odd_index)\n",
    "\n",
    "    # Split the projections into two halves so they are good dimensions for the CNN\n",
    "    combined_gcbct = divide_sinogram(pad_and_reshape(prj_gcbct), v_dim=512 if scan_type == \"HF\" else 256)\n",
    "    combined_ngcbct = divide_sinogram(pad_and_reshape(prj_ngcbct_li), v_dim=512 if scan_type == \"HF\" else 256)\n",
    "\n",
    "    # Ensure the output directories exist\n",
    "    g_dir = os.path.join(DATA_DIR, 'gated')\n",
    "    ng_dir = os.path.join(DATA_DIR, 'ng')\n",
    "    ensure_dir(g_dir)\n",
    "    ensure_dir(ng_dir)\n",
    "    \n",
    "    # Save the projections\n",
    "    torch.save(combined_gcbct, os.path.join(g_dir, f'{scan_type}_p{patient}_{scan}.pt')) # e.g., HF_p01_01.pt\n",
    "    torch.save(combined_ngcbct, os.path.join(ng_dir, f'{scan_type}_p{patient}_{scan}.pt'))\n",
    "\n",
    "# Free up memory\n",
    "del odd_index, angles, prj, prj_gcbct, angles1, prj_ngcbct_li, combined_gcbct, combined_ngcbct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4e695f",
   "metadata": {},
   "source": [
    "# 2. Aggregate projections for train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for aggregated data saving\n",
    "agg_dir = os.path.join(DATA_DIR, \"agg\")\n",
    "ensure_dir(agg_dir)\n",
    "\n",
    "# Aggregate and save projection data sets\n",
    "for scan_type in ['HF', 'FF']:\n",
    "    for sample in ['train', 'validation', 'test']:\n",
    "        prj_gcbct, prj_ngcbct = aggregate_saved_projections(scan_type, sample)\n",
    "        torch.save(prj_gcbct, os.path.join(agg_dir, f\"{scan_type}_{sample}_gated.pt\"))\n",
    "        torch.save(prj_ngcbct, os.path.join(agg_dir, f\"{scan_type}_{sample}_ng.pt\"))\n",
    "\n",
    "# Free up memory\n",
    "del prj_gcbct, prj_ngcbct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae3e79",
   "metadata": {},
   "source": [
    "# 3. Training PD CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daead9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_app(PD_training_app, [f'--epoch={PD_epochs}', f'--network={PD_network_name}', f'--model_name={PD_model_name}', f'--data_ver={data_version}', f'--optimizer={PD_optimizer}', '--shuffle=True', f'--DEBUG={DEBUG}', f'--batch_size={PD_batch_size}'], f'--num_workers={PD_num_workers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef2c2c",
   "metadata": {},
   "source": [
    "# 4. Apply PD model to all nonstop-gated sinograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28452019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained PD model onto the GPU\n",
    "PD_model = load_model(PD_network_name, PD_model_name, device=torch.device(CUDA_DEVICE))\n",
    "\n",
    "for patient, scan, scan_type in SCANS:\n",
    "    # Get the matlab dicts for the ground truth and CNN projections\n",
    "    g_mat, cnn_mat = apply_model_to_projections(patient, scan, scan_type, PD_model)\n",
    "\n",
    "    # Save the ground truth and CNN projections\n",
    "    scipy.io.savemat(os.path.join(RESULT_DIR, f'{scan_type}_p{patient}_{scan}_gated.mat'), g_mat)\n",
    "    scipy.io.savemat(os.path.join(RESULT_DIR, f'{scan_type}_p{patient}_{scan}_ng.mat'), cnn_mat)\n",
    "\n",
    "# Free up memory\n",
    "del PD_model, g_mat, cnn_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaa971",
   "metadata": {},
   "source": [
    "# 5. TODO: FDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09b672",
   "metadata": {},
   "source": [
    "# 6. Aggregate CT volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_ct_volumes(data_version, 'train', scan_type=0, augment=False)\n",
    "aggregate_ct_volumes(data_version, 'train', scan_type=0, augment=True)\n",
    "# repeat for validation/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e933115",
   "metadata": {},
   "source": [
    "# 7. Train ID CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b35e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f74da1",
   "metadata": {},
   "source": [
    "# 8. Inference on test scans for full 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = inference_3d(patient_id, scan_id, 'HF', data_version, model_name, 'tumor_location_panc.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
